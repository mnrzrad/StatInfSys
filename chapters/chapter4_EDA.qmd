---
engine: knitr
filters: 
  - webr
---

# Exploratory data analysis (EDA)

## Plan the Study

```{dot}
digraph StatProcess {
    // Graph settings
    rankdir=TB;   // Top -> Bottom
    bgcolor="transparent";
    node [fontname="Arial", fontsize=12];  // larger font default
    edge [color="#333333", penwidth=2];

    // === Problem ===
    subgraph cluster_problem {
        style=invis; label="";
        P1 [shape=circle, style=filled, fillcolor="#E07B39", fontcolor=white,
            label="P", width=0.7, height=0.7, fontsize=16, fontname="Arial Bold"];

        BOX1 [shape=box, style="filled,rounded", fillcolor="#E07B39:white",
              color="#333333", penwidth=2, fontsize=12, fontname="Arial", width=3,
              label=<<TABLE BORDER="0" CELLBORDER="0" CELLSPACING="0" CELLPADDING="4">
                     <TR><TD><B><FONT POINT-SIZE="14">Problem</FONT></B></TD></TR>
                     <TR><TD ALIGN="LEFT">• Write down study objectives</TD></TR>
                     <TR><TD ALIGN="LEFT">• Identify target/sample population</TD></TR>
                     <TR><TD ALIGN="LEFT">• Define the variates</TD></TR>
              </TABLE>>];

        { rank=same; P1; BOX1; }
        P1 -> BOX1 [style=dotted, arrowhead=none, color="#666666", constraint=false];
    }

    // === Plan ===
    subgraph cluster_plan {
        style=invis; label="";
        P2 [shape=circle, style=filled, fillcolor="#999999", fontcolor=white,
            label="P", width=0.7, height=0.7, fontsize=16, fontname="Arial Bold"];

        BOX2 [shape=box, style="filled,rounded", fillcolor="#999999:white",
              color="#333333", penwidth=2, fontsize=12, fontname="Arial", width=3,
              label=<<TABLE BORDER="0" CELLBORDER="0" CELLSPACING="0" CELLPADDING="4">
                     <TR><TD><B><FONT POINT-SIZE="14">Plan</FONT></B></TD></TR>
                     <TR><TD ALIGN="LEFT">• Plan data collection methods</TD></TR>
                     <TR><TD ALIGN="LEFT">• Calculate sample size</TD></TR>
                     <TR><TD ALIGN="LEFT">• Consider analysis options</TD></TR>
              </TABLE>>];

        { rank=same; P2; BOX2; }
        P2 -> BOX2 [style=dotted, arrowhead=none, color="#666666", constraint=false];
    }

    // === Data ===
    subgraph cluster_data {
        style=invis; label="";
        D [shape=circle, style=filled, fillcolor="#F4D03F", fontcolor=black,
           label="D", width=0.7, height=0.7, fontsize=16, fontname="Arial Bold"];

        BOX3 [shape=box, style="filled,rounded", fillcolor="#F4D03F:white",
              color="#333333", penwidth=2, fontsize=12, fontname="Arial", width=3,
              label=<<TABLE BORDER="0" CELLBORDER="0" CELLSPACING="0" CELLPADDING="4">
                     <TR><TD><B><FONT POINT-SIZE="14">Data</FONT></B></TD></TR>
                     <TR><TD ALIGN="LEFT">• Collect data per plan</TD></TR>
                     <TR><TD ALIGN="LEFT">• Note any deviations</TD></TR>
              </TABLE>>];

        { rank=same; D; BOX3; }
        D -> BOX3 [style=dotted, arrowhead=none, color="#666666", constraint=false];
    }

    // === Analysis ===
    subgraph cluster_analysis {
        style=invis; label="";
        A [shape=circle, style=filled, fillcolor="#5DADE2", fontcolor=white,
           label="A", width=0.7, height=0.7, fontsize=16, fontname="Arial Bold"];

        BOX4 [shape=box, style="filled,rounded", fillcolor="#5DADE2:white",
              color="#333333", penwidth=2, fontsize=12, fontname="Arial", width=3,
              label=<<TABLE BORDER="0" CELLBORDER="0" CELLSPACING="0" CELLPADDING="4">
                     <TR><TD><B><FONT POINT-SIZE="14">Analysis</FONT></B></TD></TR>
                     <TR><TD ALIGN="LEFT">• Analyze data per plan</TD></TR>
              </TABLE>>];

        { rank=same; A; BOX4; }
        A -> BOX4 [style=dotted, arrowhead=none, color="#666666", constraint=false];
    }

    // === Conclusion ===
    subgraph cluster_conclusion {
        style=invis; label="";
        C [shape=circle, style=filled, fillcolor="#82C341", fontcolor=white,
           label="C", width=0.7, height=0.7, fontsize=16, fontname="Arial Bold"];

        BOX5 [shape=box, style="filled,rounded", fillcolor="#82C341:white",
              color="#333333", penwidth=2, fontsize=12, fontname="Arial", width=3,
              label=<<TABLE BORDER="0" CELLBORDER="0" CELLSPACING="0" CELLPADDING="4">
                     <TR><TD><B><FONT POINT-SIZE="14">Conclusion</FONT></B></TD></TR>
                     <TR><TD ALIGN="LEFT">• Draw conclusion in context</TD></TR>
              </TABLE>>];

        { rank=same; C; BOX5; }
        C -> BOX5 [style=dotted, arrowhead=none, color="#666666", constraint=false];
    }

    // Vertical flow between clusters (left arrow column)
    P1 -> P2 -> D -> A -> C;
}
```

## After collecting the data

```{dot}
digraph AfterCollecting {
  rankdir=TB;  // top to bottom
  bgcolor="transparent";
  ranksep=1.0; // vertical spacing between stages
  
  // Common node style (uniform size for all boxes)
  node [
    shape=box, style="rounded,filled", color="#333333", penwidth=2,
    fontname="Arial",
    width=10, height=2.5, fixedsize=true
  ];
  
  // Stage 1
  S1 [label=<
    <TABLE BORDER="0" CELLBORDER="0" CELLSPACING="0" CELLPADDING="12" WIDTH="500" HEIGHT="120">
      <TR><TD ALIGN="LEFT"><B><FONT POINT-SIZE="40">Review the hypotheses</FONT></B></TD></TR>
      <TR><TD ALIGN="LEFT">
        <TABLE BORDER="0" CELLBORDER="0" CELLSPACING="2">
          <TR><TD ALIGN="RIGHT" WIDTH="28">•</TD><TD ALIGN="LEFT"><FONT POINT-SIZE="28">Review the research questions</FONT></TD></TR>
          <TR><TD ALIGN="RIGHT">•</TD><TD ALIGN="LEFT"><FONT POINT-SIZE="28">Consider sub-questions</FONT></TD></TR>
        </TABLE>
      </TD></TR>
    </TABLE>
  >, fillcolor="#FAD7A0"];
  
  // Stage 2
  S2 [label=<
    <TABLE BORDER="0" CELLBORDER="0" CELLSPACING="0" CELLPADDING="12" WIDTH="500" HEIGHT="120">
      <TR><TD ALIGN="LEFT"><B><FONT POINT-SIZE="40">Process the raw data</FONT></B></TD></TR>
      <TR><TD ALIGN="LEFT">
        <TABLE BORDER="0" CELLBORDER="0" CELLSPACING="2">
          <TR><TD ALIGN="RIGHT" WIDTH="20">•</TD><TD ALIGN="LEFT"><FONT POINT-SIZE="28">Select a suitable statistics software</FONT></TD></TR>
          <TR><TD ALIGN="RIGHT">•</TD><TD ALIGN="LEFT"><FONT POINT-SIZE="28">Convert the data into an acceptable format</FONT></TD></TR>
        </TABLE>
      </TD></TR>
    </TABLE>
  >, fillcolor="#D5DBDB"];
  
  // Stage 3
  S3 [label=<
    <TABLE BORDER="0" CELLBORDER="0" CELLSPACING="0" CELLPADDING="12" WIDTH="500" HEIGHT="120">
      <TR><TD ALIGN="LEFT"><B><FONT POINT-SIZE="40">Explore the data</FONT></B></TD></TR>
      <TR><TD ALIGN="LEFT">
        <TABLE BORDER="0" CELLBORDER="0" CELLSPACING="2">
          <TR><TD ALIGN="RIGHT" WIDTH="20">•</TD><TD ALIGN="LEFT"><FONT POINT-SIZE="28">Descriptive summaries</FONT></TD></TR>
          <TR><TD ALIGN="RIGHT">•</TD><TD ALIGN="LEFT"><FONT POINT-SIZE="28">Data visualization</FONT></TD></TR>
        </TABLE>
      </TD></TR>
    </TABLE>
  >, fillcolor="#F9E79F"];
  
  // Stage 4
  S4 [label=<
    <TABLE BORDER="0" CELLBORDER="0" CELLSPACING="0" CELLPADDING="12" WIDTH="500" HEIGHT="120">
      <TR><TD ALIGN="LEFT"><B><FONT POINT-SIZE="40">Analyze the data</FONT></B></TD></TR>
      <TR><TD ALIGN="LEFT">
        <TABLE BORDER="0" CELLBORDER="0" CELLSPACING="2">
          <TR><TD ALIGN="RIGHT" WIDTH="20">•</TD><TD ALIGN="LEFT"><FONT POINT-SIZE="28">Inferential analysis</FONT></TD></TR>
          <TR><TD ALIGN="RIGHT">•</TD><TD ALIGN="LEFT"><FONT POINT-SIZE="28">Prediction</FONT></TD></TR>
        </TABLE>
      </TD></TR>
    </TABLE>
  >, fillcolor="#AED6F1"];
  
  // Stage 5
  S5 [label=<
    <TABLE BORDER="0" CELLBORDER="0" CELLSPACING="0" CELLPADDING="12" WIDTH="500" HEIGHT="120">
      <TR><TD ALIGN="LEFT"><B><FONT POINT-SIZE="40">Report the results</FONT></B></TD></TR>
      <TR><TD ALIGN="LEFT">
        <TABLE BORDER="0" CELLBORDER="0" CELLSPACING="2">
          <TR><TD ALIGN="RIGHT" WIDTH="20">•</TD><TD ALIGN="LEFT"><FONT POINT-SIZE="28">Interpret the results in the context of the study</FONT></TD></TR>
        </TABLE>
      </TD></TR>
    </TABLE>
  >, fillcolor="#ABEBC6"];
  
  // Vertical flow connections
  S1 -> S2 -> S3 -> S4 -> S5 [color="#666666", arrowsize=1.2, penwidth=2];
}

```

## What is EDA?

Exploratory data analysis (EDA) was first formally introduced by @Tukey1977 in his influential book, *Exploratory Data Analysis.*

::: {layout-ncol="2"}
![](/figs/EDA/Tukey.jpg){width="288"}

![](/figs/EDA/book.jpg){width="238"}
:::

Since then, its importance has grown significantly, especially in recent years, for several key reasons [@Midway2022]:

i\) data is being produced faster and in larger volumes than ever before,

ii\) modern computing and software tools make it easier to explore, clean, and visualize data in meaningful ways,

iii\) contemporary statistical models are often complex and assumption-dependent, requiring us to thoroughly understand the data before applying formal techniques.

The EDA may not be fully described in concrete terms, but most data analysts and statisticians know it when they see it.

::: callout-important
The EDA is important because it helps researchers make thoughtful decisions about which ideas are worth exploring. Sometimes, the data clearly show that a particular question does not have enough support to be studied further—at least not with the current evidence.
:::

The main goals of EDA are:

-   To suggest hypotheses about what might be causing the patterns or relationships observed in the data,

-   To guide the choice of appropriate statistical tools or models by helping you understand the structure of the data,

-   To assess key assumptions that must be checked before applying formal statistical analysis (e.g., linearity, normality, independence),

-   To provide a basis for further data collection, by highlighting gaps, inconsistencies, or areas where more information is needed.

::: callout-note
EDA is not typically the final stage of analysis. Rather, it serves as a **transitional step between raw data and formal modeling**. The insights gained through EDA guide decisions about which models to use, which variables to consider, and which data issues to address.
:::

::: callout-important
## EDA Checklist

Roger D. Peng in his book [@Peng2012] provide this checklist for conducting EDA.

1.  **Start with a clear question:** Before you begin EDA, take time to define exactly what you want to find out. A clear question or hypothesis gives your analysis purpose and helps you stay focused along the way.

2.  **Load your data carefully:** Make sure your dataset is fully and correctly loaded into your analysis tool (e.g., R or Python). This first step is essential—it sets the stage for everything you will do next.

3.  **Take a first look at the data:** Check that the file type, structure, and layout are what you expected. Make sure everything is organized in a way that works for your analysis.

4.  **Use `str()` to Peek Inside the Dataset:** In R, it will get a quick summary: number of observations (rows), number and names of variables (columns), variable types (e.g., numeric, character, factor), and a preview of the data values

5.  **Look at the Beginning and End of Your Data:** Use functions such as `head()` and `tail()` to view the first and last few rows. This visual check can help to detect issues such as incorrect headers, blank rows, or unusual formatting.

6.  **Check the Number of Rows ("n"):** Make sure to verify how many observations (rows) are in your dataset. Compare this to what you expected from the original. source. If the number is too high or too low, there may be missing values, duplicate entries, or extra rows (e.g. duplicates or blank lines).

7.  **Validate with an External Source:** When possible, compare part of your dataset with a trusted external source, such as official statistics or published reports. This helps confirm the accuracy and reliability of your data.

8.  **Try the Simple Solution First:** Start by basic methods–such as summaries, tables, or visualizations– to explore and answer your question. Simple tools can often reveal key patterns or issues. Use more complex techniques only of necessary.

9.  **Challenge Your Findings:** Once you find a result, pause and ask yourself: *Does this make sense?* Check your assumptions and consider possible errors or missing information. Being critical helps make your results stronger and more trustworthy.

10. **Decide What to Do Next:** Use the insights from your EDA to guide your next steps. You may decide to collect more data, use new methods, or refine your question. Sometimes , your initial findings are already enough to answer your main question.

In Chapter 4 of @Midway2022, interested reader can find some comments for each step.
:::

::: callout-important
EDA is the single most important task to conduct at the beginning of every data science project.
:::

::: callout-tip
EDA is like exploring a new place – you do not know what you will find until you start looking.
:::

## Enter the world of EDA

```{dot}
digraph EDA {
  rankdir=TB;
  bgcolor="transparent";
  fontsize=20;
  fontname="Arial";

  // Main node (bold, rounded box)
  EDA [label=<<B>Exploratory Data Analysis</B>>, 
       shape=box, style="rounded,filled", fontsize=28, fontname="Arial Bold", 
       fillcolor="#EAF2F8", color="#333333", width=5, height=1.2, fixedsize=true];

  // Subcategories (ellipses, same size)
  node [shape=ellipse, style="filled", fontname="Arial", fontsize=22, color="#333333", width=3, height=1.2, fixedsize=true];

  View     [label="View data", fillcolor="#FAD7A0"];
  Summary  [label="Summary\nstatistics", fillcolor="#D5DBDB"];
  Graphs   [label="Basic\nGraphs", fillcolor="#F9E79F"];
  Tests    [label="Basic\nTests", fillcolor="#ABEBC6"];

  // Connect main to sub
  EDA -> View;
  EDA -> Summary;
  EDA -> Graphs;
  EDA -> Tests;

  // Detail boxes (uniform size)
  node [shape=box, style="rounded", fontsize=24, fontname="Arial", width=4.5, height=4, fixedsize=true, color="#333333"];

  V1 [label="Observation number\nVariable number\nVariable type\nVariable category\nStructure"];
  View -> V1 [style=dashed];

  S1 [label="Mean\nMedian\nMode\nRange\nVariance\nStandard deviation\nOutliers\nMissing data"];
  Summary -> S1 [style=dashed];

  G1 [label="Histogram\nBar plot\nBoxplot\nScatter-plot\nQQ-plot"];
  Graphs -> G1 [style=dashed];

  T1 [label="Check assumptions\nT-tests\nCorrelations\nANOVA\nLinear model"];
  Tests -> T1 [style=dashed];

}
```

Now it is time to **start working with data** directly. To do that, we must first understand *how data are structured* and *what types of variables* we are dealing with.

Most datasets are organized in a rectangular format — like a spreadsheet — where each **row** represents one observation (e.g. a person, object, or experiment), and each **column** represents a variable (e.g. name, age, group, result).

![Adapted from Slides of 'EDA Module I: A Bird's Eye View' by Dr. Mark Williamson](/figs/EDA/datatable.png){fig-align="center"}

<!-- 
EDA is the process of looking at data to understand it before using statistics or models. It helps us to answer questions like: 

- what types of data do we have? 

- Are there missing or strange values? 

- What patterns can we see? 

- What kind of summary or visualization is helpful?
-->


### Types of Variables

Variables represent the information we collect in data analysis. They can be broadly divided into **categorical** and **numeric** types.

#### Categorical Variables

Categorical variables describe **qualities or characteristics**. They answer questions like “**what type?**” or “**which group?**”.

-   Also called **qualitative variables**, and they produce **qualitative data**.

-   They **do not have numeric meaning** (even if represented by numbers)

They fall into two main groups:

1.  **Nominal Variables**

    -   Categories have **no logical order**.

    -   They are simply **labels** or **names**.

For example, *Gender* (male, female), *Blood group (*A, B, AB, O), *City* (Lisbon, Porto, Faro, ... ), *color* (red, blue, green), the types of drinks at Starbucks, a person's eye color.

2.  **Ordinal Variables**

    -   Categories **can be ordered** or ranked.

    -   However, the **distance between categories is not exact** or **consistent**

For example, *Satisfaction* (low, medium, high), *education* (primary, secondary, university), *rank* (1st, 2nd, 3rd), *Academic grades* (A, B, C)

::: callout-note
**Avoid coding categories with numbers** (e.g., Male = 1, Female = 2), as this may wrongly suggest order or allow meaningless calculations.

**Tip:** Use **clear text labels** like `"Male"` and `"Female"`.
:::

#### Numerical variables

Numeric variables describe **quantities** **that can be measured**. They answer questions like “**how many?**” or “**how much?**”.

-   Also called **quantitative variables**, and they produce **quantitative data**.

-   They are **numbers** we can measure, and we can meaningfully perform mathematical operations on them.

-   Usually, they have a measurement unit.

Numerical (quantitative) variables can be classified in two complementary ways:

1.  **Continuous vs. Discrete** – How values occur

2.  **Ratio vs. Interval** – How the scale is defined

**Continuous vs. Discrete**

1.  **Continuous Variables**

    -   Can take **any value** on a number line, including decimals.

    -   Represent real-world quantities.

    -   They may be restricted to positivevalues (e.g., mass) or include negatives (e.g., temperature changes).

    Some examples are: *mass*, *age*, *temperature, time.*

2.  **Discrete Variables**

    -   Take **only whole number values** (no decimals).

    -   Based on **counting**.

    -   Cannot take values between integers (e.g., 2.5 students does not make sense).

Some examples are: *number of students, number of offspring, number of infected individuals*

**Ratio vs. Interval**

Numerical variables can also be distinguished by the **scale of measurement**, which affects how we interpret differences, proportions, and ratios.

1.  **Ratio Variables**

    -   Have a **true zero** point (zero means “none”).

    -   Allows **all mathematical operations**, including ratios and proportions.

    -   Interpretation: “Tree A is twice as tall as Tree B.”

Some examples are: *Height, Weight, Age, Income, mass.*

2.  **Interval Variables**

    -   Do **not** have a **true zero** (zero is **arbitrary**).

    -   Allows meaningful **differences**, but **not ratios**.

    -   Interpretation: “The difference between 20 °C and 10 °C is 10 degrees,” but not “20 °C is twice as hot as 10 °C.”

Some examples are *Temperature (*in Celsius of Fahrenheit), *IQ scores,* Calendar dates (e.g. year 1000 vs. 2000)

::: callout-note
**Same Quantity, Different Scales**

The distinction between **ratio** and **interval** depends on **how** the variable is **measured**, not on what is being measured.

For example,

-   Temperature in **Celsius** → interval scale (arbitrary zero).

-   Temperature in **Kelvin** → ratio scale (absolute zero).

So, the same phenomenon (temperature) can be an **interval variable** (in °C), or a **ratio variable** (in K).
:::

::: callout-tip
**Variable Types Are Not Always Fixed**

You cannot determine a variable’s type just from its name — it depends on **how the data is recorded**.

Example: **Age**

-   If recorded as an exact value (e.g., 25, 35.5, 80), it is a **numerical variable**.

-   If recorded in categories (e.g., \<20, 21–25, 80+), it is a **categorical variable**.
:::

**Summary of Variable Types**

![Source: https://datatab.net/tutorial/level-of-measurement](/figs/EDA/scales.png){fig-align="center"}

| Variable Type | Scale | Ordered? | Can Measure Distance? | Can Divide? | Examples |
|------------|------------|------------|------------|------------|------------|
| **Nominal** | Categorical | ❌ No | ❌ No | ❌ No | Gender, City, Color |
| **Ordinal** | Categorical | ✅ Yes | ❌ No (not exact) | ❌ No | Rank, Education, Likert |
| **Interval** | Numeric | ✅ Yes | ✅ Yes | ❌ No | Temperature, Year |
| **Ratio** | Numeric | ✅ Yes | ✅ Yes | ✅ Yes | Age, Weight, Income |

::: callout-tip
If you are not sure about a variable, ask:

-   Does the variable **have a natural order**?
-   Can we **count it** or **measure it**?
-   Does it have a **true zero**?
:::

::: callout-important
Knowing the types of data matters because:

-   Different **statistical methods** apply to different variable types.

-   Some **graphs and visualizations** only make sense for some types of variables.
:::

### Types of EDA

EDA helps us answer important questions like:

-   What are the most common values of a variable?
-   How much do observations differ from each other?
-   Is one variable related to another?

To answer these questions, EDA is generally cross-classified into two ways:

|   | **Non-graphical (numbers/tables)** | **Graphical (plots)** |
|----------------------|------------------------------|--------------------|
| **Univariate (one)** | Univariate × Non-graphical | Univariate × Graphical |
| **Multivariate (≥2\*)** | Multivariate × Non-graphical | Multivariate × Graphical |

\* Often bivariate.

In EDA, **non-graphical methods** are simply the **numbers**—the collection of **descriptive statistics** that summarize data (center, spread, shape, position, and association), while **graphical methods** are the visual counterparts that show those same properties (e.g., histograms/boxplots for distribution, scatterplots for association), helping us verify, compare, and spot patterns or anomalies that the numbers alone might hide.

Univariate methods examine a single variable at a time, whereas multivariate methods consider two or more variables to explore relationships—most often bivariate, though sometimes three or more—and it is generally best practice to first perform univariate EDA on each variable before moving on to multivariate analysis.

Beyond the four cells of the cross-classification, EDA choices also depend on each variable’s **role** (outcome vs explanatory) and **type** (categorical vs quantitative)—and there is an element of art that grows with practice.

![](/figs/EDA/art.png){fig-align="center"}

#### Descriptive Statistics

::: callout-note
When we measure the *same characteristic* (e.g., age, gender, task speed, response to a stimulus) on all subjects in a sample, the resulting values form the **sample distribution** of that variable. This sample distribution is our imperfect window onto the **population distribution**.

Descriptive statistics aims to *describe* the sample distribution—its location, spread, shape, and unusual observations—and to make *tentative* statements about which population distributions could plausibly have generated it.
:::

Descriptive statistics give **numerical summaries** of a dataset.

Before diving into categorical and numerical summaries, first check for **missing values**. Missingness is part of the data story and can be informative: **count** missing values and look for **patterns** (are they concentrated in certain variables or groups?). In EDA, always **report the number (and share) of missing values per variable**. We will return to strategies for handling missingness later, since it merits more attention and advanced methods.

```{webr-r}
library(ggplot2)
data("mpg", package = "ggplot2")

colSums(is.na(mpg))
```

::: callout-note
summaries like mean/SD ignore `NA` by default only if you set `na.rm = TRUE`; silently dropping cases can bias results.
:::

**Univariate Case**

1.  **Qualitative Data**

For a categorical variable, the key features are the **set of categories** (the possible values) and **how often each occurs** (frequency or relative frequency).

The primary tool is a **frequency table**: list each category with its **count** and **proportion/percent**. Always include the total \$N\$ (and any **missing**) to verify that every recruited subject is represented. As a quick quality check, proportions should sum to $1.00$ (or $100\%$). Once you are comfortable, reporting either **proportion** *or* **percent** is sufficient—they are equivalent.

```{webr-r}
data("mpg", package = "ggplot2")

N <- nrow(mpg)
cat('Total number of data is:', N)
head(mpg, 3)

# Frequency table
tab <- table(mpg$class)

# Proportions and percentages
prop <- prop.table(tab)
percent <- round(100 * prop, 1)

# Check totals
sum(tab)      # should equal N
sum(prop)     # should be 1
```

2.  **Quantitative Data**

A quantitative variable’s population distribution is described by its **center** (typical value), **spread** (how much values vary), **modality** (how many peaks), **shape** (including how long or heavy the tails are), and **outliers** (unusual values). The data we observe are just **one random sample** among many we could have drawn, so the sample’s features matter only because they help us **learn about the population** they come from.

What we observe for a given variable is the **sample distribution**—how the values happen to fall in this particular sample. If we drew another sample from the same population, the distribution (and the numbers we compute) would likely be different because of **random sampling** (and, in experiments, possibly different treatment assignments or conditions). From each sample we can calculate **sample statistics**—mean, variance/standard deviation, skewness, kurtosis—but these vary from sample to sample, so they are not exact truths; they are **noisy estimates** that provide uncertain information about the **population distribution** and its parameters.

If a quantitative variable has only a few distinct values, a simple **frequency table** (as with categorical data) can be a useful tool. More often, though, we rely on **numerical summaries**—sample statistics like the mean, median, variance, standard deviation, skewness, and kurtosis. These are best understood as **estimates** of their corresponding **population parameters**. We aim to learn what we can about those parameters from a **random sample**, knowing we can’t know them exactly, because the parameters are **“secrets of nature.”**

::: callout-note
**Quantitative vs categorical summaries**

For **quantitative** variables, it is meaningful to report a variable’s **central tendency** (mean/median), **spread** (SD/IQR), **skewness**, and **kurtosis**. For **categorical** variables, these summaries **do not make sense**—use **counts**, **proportions/percentages**, **number of levels**, **mode**, and **missingness** instead.
:::

They describe the key features of a variable:

-   **Center** (e.g., mean or median) — a typical value

-   **Spread** (e.g., standard deviation or interquartile range) — how much values vary

-   **Shape** (e.g., skewness) — symmetry or lean and tail behavior

-   **Extremes** (e.g., minimum, maximum, or outliers) — unusual low/high values

**Central Tendency**

A **measure of central tendency** tells us what a “typical” or "middle" value looks like in the data.

The most common measures are the **(arithmetic) mean**, the **median**, and sometimes the **mode**.

::: callout-caution
In special situations you may also see **geometric**, **harmonic**, **trimmed**, or **Winsorized** means used as measures of centrality.
:::

::: callout-note
Most authors use **average** to mean the arithmetic mean, though some use *average* more broadly to include these other means.
:::

If we have $n$ values $x_1$, $x_2$, $\ldots$, $x_n$, the **sample (arithmetic) mean** is

$$
\bar{x} = \frac{1}{n} \sum_{i=1}^n x_i
$$

In words: **add up all the values and divide by the number of values**.

::: callout-tip
A helpful picture is the *fair-share* idea—put everything into one pot and split it equally; the amount each person would get is the mean.
:::

For most descriptive quantities, there is a **population** version and a **sample** version. In a fixed finite population—or in an idealized infinite population defined by a probability model—there is a single **population mean**, a fixed (often unknown) **parameter**. By contrast, the **sample mean** changes from one sample to another; it is a **random variable**. The distribution of the sample mean over all possible samples is its **sampling distribution**. This reflects the idea that, at least in principle, we could repeat the sampling many times and recompute the statistic each time, getting different values. Under suitable assumptions, **probability theory** lets us derive the exact (or approximate) form of this sampling distribution.

::: callout-warning
**The mean is sensitive to outliers**

Be careful: the **mean** can be pulled toward extreme values. For example, using the mean to describe **income** is often misleading because a few very high earners raise the average.

**What to do instead:** for skewed data, report the **median** (and **IQR**) or show both mean *and* median; consider **trimmed/Winsorized means**; always add a quick plot (histogram/boxplot).
:::

```{webr-r}
data("mpg", package = "ggplot2")

# variable 'hwy' (highway mpg)
x <- mpg$hwy
length(x)

mean(x)
mean(x, na.rm = TRUE)
```

The **median** is another measure of central tendency. To find it, first sort the $n$ values from smallest to largest. If $n$ is **odd**, the median is the **middle** value; if $n$ is **even**, it is the **average of the two middle** values. When there are ties around the middle, statistical software applies standard rules so you still get a single number. (For some discrete variables there may not be a unique theoretical median, but software returns a conventional choice.)

In the 2004 U.S. Census Bureau Economic Survey, the **median family income** was **\$43,318**, meaning half of families earned less and half earned more. The **mean (average)** was **\$60,828**, the amount each family would have if total income were split equally. The gap between these two numbers is large because a few very high incomes pull the **mean** upward.

::: callout-tip
**Robustness of the median**

The **median is robust**, a few very large or very small values usually **do not change it**. You can move the highest or lowest observations far away and, as long as the middle order does not change, the median stays the same.
:::

```{webr-r}
x <- mpg$hwy

median(x)
median(x, na.rm = TRUE)
```

The **mode** is the most frequent value. For quantitative data it is rarely a good “typical” summary because with continuous or rounded variables the result depends on binning/rounding, may be non-unique, and many samples have no repeated value. We mostly use **mode** as shape language—**unimodal** (one peak), **bimodal** (two), **multimodal** (many). In practice, it is conceptually useful but hard to estimate robustly for numeric variables, and is used more for **categorical or discrete** data.

```{webr-r}
tab_class <- table(mpg$class, useNA = "ifany")
tab_class

cat_mode <- names(tab_class)[tab_class == max(tab_class)]
cat_mode
```

::: callout-note
**Mean vs. median**

The most common measure of central tendency is the **mean**. When **outliers** are a concern, the **median** may be preferred.
:::

**Spread (Dispersion)**

**Spread** tells us how far values tend to lie from the **center** and how different they are from one another. A dataset with very similar values has **low dispersion**; one with values scattered widely has **high dispersion**. Three common measures:

-   **Variance** — the average *squared* distance from the mean. Useful mathematically, but harder to interpret because it is in **squared units**.
-   **Standard deviation (SD)** — the square root of the variance. Same units as the data; think of it as a **typical distance from the mean**. For bell-shaped data, most observations sit within a few SDs of the mean.
-   **Interquartile range (IQR)** — the distance between the 25th and 75th percentiles; the **middle 50%** of the data. **Robust** to outliers, and usually paired with the **median**.

Other quick checks: the **range** (max − min) is easy but very sensitive to extremes; **MAD** (median absolute deviation) is a robust alternative to SD.

The MAD can be defined as

$$
\mathrm{MAD} = \mathop{\mathrm{median}}_{1\leq i \leq n} |x_i - \bar{x}|
$$

::: callout-tip
**Which measure when?**\
Use **SD** when the distribution is roughly symmetric and free of extreme outliers. Use **IQR** (often with the **median**) when the distribution is **skewed** or contains **outliers**.
:::

::: callout-warning
**Outliers inflate variance/SD.**\
A few extreme values can make the variance and SD look large even if most data are tightly clustered. Always check a plot and consider **IQR/MAD** for robustness.
:::

To describe spread, start with each value’s **deviation from the mean** (value − mean). If you add up all these signed deviations, they cancel and sum to **zero**. To avoid that cancellation and to give extra weight to big departures, we **square** the deviations and then average them—that average of squared deviations is the **variance**.

The **population variance** is the mean of the squared deviations. For a sample, the variance is an **estimate** of it and will change from sample to sample. For $n$ observations ($x_1$, $\ldots$ , $x_n$), define each **deviation** as $(x_i - \bar{x})$ (negative if below the mean, positive if above), and thus,

$$
s^2 = \frac{1}{n-1}\sum_{i=1}^n (x_i - \bar{x})^2
$$As a **sample statistic**, ($s^2$) varies from sample to sample; we use it to **estimate** the single, fixed **population variance** ($\sigma^2$). The $(n-1)$ in the denominator ensures *unbiasedness*: across many random samples, the average of $s^2$ equals $\sigma^2$.

<!-- 

Another (equivalent) way to write the variance is

$$
s^2 = \frac{SS}{df}
$$

where $SS$ is the **sum of squared deviations** (often just “sum of squares”), i.e., $SS = \sum_{i=1}^n (x_i-\bar{x})^2$, and $df$ is the **degrees of freedom**. For a single sample variance, $df = n-1$.

-->

::: callout-note
**Why does variance matter?**

Variance is an important quantity in statistics. Many **statistical tests** use changes in variance to compare groups or detect effects.
:::

Because we square deviations, the **variance** is always **non-negative** and its units are **squared**. That is why a temperature measured in degrees has variance in **degrees²**, and an area measured in km² would have variance in **km⁴**. This can feel odd, but it is also why we often report the **standard deviation** (the square root of variance) when we want a spread measure back in the original units.

```{webr-r}
x <- mpg$hwy
var(x, na.rm = TRUE)         
```

::: callout-caution
Does `var()` compute the sample variance or population variance?
:::

The **standard deviation** is the **square root of the variance**, so it is in the **same units** as the data, which makes it easier to interpret. We usually write the **sample** standard deviation as $s$ (and the population SD as $\sigma$ ).

::: callout-note
**Why use standard deviation?**

-   It is on the **same scale** as the variable

-   It gives us a **sense of spread** we can understand

-   it is more commonly used in EDA than variance
:::

::: callout-warning
**SD is sensitive (like the mean)**

The **standard deviation** is **not robust**: it can be distorted by **skewed distributions** and **outliers (extreme values)**.

**When this happens:** prefer median + IQR or MAD.
:::

```{webr-r}
x <- mpg$hwy
sd(x, na.rm = TRUE) 
```

To understand the **interquantile range (IQR),** first we define **quartiles**. Quartiles split the data into four equal parts: the first quartile (**Q1**) is the smallest value below which 25% of observations fall, the second quartile (**Q2**) is the median (50%), and the third quartile (**Q3**) marks 75%. These three cut points summarize where the lower quarter ends, where the middle lies, and where the upper quarter begins, which is especially helpful when the distribution is not symmetric.

The **interquartile range (IQR)** is the distance between the third and first quartiles, (\$ \mathrm{IQR} = Q3 - Q1\$ ). It measures how spread out the **middle 50%** of the data are: a wider IQR means the central values are more dispersed, and a narrower IQR means they are more tightly clustered. Like the standard deviation, the IQR is expressed in the **same units** as the original data, but unlike the standard deviation it is **robust**—a few extreme highs or lows have little effect on it because it depends only on the central half of the distribution.

In contrast, the **range** (maximum minus minimum) is very sensitive to outliers and can change dramatically from sample to sample; it is useful for quick checks and for spotting obvious data-entry errors when you know plausible bounds, but it is not a stable measure of spread. By comparison, the variance/standard deviation fluctuate less than the range, and the IQR fluctuates less than either of them.

::: callout-note
**Why is the IQR useful?**

-   It does not depend on extreme values.

-   It gives a good summary of the central spread

-   It is preferred in EDA for skewed or messy data.
:::

```{webr-r}
x <- mpg$hwy
IQR(x, na.rm = TRUE) 
```

**Shape (Skewness and kurtosis)**

**Skewness** describes **asymmetry**. A **positive** skew means a long **right** tail (very high values are more common than very low ones); a **negative** skew means a long **left** tail.

**Kurtosis** describes **tail weight** (and peak shape) **relative to a Normal** distribution. **Positive** kurtosis (“heavy tails”) means more extreme values and a sharper center peak; **negative** kurtosis (“light tails”) means fewer extremes and a flatter, broader peak.

When we compute these from a **sample**, we get **estimates** with **standard errors**. As a rough rule: if an estimate is within about $\pm 2$ **standard errors of zero**, there is **no strong evidence** of skewness or extra tail weight; if it is **more than** $2$ **standard errors** away, that suggests **positive/negative skew** or **heavier/lighter tails** in that direction.

::: callout-warning
**Use with care.** Skewness and kurtosis are **sensitive to outliers** and can be unstable in **small samples**.

**Tip:** Treat them as **supporting evidence**, and always pair with plots (histogram/density and a QQ-plot) before drawing conclusions.
:::

::: callout-note
Some software reports **“excess kurtosis”** (Normal = 0), others report **kurtosis** (Normal = 3). Check which convention your output uses.
:::

```{webr-r}
x <- mpg$hwy

library(moments)
moments::skewness(x) 

# OR

library(e1071)
e1071::skewness(x) 
```

```{webr-r}
library(moments)
moments::kurtosis(x) 

# OR

library(e1071)
e1071::kurtosis(x) 
```

See this [link](https://www.r-bloggers.com/2020/11/skewness-and-kurtosis-in-statistics/) for more examples in R about skewness and kurtosis.

**Extremes and outliers**

**Extremes** are simply the **minimum** and **maximum** (and other high/low quantiles). They’re expected in any sample.

```{webr-r}
x <- mpg$hwy

min(x, na.rm = TRUE)
max(x, na.rm = TRUE)
```

**Outliers** are observations **unusually far** from the bulk **relative to a rule or model** (context matters).

**Tukey’s rule** flags an observation as a **mild outlier** if it lies below **Q1 − 1.5×IQR** or above **Q3 + 1.5×IQR**, and as an **extreme outlier** if it lies beyond **Q1 − 3×IQR** or **Q3 + 3×IQR**.

```{webr-r}
# Tukey outliers using 1.5*IQR rule
Q <- quantile(x, probs = c(.25, .75), na.rm = TRUE, names = FALSE)
iqr <- Q[2] - Q[1]
lower <- Q[1] - 1.5 * iqr
upper <- Q[2] + 1.5 * iqr
c(lower = lower, upper = upper)

# Values flagged as outliers by this rule
outliers <- x[x < lower | x > upper]
outliers
```

:::: panel-tabset
### Exercise

In the dataset `mpg`,

1.  Compute the **mean** and **median** of `cty`. Which is larger? What does that suggest about skew?

    ```{webr-r}

    ```

2.  For `displ` (engine displacement), report **SD** and **IQR**. Which would you prefer if the distribution is skewed? Why?

    ```{webr-r}

    ```

3.  Find the modal category of `drv` (f/r/4). Also report proportions.

    ```{webr-r}

    ```

4.  Compute **skewness** and **kurtosis** for `hwy`, `cty`, and `displ`. Which looks most skewed? Which has the heaviest tails?

    ```{webr-r}

    ```

5.  For `cty`, compute **min/max** and identify outliers using the **1.5×IQR** rule. How many outliers?

    ```{webr-r}

    ```


### Solutions

<!--
::: {.solution exercise="ex_1"}
``` r
# 1
mean(mpg$cty, na.rm = TRUE)
median(mpg$cty, na.rm = TRUE)
skewness(mpg$cty)

#2 
sd(mpg$displ, na.rm = TRUE)
IQR(mpg$displ, na.rm = TRUE)

#3 
tab <- table(mpg$drv)
names(tab)[tab == max(tab)]
prop.table(tab)

# 4
vars <- c("hwy","cty","displ")
sapply(mpg[vars], skewness)
sapply(mpg[vars], kurtosis_excess)


# 5
x <- mpg$cty
min(x, na.rm = TRUE); max(x, na.rm = TRUE)
Q <- quantile(x, c(.25,.75), na.rm = TRUE); iqr <- diff(Q)
lower <- Q[1] - 1.5*iqr; upper <- Q[2] + 1.5*iqr
which(x < lower | x > upper)
length(which(x < lower | x > upper))
```
:::
-->
::::

**Multivariate Case**

**Cross-tabulation** is the basic non-graphical way to study the relationship between two (or more) variables. For two categorical variables, make a two-way table of **counts**, and (depending on your question) add **row %** (each row sums to 100), **column %** (each column sums to 100), and/or **cell %** (table sums to 100). You can extend this to a third variable by producing one two-way table **at each level** of the third variable (or by using a three-way contingency table).

```{webr-r}
# Data
data("mpg", package = "ggplot2")

# Two-way cross-tab: vehicle class (rows) by drive type (columns)
tab <- table(mpg$class, mpg$drv)   # counts
tab
addmargins(tab)                    # add row/col totals

# Percentages
cell_pct <- round(100 * prop.table(tab), 1)   # over all cells
row_pct  <- round(100 * prop.table(tab, 1), 1) # within rows
col_pct  <- round(100 * prop.table(tab, 2), 1) # within columns

cell_pct
row_pct
col_pct

# Treat a quantitative-with-few-levels variable as categorical (e.g., cylinders)
tab_cyl_drv <- table(factor(mpg$cyl), mpg$drv)
tab_cyl_drv
round(100 * prop.table(tab_cyl_drv, 1), 1)  # row %

# Three-way cross-tab: class × drv by model year (1999 vs 2008)
tab3 <- xtabs(~ class + drv + year, data = mpg)   # 3D table
ftable(tab3)                                      # flat view

# Row % within each year
by_year_rowpct <- lapply(split(mpg, mpg$year), function(d) {
  round(100 * prop.table(table(d$class, d$drv), 1), 1)
})
by_year_rowpct$`1999`
by_year_rowpct$`2008`

```

**Associations**

In EDA, we often want to ask *Is one variable associated with another?*

This can be for:

-   Two numeric variables

-   Two categorical variables

-   One numeric and one categorical

**Pairs of Numeric Variables**

The most common way to measure association between two numeric variables is:

**Pearson's Correlation Coefficient**

-   Measures **Strength** and **direction** of a **linear relationship**.

-   Values range from $-1$ to $+1$:

    -   $+1$: Perfect positive linear association

    -   $-1$: Perfect negative linear association

    -   $0$: no linear relationship

::: callout-important
Person's $r$ only measures **linear** relationships.
:::

::: callout-caution
If the relationship is **curved**, $r$ can be misleading. See [Anscombe’s Quartet](https://en.wikipedia.org/wiki/Anscombe%27s_quartet) for famous examples.
:::

**Rank Correlations: For Non-linear Relationships**

If the relationship is not linear, use a **rank correlation**:

| Method                | Notes                          |
|-----------------------|--------------------------------|
| **Spearman’s** $\rho$ | More sensitive to **outliers** |
| **Kendall’s** $\tau$  | Better for **ordinal data**    |

These methods:

-   convert data into **ranks** (1st, 2nd, 3rd, ...)

-   Measure how well the ranks agree between two variables

They are interpreted like Pearson's $r$:

-   Close to $\pm 1$ means strong association

-   $0$ means no association

**Pairs of Categorical Variables**

For two categorical variables, we ask *Are certain combinations of categories more or less common than expected?*

The most basic tool is the **contingency table**. It counts how many times each combination of categories appears in the data.

This table helps us to answer questions like:

-   Do some combinations occur more often than others?

-   Are the two categorical variables associated?

**Example:** **Penguins Species and Islands**\
Imagine we observed $344$ penguins from three species on three islands. We record how many penguins of each species were found on each island.

| **Species**   | **Biscoe** | **Dream** | **Torgersen** | **Total** |
|---------------|------------|-----------|---------------|-----------|
| **Adelie**    | 44         | 56        | 52            | 152       |
| **Chinstrap** | 0          | 68        | 0             | 68        |
| **Gentoo**    | 124        | 0         | 0             | 124       |
| **Total**     | 168        | 124       | 52            | 344       |

This table tells us:

**Summary of Correlation and Association Measures in R**

This table shows which association or correlation measure to use depending on the types of variables, along with the appropriate R function.

| Variable Types | Measure | Interpretation | R Function / Package |
|------------------|------------------|------------------|------------------|
| **Numeric – Numeric** | **Pearson’s r** | Strength of **linear** relationship | `cor(x, y, method = "pearson")` |
| **Numeric – Numeric** | **Spearman’s ρ** | Strength of **monotonic** relationship | `cor(x, y, method = "spearman")` |
| **Numeric – Numeric** | **Kendall’s τ** | Rank-based measure; robust to ties | `cor(x, y, method = "kendall")` |
| **Ordinal – Ordinal** | **Spearman’s ρ** or **Kendall’s τ** | Association between ranks | Same as above |
| **Nominal – Nominal (2×2)** | **Phi (φ) coefficient** | Association between two binary variables | `psych::phi(table)` |
| **Nominal – Nominal (k×m)** | **Cramér’s V** | Strength of association in contingency table | `rcompanion::cramerV(table)` or `DescTools::CramerV(table)` |
| **Nominal – Numeric** | **Eta (η) coefficient** | How much variance in numeric var is explained by group | `DescTools::EtaSq(aov(y ~ group))` |
| **Binary – Binary** | **Tetrachoric correlation** | For binary variables assumed to reflect latent continuous variables | `psych::tetrachoric(table)$rho` |
| **Ordinal – Nominal** | *(No standard measure)* | Use visual summaries or grouped statistics | `table()`, `ggplot2::geom_bar()`, `mosaicplot()` |

------------------------------------------------------------------------

**Notes**

-   **Spearman’s ρ** and **Kendall’s τ** both work well for **ranked data** and are more robust to non-linear trends than Pearson’s r.
-   **Cramér’s V** is used for **nominal data**, and its values range from 0 to 1.
-   **Eta squared (η²)** measures how much of the variance in the numeric variable is explained by the group (nominal) variable.
-   For **ordinal + nominal**, no widely accepted coefficient exists; focus on visual summaries (e.g., bar charts or stacked plots).

------------------------------------------------------------------------

**Example: What Should You Use?**

| Situation                       | Use                      |
|---------------------------------|--------------------------|
| Height vs Weight                | Pearson’s r              |
| Exam Rank vs Satisfaction Level | Kendall’s τ              |
| Eye Color vs Blood Type         | Cramér’s V               |
| Gender vs Income                | ANOVA + Boxplot          |
| Plant Type vs Size Category     | Cross-tab or Mosaic Plot |

These summaries help us compare groups and form initial impressions (for example, the mean suggests a “typical” value). **But a few numbers can not tell the whole story**—different datasets can share the same mean and spread yet look very different, so always pair numbers with plots and context.

#### Graphical Summaries

Graphs help us **see patterns**, **spot outliers**, and **understand distributions**.

Common EDA plots include: - **Histograms** – show the shape and spread of a numeric variable - **Boxplots** – show center, spread, and outliers - **Bar charts** – show frequencies of categories - **Scatterplots** – show relationships between two numeric variables

Graphs are **easier to understand** than tables of numbers. They help us and others **see what’s going on** in the data.

::: {.callout-caution appearance="minimal"}
<!--

nomial: What we can do:

Count frequencies (e.g. how many students are from each city)

Use bar charts or pie charts

ordinal What we can do:

Count frequencies

Compare medians

Use bar charts or ordered plots

ratio What we can do:

All descriptive statistics

Use histograms, box-plots, scatterplots

interval What we can do:

calculate mean, standard deviation

plot histograms or line charts

-->
:::

##### Principles of Analytic Graphics

Based on [@Tufte2006], there are six key principles for designing informative and effective graphs.

**Principle 1 – Show Comparison**

::: {.callout-caution appearance="simple" icon="false"}
Showing comparisons is really the basis of all good scientific investigation. [@Peng2012]
:::

Good data analysis always involves **comparing** things. A single number or result doesn’t mean much on its own. We need to ask:

::: {.callout-important appearance="simple" icon="false"}
Compared to what?
:::

For example, if we see that children with air cleaners had more symptom-free days, that sounds good. But how do we know the air cleaner made the difference? We only know that **by comparing** to another group of children who didn’t get the air cleaner. When we add that comparison, we can see that the control group didn’t improve — so the improvement likely came from the air cleaner.

![Change in symptom-free days with air cleaner. Source: \@Peng2012](/figs/EDA/EDA-P1-a.png){fig-align="center"}

![Change in symptom-free days with air cleaner. Source: \@Peng2012](/figs/EDA/EDA-P1-a.png){#figEDA1 fig-align="center"}

![Change in symptom-free days by treatment group. Source: \@Peng2012](/figs/EDA/EDA-P1-b.png){#figEDA2 fig-align="center"}

Good data graphics should always show **at least two things** so we can compare and understand what’s really happening.

**Principle 2: Show Causality and Explanation**

When making a data graphics, it is helpful to show **why** you think something is happening – not just what is happening. Even if you can not prove a cause, you can show your **hypothesis** of **idea** about how one thing might lead to another.

::: {.callout-caution appearance="minimal"}
If possible, it is always useful to show your causal framework for thinking about a question. [@Peng2012]

<!-- # Generally, it is difficult to prove that one thing causes another thing even with the most carefully collected data.  But it is still often useful for your data graphics to indicate what you are thinking about in terms of cause. Such a display may suggest hypotheses or refute them, but most importantly, they will raise new questions that can be followed up with new data or analyses. -->
:::

For example, in [#figEDA2](#figEDA2) we saw that children with an air cleaner had more symptom–free days. But that alone does not explain **why**. A good follow-up question is: "*Why did the air cleaner help?"* One possible reason is that air cleaners reduce **fine particles** in the air – especially in homes with smokers. Breathing in these particles can make asthma worse, so removing them might help children feel better. To show this, we can make a new plot.

![Change in symptom-free days and change in PM2.5 levels in-home. Source: @Peng2012](/figs/EDA/EDA-P2.png){fig-align="center"}

From the plot, we can see:

-   Children with air cleaners had more symptom-free days.

-   Their homes also had **less PM2.5** after six months.

-   In contrast, the control group had little improvement.

This **pattern supports** the idea that air cleaners work by reducing harmful particles — but it is not final proof. Other things might also cause the change, so more data and careful studies are needed to confirm.

**Principle 3: Show Multivariate Data**

::: {.callout-caution appearance="minimal" icon="false"}
The real world is multivariate. [@Peng2012]
:::

In real life, most problems involve **more than one or two variables**. We call this **multivariate data**. Good data graphics should try to show these multiple variables at the same time, instead of reducing everything to just one number or a simple trend.

Let us look at an example.

The `mtcars` dataset contains information about 32 car models from the 1970s. Each row is a car and each column is a variable. Some of these variables are: `mpg`: miles per gallon (fuel efficiency), `wt`: weight (in 1000 lbs), `cyl`: number of cylanders (engine size), `hp`: horse power, `qsec`: 1/4 mile time (acceleration), `am`: Transmission (0 = auto, 1 = manual). These variables help us to explore relationship between engin size, weight, fuel use, and more.

```{webr-r}
data("mtcars")
head(mtcars)
```

We want to know how a car's weight affects its fuel efficiency (miles per gallon). We look at a simple scatter plot of these two variables.

```{webr-r}
library(ggplot2)

ggplot(mtcars, aes(x = wt, y = mpg)) + 
  geom_point(color = 'blue', size = 3) + 
  geom_smooth(method = 'lm', se = FALSE, color = 'red') + 
  labs(x = 'weight (1000 lbs)',
       y = 'Miles per Gallon (MPG)') + 
  theme_minimal()
```

Heavier cars tend to have lower fuel efficiency. But is weight the only thing affecting fuel use?

Cars also have different engine sizes, measured by cylinders (`cyl`). This affects both weight and fuel efficiency. To understand the relationship better, we add `cyl` as a third variable by coloring points by the number of cylinders.

```{webr-r}
mtcars$cyl <- factor(mtcars$cyl)

ggplot(mtcars, aes(x = wt, y = mpg, color=cyl)) + 
  geom_point(size = 3) + 
  geom_smooth(method = 'lm', se = FALSE, aes(group = cyl)) + 
  labs(x = 'Weight (1000 lbs)',
       y = 'Miles per Gallon (MPG)', 
       color = "Number of cylinders") + 
  theme_minimal()
```

Now, we see that cars with 4, 6, and 8 cylinders have different trends. The overall pattern changes once we include this third variable.

::: callout-caution
The number of cylinders **cofounds** the relationship – it influences both weight and MPG.
:::

To understand how the number of cylinders changes the relationship between weight and fuel efficiency, we can make separate plots for each cylinder group. This is called **faceting**.

```{webr-r}
ggplot(mtcars, aes(x = wt, y = mpg)) + 
  geom_point() + 
  geom_smooth(method = 'lm', se = FALSE) +
  facet_wrap(~ cyl) + 
  labs(title = 'MPG vs. Weight by Cylinder Group')
```

::: callout-important
Sometimes, looking at groups separately helps us find clearer patterns that get lost in a big mixed dataset.
:::

Even, we can add the variable transmission(`am`) as an additional variable by using shapes or facet.

```{webr-r}
# Prepare the data
mtcars$cyl <- factor(mtcars$cyl)  
mtcars$am <- factor(mtcars$am, labels = c("Automatic", "Manual"))  

ggplot(mtcars, aes(x = wt, y = mpg, color = cyl, shape = am)) +
  geom_point(size = 3) +
  geom_smooth(method = "lm", se = FALSE, aes(group = cyl), linetype = "solid") +
  labs(
    x = "Weight (1000 lbs)",
    y = "Miles per Gallon (MPG)",
    color = "Cylinders",
    shape = "Transmission"
  ) +
  theme_minimal()

```

```{webr-r}
mtcars$cyl <- factor(mtcars$cyl)
mtcars$am <- factor(mtcars$am, labels = c('Automatic', 'Manual')) 


ggplot(mtcars, aes(x = wt, y = mpg, color = cyl)) + 
  geom_point(size = 3) + 
  geom_smooth(method = 'lm', se = TRUE, aes(group = cyl)) + 
  facet_wrap(~ am) + 
  labs(
    x = 'Weight (1000 lbs)',
    y = 'Miles per Gallon (MPG)',
    color = 'Cylinders'
  ) + 
  theme_minimal()
```

Now, each panel shows either automatic automatic or manual cars. Within each panel, colors show the number of cylinders.

Even we can use `facet_grid` that allows us to split the plot into rows and columns based on two categorical variables – perfect for showing how relationships vary across combinations. We will use `am` in rows and `cyl` in columns.

```{webr-r}
mtcars$cyl <- factor(mtcars$cyl)
mtcars$am <- factor(mtcars$am, labels = c('Automatic', 'Manual'))

ggplot(mtcars, aes(x = wt, y = mpg)) + 
  geom_point(aes(color = cyl), size = 3) + 
  geom_smooth(method = 'lm', se = FALSE, color = 'black') +
  facet_grid(am ~ cyl) + 
  labs(
    x = 'Weight (1000 lbs)',
    y = 'Miles per Gallon (MPG)',
    color = 'Cylinders'
  ) 
```

This way, we can see how the relationship between weight and MPG changes in each group combination.

**Principle 4: Integrate Evidence — Keep the message clear**

When you make a graph, *do not rely* on points and lines to show your idea. You can also use: **Numbers** to give exact values, **Words or short labels** to explain what is happening, **Pictures or diagrams** to give context.

::: callout-important
A good graph tells a complete story.
:::

Use all tools you need – not just the ones your software gives you easily.

::: callout-important
The goal is **not to just make a nice picture,** but to help people understand your message clearly.
:::

**Principle 5: Describe and Document the Evidence**

A good graph tells a story – clearly and completely. That means it should include:

-   A clear **title**

-   Labels for the **x-axis** and **y-axis**

-   Units for measurement (e.g. 'weights in 1000 lbs')

-   Time scale if needed (e.g. 'daily', 'monthly')

-   where the data comes from (e.g., 'New York', 'EPA')

-   source of the data

::: callout-tip
Imagine someone looking only at your plot without reading anything else. **Can they understand the main idea?** if yes – your plot is doing a good job.
:::

::: callout-note
Even if your graph is not *final*, it is a good habit to label things early. It helps you and others understand what is going on.
:::

For example, instead of using

```{r}
#| eval: false
#| include: false
plot(x, y)
```

try this

```{r}
#| eval: false
#| include: false
plot(x, y,
     xlab = "Weight (1000 lbs)",
     ylab = "Fuel efficiency (Miles per Gallon)",
     main = "Number of Deaths")
```

when we use `ggplot2`, it is better to add `labs()` like we did until now.

**Principle 6: Content is King**

::: callout-important
A beautiful plot means nothing if the **question is weak** or the d**ata is poor.**
:::

Data graphics are only powerful when:

-   the **question is clear and important**

-   the **data is high quality and relevant**

-   the **evidence supports the question**

No chart or fancy design can fix a bad question or messy data. That is why it is crucial to start with a strong idea and only show what really matters to answer that idea.

::: callout-tip
Do not just decorate your data – focus on the message!
:::

## Airquailty dataset

We will explore the `airquality` dataset, which contains daily measurement of air pollutants and weather conditions in New York City May to September 1973.

**Step 1 –** *How do ozone levels vary across different months in New York during the summer in 1973?*

This question is specific and focused: *One location (New York), One variable (ozone), one year and a defined time window (May to September)*

**Step 2 –** The `airquality` dataset is built into R. Load it with:

```{webr-r}
data("airquality")
airquality
```

**Step 3 –** Check the size and dimension of the dataset

```{webr-r}
dim(airquality)

# or 
nrow(airquality)
ncol(airquality)
```

**Step 4 –** run `str()`

```{webr-r}
str(airquality)
```

::: callout-caution
There are some missing values (`NA` , Not Available) in the dataset.
:::

**Step 5 –**

```{webr-r}
head(airquality)
```

```{webr-r}
tail(airquality)
```

**Step 6 –**

First, we count how many rows (i.e., records or observations) are in the dataset.

```{webr-r}
nrow(ozone)
```

Missing values (denoted as `NA` in R) can lead to incorrect calculations or unexpected results. It is good practice to check how many missing values there are per variable.

```{webr-r}
colSums(is.na(ozone))
```

**Using \`dplyr\`**

```{webr-r}
library(dplyr)

airquality |> 
  summarise(across(everything(), ~sum(is.na(.))))
```

This command uses `across()` to apply the same function to all columns, and `sum(is.na(.))` to count the number of missing values per column.

::: callout-tip
**What is \~ ?**

The `~` introduces an **anonymous function** — a function written inline without a name.

This

```{r}
~ sum(is.na(.))
```

is a shorthand for

```{r}
function(x) sum(is.na(x))
```
:::

Or, we can check how many rows are from July:

```{webr-r}
airquality |> 
  filter(Month == 7) |> nrow()
```

check how many missing values are just in August.

```{webr-r}
airquality |> 
  filter(Month == 8) |> 
  summarise(across(everything(), ~ sum(is.na(.))))
```

**Step 7 –** According to the U.S. EPA, ozone levels above 70 parts per billion (ppb) may be considered unhealthy.

```{webr-r}
summary(airquality$Ozone)
```

Based on the output, many days have safe levels and some days have extremely high ozone levels.

**Step 8 –** Let us check the average ozone level by month:

```{webr-r}
library(dplyr)

airquality |> 
  group_by(Month) |> 
  summarise(avg_ozone = mean(Ozone, na.rm = TRUE))
```

This gives a quick overview of how ozone levels change over the summer. Let visualize it:

```{webr-r}
library(ggplot2)

ggplot(airquality, aes(x = factor(Month), y = Ozone)) + 
  geom_boxplot(fill = 'lightblue', color = 'black', na.rm = TRUE) +
  scale_x_discrete(labels = c("May", "June", "July", "August", "September")) +
  labs(x = "Month",
       y = 'Ozone (ppb)') + 
  theme_minimal()
```

Based on the plot, we observe that July and August have the highest median ozone levels, showing that typical ozone concentrations were significantly higher during mid-summer. This suggests a seasonal pattern, likely driven by higher temperatures and increased sunlight, which promote the formation of ozone. The taller boxes and whiskers for these months reflect a greater variability in ozone levels, including several high outliers. In contrast, May and September show lower median values and less variation, possibly due to cooler temperatures and different atmospheric conditions. The median ozone level is June is slightly higher than in May but lower than in July, with a moderate level of variability. Overall, this seasonal trend is consistent with environmental science – **ozone forms more easily in strong sunlight and warm conditions**, which are more prevalent in July and August.

**Step 9 –** Let us examine whether temperature or wind speed might help explain ozone patterns.

```{webr-r}
library(ggplot2)

ggplot(airquality, aes(x = Temp, y = Ozone)) + 
  geom_point(color = 'darkgreen', alpha = 0.8) + 
  labs(x = 'Temperature (°F)',
       y = 'Ozone (ppb)') + 
  theme_minimal()
```

```{webr-r}
ggplot(airquality, aes(x = Wind, y = Ozone)) +
  geom_point(color = "darkblue", alpha = 0.8) +
  labs(title = "Ozone vs Wind Speed",
       x = "Wind Speed (mph)",
       y = "Ozone (ppb)") +
  theme_minimal()
```

You may observe that there is a *positive* relationship between temperature and ozone and a *negative* relationship between wind speed and ozone. These patterns support common environmental science findings.

**Step 10 –** Based on our findings, we might fit a simple regression model

```{webr-r}
model <- lm(Ozone ~ Temp + Wind, data = airquality)
summary(model)
```

We might also refine our question: *On which days was the ozone level unusually high, and what were the weather conditions on those days?*

Alternative question

***Step 1 – Which weather factor—temperature, wind, or solar radiation—has the strongest relationship with ozone levels during the summer of 1973 in New York?***

This question is more analytical than descriptive, and focused on **relationships** between variables. So, we need to examine how ozone changes with respect to other variables.

**Step 2 –**

```{webr-r}
data("airquality")
```

**Step 3 –**

```{webr-r}
airquality  |>  
  summarise(rows = n())  |>  
  mutate(cols = ncol(airquality))
```

**Step 4 –**

```{webr-r}
airquality |> 
  glimpse()
```

**Step 5 –**

```{webr-r}
airquality |> 
  slice_head(n = 5)
```

```{webr-r}
airquality |> 
  slice_tail(n = 5)
```

**Step 6 –**

```{webr-r}
ozone_clean <- airquality |> 
  filter(!is.na(Ozone), !is.na(Temp), !is.na(Wind), !is.na(Solar.R))

ozone_clean |> 
  summarise(rows = n())
```

**Step 7 –**

Check how often ozone exceeds EPA's 70 ppb guideline:

```{webr-r}
ozone_clean |> 
  summarise(above_70 = sum(Ozone > 70), 
            total = n(), 
            percent = round(100 * sum(Ozone > 70) / n(), 1))
```

**Step 8 –**

Since `dplyr` does not include a `cor()` function, we will compute correlations manually using `summarise()` and `cor()` from base R, keeping within tidy pipelines:

```{webr-r}
ozone_clean |> 
  summarise(cor_temp = cor(Ozone, Temp),
            cor_wind = cor(Ozone, Wind),
            cor_solar = cor(Ozone, Solar.R))
```

```{webr-r}
ggplot(ozone_clean, aes(x = Temp, y = Ozone)) + 
  geom_point(color = "steelblue") + 
  labs(x = "Temperature (F)",
       y = "Ozone (ppb)") + 
  theme_minimal()
```

```{webr-r}
ggplot(ozone_clean, aes(x = Wind, y = Ozone)) + 
  geom_point(color = 'darkgreen') + 
  labs(x = "Wind (mph)",
       y = "Ozone (ppb)") + 
  theme_minimal()
```

```{webr-r}
ggplot(ozone_clean, aes(x = Solar.R, y = Ozone)) + 
  geom_point(color = 'orange') + 
  labs(x = "Solar Radiation (langley)",
       y = "Ozone (ppb)") + 
  theme_minimal()
```

**More advanced:**

```{webr-r}
# install.packages("patchwork")
library(patchwork)

p1 <- ggplot(ozone_clean, aes(Temp, Ozone)) + 
  geom_point(color = "steelblue") + 
  labs(title = "Ozone vs Temp", x = "Temperature", y = "Ozone") + 
  theme_minimal()

p2 <- ggplot(ozone_clean, aes(Wind, Ozone)) + 
  geom_point(color = "darkgreen") + 
  labs(title = "Ozone vs Wind", x = "Wind Speed", y = "Ozone") + 
  theme_minimal()

p3 <- ggplot(ozone_clean, aes(Solar.R, Ozone)) + 
  geom_point(color = "orange") + 
  labs(title = "Ozone vs Solar Radiation", x = "Solar Radiation", y = "Ozone") + 
  theme_minimal()

(p1 | p2 | p3)

```

But sometimes, a simple code gives the more informative output:

```{webr-r}
cor(ozone_clean)
```

visualize the relationships:

```{webr-r}
pairs(ozone_clean, 
      main = "Ozone vs. Weather Variables",
      col = 'darkred', pch = 19)
```

**Step 9 –**

```{webr-r}
model <- ozone_clean  |> 
  lm(Ozone ~ Temp + Wind + Solar.R, data = .)

summary(model)

```

When we check p-values and coefficients, we see `Temp` has strong and significant positive effect, `Wind` has strong and significant negative effect, and `Solar.R` has weaker effect but still contributes.

**Step 10 –**

Now we know temperature has the strongest effect on ozone levels:

-   Should we check for nonlinear effects (e.g., does ozone spike at high temps)?

-   Would a time-based model (e.g. by day or month) add insight?

-   What is the temperature threshold where ozone exceeds 70 ppb?

-   Are there interactions between variables (e.g. high temp + low wind)?

-   Do results change if the we include time (e.g. month)?

We might now refine our question: *How much does temperature need to rise before ozone levels exceed the 70 ppb threshold?*

As Tukey emphasized, EDA is about "detecting the unexpected" and **learning from the data before attempting to explain it**.

:::: callout-tip
At the beginning, it is hard to ask the *perfect* question because you do not know the date well yet. But here is the secret:

::: {.callout-important appearance="minimal" icon="false"}
The more questions you ask, the better your questions become.
:::
::::

Each time you explore one idea, it leads to a **new question.** That is how you:

-   Discover patterns

-   Notice surprises

-   Understand your data more deeply

::: callout-caution
Good EDA is like this

1.  Ask a question

2.  Make a plot or summary

3.  Look at the result

4.  Ask a new, better question

5.  Repeat!
:::

::: callout-tip
Do not wait for the perfect question - **just start**. Exploration will lead you to insight.
:::
