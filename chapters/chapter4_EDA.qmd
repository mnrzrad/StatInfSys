---
engine: knitr
filters: 
  - webr
---

# Exploratory data analysis (EDA)

## What is EDA?

Exploratory data analysis (EDA) was first formally introduced by @Tukey1977 in his influential 1977 book, *Exploratory Data Analysis.* Since then, its importance has grown significantly, especially in recent years, for several key reasons: i) data is being produced faster and in larger volumes than ever before, ii) modern computing and software tools make it easier to explore, clean, and visualize data in meaningful ways, iii) contemporary statistical models are often complex and assumption-dependent, requiring us to thoroughly understand the data before applying formal techniques. [@Midway2022]

The EDA may not be fully described in concrete terms, but most data analysts and statisticians know it when they see it.

::: callout-important
The EDA is important because it helps researchers make thoughtful decisions about which ideas are worth exploring. Sometimes, the data clearly show that a particular question does not have enough support to be studied further—at least not with the current evidence.
:::

The main goals of EDA are:

-   To suggest hypotheses about what might be causing the patterns or relationships observed in the data,

-   To guide the choice of appropriate statistical tools or models by helping you understand the structure of the data,

-   To assess key assumptions that must be checked before applying formal statistical analysis (e.g., linearity, normality, independence),

-   To provide a basis for further data collection, by highlighting gaps, inconsistencies, or areas where more information is needed.

::: callout-note
EDA is not typically the final stage of analysis. Rather, it serves as a **transitional step between raw data and formal modeling**. The insights gained through EDA guide decisions about which models to use, which variables to consider, and which data issues to address.
:::

::: callout-important
## EDA Checklist

Roger D. Peng in his book [@Peng2012] provide this checklist for conducting EDA.

1.  **Start with a clear question:** Before you begin EDA, take time to define exactly what you want to find out. A clear question or hypothesis gives your analysis purpose and helps you stay focused along the way.

2.  **Load your data carefully:** Make sure your dataset is fully and correctly loaded into your analysis tool (e.g., R or Python). This first step is essential—it sets the stage for everything you will do next.

3.  **Take a first look at the data:** Check that the file type, structure, and layout are what you expected. Make sure everything is organized in a way that works for your analysis.

4.  **Use `str()` to Peek Inside the Dataset:** In R, it will get a quick summary: number of observations (rows), number and names of variables (columns), variable types (e.g., numeric, character, factor), and a preview of the data values

5.  **Look at the Beginning and End of Your Data:** Use functions such as `head()` and `tail()` to view the first and last few rows. This visual check can help to detect issues such as incorrect headers, blank rows, or unusual formatting.

6.  **Check the Number of Rows ("n"):** Make sure to verify how many observations (rows) are in your dataset. Compare this to what you expected from the original. source. If the number is too high or too low, there may be missing values, duplicate entries, or extra rows (e.g. duplicates or blank lines).

7.  **Validate with an External Source:** When possible, compare part of your dataset with a trusted external source, such as official statistics or published reports. This helps confirm the accuracy and reliability of your data.

8.  **Try the Simple Solution First:** Start by basic methods–such as summaries, tables, or visualizations– to explore and answer your question. Simple tools can often reveal key patterns or issues. Use more complex techniques only of necessary.

9.  **Challenge Your Findings:** Once you find a result, pause and ask yourself: *Does this make sense?* Check your assumptions and consider possible errors or missing information. Being critical helps make your results stronger and more trustworthy.

10. **Decide What to Do Next:** Use the insights from your EDA to guide your next steps. You may decide to collect more data, use new methods, or refine your question. Sometimes , your initial findings are already enough to answer your main question.

In Chapter 4 of @Midway2022, interested reader can find some comments for each step.
:::

::: callout-important
EDA is the single most important task to conduct at the beginning of every data science project.
:::

::: callout-tip
EDA is like exploring a new place – you do not know what you will find until you start looking.
:::

### Airquailty dataset

We will explore the `airquality` dataset, which contains daily measurement of air pollutants and weather conditions in New York City May to September 1973.

**Step 1 –** *How do ozone levels vary across different months in New York during the summer in 1973?*

::: callout-note
This question is specific and focused: *One location (New York), One variable (ozone), one year and a defined time window (May to September)*
:::

**Step 2 –** The `airquality` dataset is built into R. Load it with:

```{webr-r}
data("airquality")
airquality
```

**Step 3 –** Check the size and dimension of the dataset

```{webr-r}
dim(airquality)

# or 
nrow(airquality)
ncol(airquality)
```

**Step 4 –** run `str()`

```{webr-r}
str(airquality)
```

::: callout-caution
There are some missing values (`NA` , Not Available) in the dataset.
:::

**Step 5 –**

```{webr-r}
head(airquality)
```

```{webr-r}
tail(airquality)
```

**Step 6 –**

First, we count how many rows (i.e., records or observations) are in the dataset.

```{webr-r}
nrow(ozone)
```

Missing values (denoted as `NA` in R) can lead to incorrect calculations or unexpected results. It is good practice to check how many missing values there are per variable.

```{webr-r}
colSums(is.na(ozone))
```

:::: callout-note
## Using \`dplyr\`

```{webr-r}
library(dplyr)

airquality |> 
  summarise(across(everything(), ~sum(is.na(.))))
```

This command uses `across()` to apply the same function to all columns, and `sum(is.na(.))` to count the number of missing values per column.

::: callout-tip
## What is \~ ?

The `~` introduces an **anonymous function** — a function written inline without a name.

This

```{r}
~ sum(is.na(.))
```

is a shorthand for

```{r}
function(x) sum(is.na(x))
```
:::
::::

Or, we can check how many rows are from July:

```{webr-r}
airquality |> 
  filter(Month == 7) |> nrow()
```

check how many missing values are just in August.

```{webr-r}
airquality |> 
  filter(Month == 8) |> 
  summarise(across(everything(), ~ sum(is.na(.))))
```

**Step 7 –** According to the U.S. EPA, ozone levels above 70 parts per billion (ppb) may be considered unhealthy.

```{webr-r}
summary(airquality$Ozone)
```

Based on the output, many days have safe levels and some days have extremely high ozone levels.

**Step 8 –** Let us check the average ozone level by month:

```{webr-r}
library(dplyr)

airquality |> 
  group_by(Month) |> 
  summarise(avg_ozone = mean(Ozone, na.rm = TRUE))
```

This gives a quick overview of how ozone levels change over the summer. Let visualize it:

```{webr-r}
library(ggplot2)

ggplot(airquality, aes(x = factor(Month), y = Ozone)) + 
  geom_boxplot(fill = 'lightblue', color = 'black', na.rm = TRUE) +
  scale_x_discrete(labels = c("May", "June", "July", "August", "September")) +
  labs(x = "Month",
       y = 'Ozone (ppb)') + 
  theme_minimal()
```

Based on the plot, we observe that July and August have the highest median ozone levels, showing that typical ozone concentrations were significantly higher during mid-summer. This suggests a seasonal pattern, likely driven by higher temperatures and increased sunlight, which promote the formation of ozone. The taller boxes and whiskers for these months reflect a greater variability in ozone levels, including several high outliers. In contrast, May and September show lower median values and less variation, possibly due to cooler temperatures and different atmospheric conditions. The median ozone level is June is slightly higher than in May but lower than in July, with a moderate level of variability. Overall, this seasonal trend is consistent with environmental science – **ozone forms more easily in strong sunlight and warm conditions**, which are more prevalent in July and August.

**Step 9 –** Let us examine whether temperature or wind speed might help explain ozone patterns.

```{webr-r}
library(ggplot2)

ggplot(airquality, aes(x = Temp, y = Ozone)) + 
  geom_point(color = 'darkgreen', alpha = 0.8) + 
  labs(x = 'Temperature (°F)',
       y = 'Ozone (ppb)') + 
  theme_minimal()
```

```{webr-r}
ggplot(airquality, aes(x = Wind, y = Ozone)) +
  geom_point(color = "darkblue", alpha = 0.8) +
  labs(title = "Ozone vs Wind Speed",
       x = "Wind Speed (mph)",
       y = "Ozone (ppb)") +
  theme_minimal()
```

You may observe that there is a *positive* relationship between temperature and ozone and a *negative* relationship between wind speed and ozone. These patterns support common environmental science findings.

**Step 10 –** Based on our findings, we might fit a simple regression model

```{webr-r}
model <- lm(Ozone ~ Temp + Wind, data = airquality)
summary(model)
```

We might also refine our question: *On which days was the ozone level unusually high, and what were the weather conditions on those days?*

#### Alternative question

***Step 1 – Which weather factor—temperature, wind, or solar radiation—has the strongest relationship with ozone levels during the summer of 1973 in New York?***

This question is more analytical than descriptive, and focused on **relationships** between variables. So, we need to examine how ozone changes with respect to other variables.

**Step 2 –**

```{webr-r}
data("airquality")
```

**Step 3 –**

```{webr-r}
airquality  |>  
  summarise(rows = n())  |>  
  mutate(cols = ncol(airquality))
```

**Step 4 –**

```{webr-r}
airquality |> 
  glimpse()
```

**Step 5 –**

```{webr-r}
airquality |> 
  slice_head(n = 5)
```

```{webr-r}
airquality |> 
  slice_tail(n = 5)
```

**Step 6 –**

```{webr-r}
ozone_clean <- airquality |> 
  filter(!is.na(Ozone), !is.na(Temp), !is.na(Wind), !is.na(Solar.R))

ozone_clean |> 
  summarise(rows = n())
```

**Step 7 –**

Check how often ozone exceeds EPA's 70 ppb guideline:

```{webr-r}
ozone_clean |> 
  summarise(above_70 = sum(Ozone > 70), 
            total = n(), 
            percent = round(100 * sum(Ozone > 70) / n(), 1))
```

**Step 8 –**

Since `dplyr` does not include a `cor()` function, we will compute correlations manually using `summarise()` and `cor()` from base R, keeping within tidy pipelines:

```{webr-r}
ozone_clean |> 
  summarise(cor_temp = cor(Ozone, Temp),
            cor_wind = cor(Ozone, Wind),
            cor_solar = cor(Ozone, Solar.R))
```

```{webr-r}
ggplot(ozone_clean, aes(x = Temp, y = Ozone)) + 
  geom_point(color = "steelblue") + 
  labs(x = "Temperature (F)",
       y = "Ozone (ppb)") + 
  theme_minimal()
```

```{webr-r}
ggplot(ozone_clean, aes(x = Wind, y = Ozone)) + 
  geom_point(color = 'darkgreen') + 
  labs(x = "Wind (mph)",
       y = "Ozone (ppb)") + 
  theme_minimal()
```

```{webr-r}
ggplot(ozone_clean, aes(x = Solar.R, y = Ozone)) + 
  geom_point(color = 'orange') + 
  labs(x = "Solar Radiation (langley)",
       y = "Ozone (ppb)") + 
  theme_minimal()
```

**More advanced:**

```{webr-r}
# install.packages("patchwork")
library(patchwork)

p1 <- ggplot(ozone_clean, aes(Temp, Ozone)) + 
  geom_point(color = "steelblue") + 
  labs(title = "Ozone vs Temp", x = "Temperature", y = "Ozone") + 
  theme_minimal()

p2 <- ggplot(ozone_clean, aes(Wind, Ozone)) + 
  geom_point(color = "darkgreen") + 
  labs(title = "Ozone vs Wind", x = "Wind Speed", y = "Ozone") + 
  theme_minimal()

p3 <- ggplot(ozone_clean, aes(Solar.R, Ozone)) + 
  geom_point(color = "orange") + 
  labs(title = "Ozone vs Solar Radiation", x = "Solar Radiation", y = "Ozone") + 
  theme_minimal()

(p1 | p2 | p3)

```

But sometimes, a simple code gives the more informative output:

```{webr-r}
cor(ozone_clean)
```

visualize the relationships:

```{webr-r}
pairs(ozone_clean, 
      main = "Ozone vs. Weather Variables",
      col = 'darkred', pch = 19)
```

**Step 9 –**

```{webr-r}
model <- ozone_clean  |> 
  lm(Ozone ~ Temp + Wind + Solar.R, data = .)

summary(model)

```

When we check p-values and coefficients, we see `Temp` has strong and significant positive effect, `Wind` has strong and significant negative effect, and `Solar.R` has weaker effect but still contributes.

**Step 10 –**

Now we know temperature has the strongest effect on ozone levels:

-   Should we check for nonlinear effects (e.g., does ozone spike at high temps)?

-   Would a time-based model (e.g. by day or month) add insight?

-   What is the temperature threshold where ozone exceeds 70 ppb?

-   Are there interactions between variables (e.g. high temp + low wind)?

-   Do results change if the we include time (e.g. month)?

We might now refine our question: *How much does temperature need to rise before ozone levels exceed the 70 ppb threshold?*

::: callout-note
As Tukey emphasized, EDA is about "detecting the unexpected" and **learning from the data before attempting to explain it**.
:::

:::: callout-tip
At the beginning, it is hard to ask the *perfect* question because you do not know the date well yet. But here is the secret:

::: {.callout-important appearance="minimal" icon="false"}
The more questions you ask, the better your questions become.
:::
::::

Each time you explore one idea, it leads to a **new question.** That is how you:

-   Discover patterns

-   Notice surprises

-   Understand your data more deeply

::: callout-caution
Good EDA is like this

1.  Ask a question

2.  Make a plot or summary

3.  Look at the result

4.  Ask a new, better question

5.  Repeat!
:::

::: callout-tip
Do not wait for the perfect question - **just start**. Exploration will lead you to insight.
:::

## Principles of Analytic Graphics

Based on [@Tufte2006], there are six key principles for designing informative and effective graphs.

### Principle 1 – Show Comparison

::: {.callout-caution appearance="simple" icon="false"}
Showing comparisons is really the basis of all good scientific investigation. [@Peng2012]
:::

Good data analysis always involves **comparing** things. A single number or result doesn’t mean much on its own. We need to ask:

::: {.callout-important appearance="simple" icon="false"}
Compared to what?
:::

For example, if we see that children with air cleaners had more symptom-free days, that sounds good. But how do we know the air cleaner made the difference? We only know that **by comparing** to another group of children who didn’t get the air cleaner. When we add that comparison, we can see that the control group didn’t improve — so the improvement likely came from the air cleaner.

![Change in symptom-free days with air cleaner. Source: \@Peng2012](/figs/EDA/EDA-P1-a.png){fig-align="center"}

![Change in symptom-free days with air cleaner. Source: \@Peng2012](/figs/EDA/EDA-P1-a.png){#figEDA1 fig-align="center"}

![Change in symptom-free days by treatment group. Source: \@Peng2012](/figs/EDA/EDA-P1-b.png){#figEDA2 fig-align="center"}

Good data graphics should always show **at least two things** so we can compare and understand what’s really happening.

### Principle 2: Show Causality and Explanation

When making a data graphics, it is helpful to show **why** you think something is happening – not just what is happening. Even if you can not prove a cause, you can show your **hypothesis** of **idea** about how one thing might lead to another.

::: {.callout-caution appearance="minimal"}
If possible, it is always useful to show your causal framework for thinking about a question. [@Peng2012]

<!-- # Generally, it is difficult to prove that one thing causes another thing even with the most carefully collected data.  But it is still often useful for your data graphics to indicate what you are thinking about in terms of cause. Such a display may suggest hypotheses or refute them, but most importantly, they will raise new questions that can be followed up with new data or analyses. -->
:::

For example, in [#figEDA2](#figEDA2) we saw that children with an air cleaner had more symptom–free days. But that alone does not explain **why**. A good follow-up question is: "*Why did the air cleaner help?"* One possible reason is that air cleaners reduce **fine particles** in the air – especially in homes with smokers. Breathing in these particles can make asthma worse, so removing them might help children feel better. To show this, we can make a new plot.

![Change in symptom-free days and change in PM2.5 levels in-home. Source: @Peng2012](/figs/EDA/EDA-P2.png){fig-align="center"}

From the plot, we can see:

-   Children with air cleaners had more symptom-free days.

-   Their homes also had **less PM2.5** after six months.

-   In contrast, the control group had little improvement.

This **pattern supports** the idea that air cleaners work by reducing harmful particles — but it is not final proof. Other things might also cause the change, so more data and careful studies are needed to confirm.

### Principle 3: Show Multivariate Data

::: {.callout-caution appearance="minimal" icon="false"}
The real world is multivariate. [@Peng2012]
:::

In real life, most problems involve **more than one or two variables**. We call this **multivariate data**. Good data graphics should try to show these multiple variables at the same time, instead of reducing everything to just one number or a simple trend.

Let us look at an example.

The `mtcars` dataset contains information about 32 car models from the 1970s. Each row is a car and each column is a variable. Some of these variables are: `mpg`: miles per gallon (fuel efficiency), `wt`: weight (in 1000 lbs), `cyl`: number of cylanders (engine size), `hp`: horse power, `qsec`: 1/4 mile time (acceleration), `am`: Transmission (0 = auto, 1 = manual). These variables help us to explore relationship between engin size, weight, fuel use, and more.

```{webr-r}
data("mtcars")
head(mtcars)
```

We want to know how a car's weight affects its fuel efficiency (miles per gallon). We look at a simple scatter plot of these two variables.

```{webr-r}
library(ggplot2)

ggplot(mtcars, aes(x = wt, y = mpg)) + 
  geom_point(color = 'blue', size = 3) + 
  geom_smooth(method = 'lm', se = FALSE, color = 'red') + 
  labs(x = 'weight (1000 lbs)',
       y = 'Miles per Gallon (MPG)') + 
  theme_minimal()
```

Heavier cars tend to have lower fuel efficiency. But is weight the only thing affecting fuel use?

Cars also have different engine sizes, measured by cylinders (`cyl`). This affects both weight and fuel efficiency. To understand the relationship better, we add `cyl` as a third variable by coloring points by the number of cylinders.

```{webr-r}
mtcars$cyl <- factor(mtcars$cyl)

ggplot(mtcars, aes(x = wt, y = mpg, color=cyl)) + 
  geom_point(size = 3) + 
  geom_smooth(method = 'lm', se = FALSE, aes(group = cyl)) + 
  labs(x = 'Weight (1000 lbs)',
       y = 'Miles per Gallon (MPG)', 
       color = "Number of cylinders") + 
  theme_minimal()
```

Now, we see that cars with 4, 6, and 8 cylinders have different trends. The overall pattern changes once we include this third variable.

::: callout-caution
The number of cylinders **cofounds** the relationship – it influences both weight and MPG.
:::

To understand how the number of cylinders changes the relationship between weight and fuel efficiency, we can make separate plots for each cylinder group. This is called **faceting**.

```{webr-r}
ggplot(mtcars, aes(x = wt, y = mpg)) + 
  geom_point() + 
  geom_smooth(method = 'lm', se = FALSE) +
  facet_wrap(~ cyl) + 
  labs(title = 'MPG vs. Weight by Cylinder Group')
```

::: callout-important
Sometimes, looking at groups separately helps us find clearer patterns that get lost in a big mixed dataset.
:::

Even, we can add the variable transmission(`am`) as an additional variable by using shapes or facet.

```{webr-r}
# Prepare the data
mtcars$cyl <- factor(mtcars$cyl)  
mtcars$am <- factor(mtcars$am, labels = c("Automatic", "Manual"))  

ggplot(mtcars, aes(x = wt, y = mpg, color = cyl, shape = am)) +
  geom_point(size = 3) +
  geom_smooth(method = "lm", se = FALSE, aes(group = cyl), linetype = "solid") +
  labs(
    x = "Weight (1000 lbs)",
    y = "Miles per Gallon (MPG)",
    color = "Cylinders",
    shape = "Transmission"
  ) +
  theme_minimal()

```

```{webr-r}
mtcars$cyl <- factor(mtcars$cyl)
mtcars$am <- factor(mtcars$am, labels = c('Automatic', 'Manual')) 


ggplot(mtcars, aes(x = wt, y = mpg, color = cyl)) + 
  geom_point(size = 3) + 
  geom_smooth(method = 'lm', se = TRUE, aes(group = cyl)) + 
  facet_wrap(~ am) + 
  labs(
    x = 'Weight (1000 lbs)',
    y = 'Miles per Gallon (MPG)',
    color = 'Cylinders'
  ) + 
  theme_minimal()
```

Now, each panel shows either automatic automatic or manual cars. Within each panel, colors show the number of cylinders.

Even we can use `facet_grid` that allows us to split the plot into rows and columns based on two categorical variables – perfect for showing how relationships vary across combinations. We will use `am` in rows and `cyl` in columns.

```{webr-r}
mtcars$cyl <- factor(mtcars$cyl)
mtcars$am <- factor(mtcars$am, labels = c('Automatic', 'Manual'))

ggplot(mtcars, aes(x = wt, y = mpg)) + 
  geom_point(aes(color = cyl), size = 3) + 
  geom_smooth(method = 'lm', se = FALSE, color = 'black') +
  facet_grid(am ~ cyl) + 
  labs(
    x = 'Weight (1000 lbs)',
    y = 'Miles per Gallon (MPG)',
    color = 'Cylinders'
  ) 
```

This way, we can see how the relationship between weight and MPG changes in each group combination.

### Principle 4: Integrate Evidence — Keep the message clear

When you make a graph, *do not rely* on points and lines to show your idea. You can also use: **Numbers** to give exact values, **Words or short labels** to explain what is happening, **Pictures or diagrams** to give context.

::: callout-important
A good graph tells a complete story.
:::

Use all tools you need – not just the ones your software gives you easily.

::: callout-important
The goal is **not to just make a nice picture,** but to help people understand your message clearly.
:::

### Principle 5: Describe and Document the Evidence

A good graph tells a story – clearly and completely. That means it should include:

-   A clear **title**

-   Labels for the **x-axis** and **y-axis**

-   Units for measurement (e.g. 'weights in 1000 lbs')

-   Time scale if needed (e.g. 'daily', 'monthly')

-   where the data comes from (e.g., 'New York', 'EPA')

-   source of the data

::: callout-tip
Imagine someone looking only at your plot without reading anything else. **Can they understand the main idea?** if yes – your plot is doing a good job.
:::

::: callout-note
Even if your graph is not *final*, it is a good habit to label things early. It helps you and others understand what is going on.
:::

For example, instead of using

```{r}
#| eval: false
#| include: false
plot(x, y)
```

try this

```{r}
#| eval: false
#| include: false
plot(x, y,
     xlab = "Weight (1000 lbs)",
     ylab = "Fuel efficiency (Miles per Gallon)",
     main = "Number of Deaths")
```

when we use `ggplot2`, it is better to add `labs()` like we did until now.

### Principle 6: Content is King

::: callout-important
A beautiful plot means nothing if the **question is weak** or the d**ata is poor.**
:::

Data graphics are only powerful when:

-   the **question is clear and important**

-   the **data is high quality and relevant**

-   the **evidence supports the question**

No chart or fancy design can fix a bad question or messy data. That is why it is crucial to start with a strong idea and only show what really matters to answer that idea.

::: callout-tip
Do not just decorate your data – focus on the message!
:::
