---
engine: knitr
filters: 
  - webr
---

```{webr-r}
#| context: setup
library(tidyverse)
```

# Logistic Regression

A binary classification problem is one where the outcome variable can take on only two possible values. For example:

- will a loaner enter default or not, based on their credit score and income;
- will a driver be involved in an accident or not, based on their age, automobile age and driving history;
- will a patient have a heart attack or not, based on their cholesterol level and blood pressure, and other health indicators.

For this kind of problem, the dataset used to fit the model is composed of observations $(\mathbf{x}_1, y_1)$, $(\mathbf{x}_2, y_2)$, ..., $(\mathbf{x}_n, y_n)$ where each $y_i$ is usually labelled 0 (failure, no event, ...) or 1 (success, event, ...) and $\mathbf{x}_i$ is a vector of input variables.

The task at hand is to build a model that, given an arbitrary $\mathbf{x}$, will predict the probability that $y = 1$.

## Modelling Probabilities

Why not use a linear regression model to predict the probability that $y = 1$? After all, linear regression is a well-known and widely used method.

```{webr-r}
n <- 20
x <- runif(n)
y <- rbinom(n, 1, x)
ggplot(tibble(x, y), aes(x, y)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  labs(title = "",
       x = "x",
       y = "y")
```

There are some problems with this approach:

1. the output values are never (with probability 1) exactly 0 or 1, the values that are taken by $y$;
2. even considering a threshold (e.g. 0.5) to classify the predicted values into 0 or 1 if , this would be mostly an arbitrary chosen value.

Instead, we can opt to model the *probability* of success of the event described by $y$, i.e $\operatorname{P}(Y=1)$. This is a more sound and natural way to model the prediction of a random binary event.

A logistic function can be used to model the probability that $y = 1$ given $\mathbf{x}$.


```{webr-r}
ggplot(tibble(x, y), aes(x, y)) +
  geom_point() +
  geom_smooth(method = "glm", 
       method.args = list(family = "binomial"), 
       se = FALSE) +
  labs(title = "",
       x = "x",
       y = "y")
  
```

## Sigmoid Functions

A sigmoid function $f(x)$ is a mathematical function having an "S" shaped curve (sigmoid curve) with the following properties:

- $0<f(x)<1$;
- $\displaystyle \lim_{x \to -\infty} f(x) = 0$, $\displaystyle \lim_{x \to +\infty} f(x) = 1$;
- $f'(x)>0$.

A common sigmoid function is the logistic function, defined as:
$$f(x) = \frac{1}{1 + e^{-x}} = \frac{e^x}{1 + e^x}.$$
This function will play a central row in the logistic regression model, as we will see briefly.
