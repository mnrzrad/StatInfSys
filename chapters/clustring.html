<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.25">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>10&nbsp; Clustering – Statistics and Information Systems</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../chapters/chapter5_logistic_regression.html" rel="next">
<link href="../chapters/Decision_trees.html" rel="prev">
<script src="../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-7b89279ff1a6dce999919e0e67d4d9ec.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-0dd2bd5de344125cf763a379ddc3eb04.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/monaco-editor@0.47.0/min/vs/editor/editor.main.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.2/css/all.min.css">
  
<style type="text/css">
.monaco-editor pre {
  background-color: unset !important;
}

.qwebr-editor-toolbar {
  width: 100%;
  display: flex;
  justify-content: space-between;
  box-sizing: border-box;
}

.qwebr-editor-toolbar-left-buttons, .qwebr-editor-toolbar-right-buttons {
  display: flex;
}

.qwebr-non-interactive-loading-container.qwebr-cell-needs-evaluation, .qwebr-non-interactive-loading-container.qwebr-cell-evaluated {
  justify-content: center;
  display: flex;
  background-color: rgba(250, 250, 250, 0.65);
  border: 1px solid rgba(233, 236, 239, 0.65);
  border-radius: 0.5rem;
  margin-top: 15px;
  margin-bottom: 15px;
}

.qwebr-r-project-logo {
  color: #2767B0; /* R Project's blue color */
}

.qwebr-icon-status-spinner {
  color: #7894c4;
}

.qwebr-icon-run-code {
  color: #0d9c29
}

body.quarto-light .qwebr-output-code-stdout {
  color: #111;
}

body.quarto-dark .qwebr-output-code-stdout {
  color: #EEE;
}

.qwebr-output-code-stderr {
  color: #db4133;
}

body.quarto-light .qwebr-editor {
  border: 1px solid #EEEEEE;
}

body.quarto-light .qwebr-editor-toolbar {
  background-color: #EEEEEE;
  padding: 0.2rem 0.5rem;
}

body.quarto-dark .qwebr-editor {
  border: 1px solid #111;
}

body.quarto-dark .qwebr-editor-toolbar {
  background-color: #111;
  padding: 0.2rem 0.5rem;
}

.qwebr-button {
  display: inline-block;
  font-weight: 400;
  line-height: 1;
  text-decoration: none;
  text-align: center;
  padding: 0.375rem 0.75rem;
  font-size: .9rem;
  border-radius: 0.25rem;
  transition: color .15s ease-in-out,background-color .15s ease-in-out,border-color .15s ease-in-out,box-shadow .15s ease-in-out;
}

body.quarto-light .qwebr-button {
  background-color: #EEEEEE;
  color: #000;
  border-color: #dee2e6;
  border: 1px solid rgba(0,0,0,0);
}

body.quarto-dark .qwebr-button {
  background-color: #111;
  color: #EEE;
  border-color: #dee2e6;
  border: 1px solid rgba(0,0,0,0);
}

body.quarto-light .qwebr-button:hover {
  color: #000;
  background-color: #d9dce0;
  border-color: #c8ccd0;
}

body.quarto-dark .qwebr-button:hover {
  color: #d9dce0;
  background-color: #323232;
  border-color: #d9dce0;
}

.qwebr-button:disabled,.qwebr-button.disabled,fieldset:disabled .qwebr-button {
  pointer-events: none;
  opacity: .65
}

.qwebr-button-reset {
  color: #696969; /*#4682b4;*/
}

.qwebr-button-copy {
  color: #696969;
}

/* Style the code highlight lines */
body.quarto-light .qwebr-editor-highlight-line {
  background-color: lightblue;
}

body.quarto-dark .qwebr-editor-highlight-line {
  background-color: darkblue;
}

/* Style the modal pop-up */

/* The Modal (background) */
.qwebr-modal {
  display: none; /* Hidden by default */
  position: fixed; /* Stay in place */
  z-index: 1; /* Sit on top */
  left: 0;
  top: 0;
  width: 100%; /* Full width */
  height: 100%; /* Full height */
  overflow: auto; /* Enable scroll if needed */
  background-color: rgb(0,0,0); /* Fallback color */
  background-color: rgba(0,0,0,0.4); /* Black w/ opacity */
  padding-top: 60px;
}

/* Modal Content */
.qwebr-modal-content {
  background-color: #fefefe;
  margin: 5% auto; /* 15% from the top and centered */
  padding: 20px;
  border: 1px solid #888;
  width: 80%; /* Could be more or less, depending on screen size */
}

.qwebr-modal-content-code {
  max-height: 50vh;
  min-height: 5vh;
  overflow: scroll;
  border: 1px solid #888;
}

/* The Close Button */
.qwebr-modal-close {
  color: #aaa;
  float: right;
  font-size: 28px;
  font-weight: bold;
}

.qwebr-modal-close:hover,
.qwebr-modal-close:focus {
  color: black;
  text-decoration: none;
  cursor: pointer;
}

.qwebr-download-btn {
  margin-top: 10px;
  text-decoration: none !important;
}

/* Styling to download image that is created */

.qwebr-canvas-image {
  position: relative;
  display: inline-block;
  margin: 10px;
}

.qwebr-canvas-image-download-btn {
  position: absolute;
  top: 10px;
  right: 10px;
  padding: 5px 10px;
  background-color: #007BFF;
  color: white;
  border: none;
  cursor: pointer;
  display: none;
}

figure:hover .qwebr-canvas-image-download-btn {
  display: block;
}

/* Custom styling for RevealJS Presentations*/

/* Reset the style of the interactive area */
.reveal div.qwebr-interactive-area {
  display: block;
  box-shadow: none;
  max-width: 100%;
  max-height: 100%;
  margin: 0;
  padding: 0;
}

/* Provide space to entries */
.reveal div.qwebr-output-code-area pre div {
  margin: 1px 2px 1px 10px;
}

/* Collapse the inside code tags to avoid extra space between line outputs */
.reveal pre div code.qwebr-output-code-stdout, .reveal pre div code.qwebr-output-code-stderr {
  padding: 0;
  display: contents;
}

body.reveal.quarto-light pre div code.qwebr-output-code-stdout {
  color: #111;
}

body.reveal.quarto-dark pre div code.qwebr-output-code-stdout {
  color: #EEEEEE;
}

.reveal pre div code.qwebr-output-code-stderr {
  color: #db4133;
}


/* Create a border around console and output (does not effect graphs) */
body.reveal.quarto-light div.qwebr-console-area {
  border: 1px solid #EEEEEE;
  box-shadow: 2px 2px 10px #EEEEEE;
}

body.reveal.quarto-dark div.qwebr-console-area {
  border: 1px solid #111;
  box-shadow: 2px 2px 10px #111;
}


/* Cap output height and allow text to scroll */
/* TODO: Is there a better way to fit contents/max it parallel to the monaco editor size? */
.reveal div.qwebr-output-code-area pre {
  max-height: 400px;
  overflow: scroll;
}

iframe.qwebr-output-code-browse {
  width: 100%;

  /*
    TODO: How to make the height automatic according to the widget size,
    or respect the quarto code block options?
  */
  min-height: 500px;
}

</style>
<script type="module">
// Document level settings ----

// Determine if we need to install R packages
globalThis.qwebrInstallRPackagesList = [''];

// Specify possible locations to search for the repository
globalThis.qwebrPackageRepoURLS = ['https://repo.r-wasm.org/'];

// Check to see if we have an empty array, if we do set to skip the installation.
globalThis.qwebrSetupRPackages = !(qwebrInstallRPackagesList.indexOf("") !== -1);
globalThis.qwebrAutoloadRPackages = true;

// Display a startup message?
globalThis.qwebrShowStartupMessage = false;
globalThis.qwebrShowHeaderMessage = false;

// Describe the webR settings that should be used
globalThis.qwebrCustomizedWebROptions = {
  "baseURL": "https://webr.r-wasm.org/v0.5.2/",
  "serviceWorkerUrl": "",
  "homedir": "/home/web_user", 
  "channelType": "ChannelType.Automatic"
};

// Store cell data
globalThis.qwebrCellDetails = [{"code":"x <- c(2, 4)\ny <- c(5, 8)\n\n# Euclidean distance\nd_E <- sqrt(sum((x - y)^2))\ncat(\"Euclidean distance using direct function:\", d_E, \"\\n\")\n\n# Another way\ndf <- data.frame(rbind(x, y))\ndist_euclidean <- dist(df, method = 'euclidean')\ncat(\"Euclidean distance using 'dist()' function:\", dist_euclidean, \"\\n\")\n\n# Using the package \"factoextra\" \nlibrary(factoextra)\ndist_euclidean_factoextra <- get_dist(df, method = 'euclidean')\ncat(\"Euclidean distance using 'factoextra::get_dist()' function:\", dist_euclidean_factoextra)","id":1,"options":{"autorun":"true","classes":"","comment":"","context":"interactive","dpi":72,"editor-font-scale":"1","editor-max-height":"","editor-quick-suggestions":"false","editor-word-wrap":"true","fig-cap":"","fig-height":5,"fig-width":7,"label":"euclidean-distance","message":"false","out-height":"","out-width":"700px","output":"true","read-only":"false","results":"markup","warning":"false"}},{"code":"x <- c(2, 4)\ny <- c(5, 8)\n\n# Manhattan distance\nd_M <- sum(abs(x - y))\ncat(\"Manhattan distance using direct function:\", d_M, \"\\n\")\n\n# Another way\ndf <- data.frame(rbind(x, y))\ndist_manhattan <- dist(df, method = 'manhattan')\ncat(\"Manhattan distance using 'dist()' function:\", dist_manhattan, \"\\n\")\n\n# Using the package \"factoextra\" \nlibrary(factoextra)\ndist_manhattan_factoextra <- get_dist(df, method = 'manhattan')\ncat(\"Manhattan distance using 'factoextra::get_dist()' function:\", dist_manhattan_factoextra)","id":2,"options":{"autorun":"true","classes":"","comment":"","context":"interactive","dpi":72,"editor-font-scale":"1","editor-max-height":"","editor-quick-suggestions":"false","editor-word-wrap":"true","fig-cap":"","fig-height":5,"fig-width":7,"label":"manhattan-distance","message":"false","out-height":"","out-width":"700px","output":"true","read-only":"false","results":"markup","warning":"false"}},{"code":"x <- c(2, 4)\ny <- c(5, 8)\n\n# Minkowski distance\nd_r <- function(x, y, r) {\n  (sum(abs(x - y)^r))^(1/r)\n}\ncat('Manhattan distance:', d_r(x, y, r = 1), 'that should be equal to d_M which is', d_M, '\\n')\ncat('Euclidean distance:', d_r(x, y, r = 2), 'that should be equal to d_E which is', d_E, '\\n')\ncat('Minkowski Distance', d_r(x, y, r = 5), '\\n')\ncat('Minkowski Distance', d_r(x, y, r = 10), '\\n')\n\n# Another way\ndf <- data.frame(rbind(x, y))\ndist_minkowski_5 <- dist(df, method = 'minkowski', p = 5)\ndist_minkowski_10 <- dist(df, method = 'minkowski', p = 10)\ncat(\"Minkowski distance using 'dist()' function (p = 5):\", dist_minkowski_5, '\\n')\ncat(\"Minkowski distance using 'dist()' function (p = 10):\", dist_minkowski_10, '\\n')\n\n\n# Using the package \"factoextra\" \nlibrary(factoextra)\ndist_minkowski_5_factoextra <- get_dist(df, method = 'manhattan', p = 5)\ncat(\"Minkowski distance using 'factoextra::get_dist()' function:\", dist_minkowski_5_factoextra, '\\n') \n\ndist_minkowski_10_factoextra <- get_dist(df, method = 'manhattan', p = 10)\ncat(\"Minkowski distance using 'factoextra::get_dist()' function:\", dist_minkowski_10_factoextra) ","id":3,"options":{"autorun":"true","classes":"","comment":"","context":"interactive","dpi":72,"editor-font-scale":"1","editor-max-height":"","editor-quick-suggestions":"false","editor-word-wrap":"true","fig-cap":"","fig-height":5,"fig-width":7,"label":"manhattan-distance","message":"false","out-height":"","out-width":"700px","output":"true","read-only":"false","results":"markup","warning":"false"}},{"code":"x <- c(2, 4)\ny <- c(5, 8)\n\n# Chebyshev distance\nd_C <- max(abs(x - y))\ncat(\"Chebyshev distance using direct function:\", d_C, \"\\n\")\n\n# Another way\ndf <- data.frame(rbind(x, y))\ndist_chebyshev <- dist(df, method = 'maximum')\ncat(\"Chebyshev distance using 'dist()' function:\", dist_chebyshev, \"\\n\")\n\n# Using the package \"factoextra\" \nlibrary(factoextra)\ndist_chebyshev_factoextra <- get_dist(df, method = 'maximum')\ncat(\"Chebyshev distance using 'factoextra::get_dist()' function:\", dist_chebyshev_factoextra)","id":4,"options":{"autorun":"true","classes":"","comment":"","context":"interactive","dpi":72,"editor-font-scale":"1","editor-max-height":"","editor-quick-suggestions":"false","editor-word-wrap":"true","fig-cap":"","fig-height":5,"fig-width":7,"label":"chebyshev-distance","message":"false","out-height":"","out-width":"700px","output":"true","read-only":"false","results":"markup","warning":"false"}},{"code":"x <- c(2, 4)\ny <- c(5, 8)\n\n# For Mahalanobis, we need covariance matrix (example with small dataset)\nX <- matrix(c(2, 4, 5, 8, 3, 7), ncol = 2, byrow = TRUE)\ncov_matrix <- cov(X)\nd_mahalanobis <- sqrt(t(x - y) %*% solve(cov_matrix) %*% (x - y))\nd_mahalanobis","id":5,"options":{"autorun":"true","classes":"","comment":"","context":"interactive","dpi":72,"editor-font-scale":"1","editor-max-height":"","editor-quick-suggestions":"false","editor-word-wrap":"true","fig-cap":"","fig-height":5,"fig-width":7,"label":"mahalanobis-distance","message":"false","out-height":"","out-width":"700px","output":"true","read-only":"false","results":"markup","warning":"false"}},{"code":"library(lsa)  # for cosine similarity\n\nx <- c(1, 2, 3)\ny <- c(2, 4, 6)\nz <- c(3, 0, 0)\n\ncos_xy <- cosine(x, y)\ncos_xz <- cosine(x, z)\n\ncat(\"Cosine similarity (x,y):\", round(cos_xy, 3), \"\\n\")\ncat(\"Cosine similarity (x,z):\", round(cos_xz, 3), \"\\n\")\ncat(\"Cosine distance (x,y):\", round(1 - cos_xy, 3), \"\\n\")\ncat(\"Cosine distance (x,z):\", round(1 - cos_xz, 3), \"\\n\")","id":6,"options":{"autorun":"true","classes":"","comment":"","context":"interactive","dpi":72,"editor-font-scale":"1","editor-max-height":"","editor-quick-suggestions":"false","editor-word-wrap":"true","fig-cap":"","fig-height":5,"fig-width":7,"label":"cosine-distance","message":"false","out-height":"","out-width":"700px","output":"true","read-only":"false","results":"markup","warning":"false"}},{"code":"# Two binary observations (e.g., presence/absence of features)\no1 <- c(1, 0, 1, 1, 0, 0, 1)\no2 <- c(1, 1, 0, 1, 0, 0, 0)\n\n# Compute the components\nf11 <- sum(o1 == 1 & o2 == 1)\nf00 <- sum(o1 == 0 & o2 == 0)\nf10 <- sum(o1 == 1 & o2 == 0)\nf01 <- sum(o1 == 0 & o2 == 1)\nd <- length(o1)\n\n# Similarity and distance\ns_SMC <- (f11 + f00) / d\nd_SMC <- (f01 + f10) / d  # same as 1 - s_SMC\n\ncat(\"f11 =\", f11, \"f00 =\", f00, \"f10 =\", f10, \"f01 =\", f01, \"\\n\")\ncat(\"Simple Matching Coefficient (similarity):\", round(s_SMC, 3), \"\\n\")\ncat(\"Simple Matching Distance:\", round(d_SMC, 3), \"\\n\")","id":7,"options":{"autorun":"true","classes":"","comment":"","context":"interactive","dpi":72,"editor-font-scale":"1","editor-max-height":"","editor-quick-suggestions":"false","editor-word-wrap":"true","fig-cap":"","fig-height":5,"fig-width":7,"label":"smc-distance-example","message":"false","out-height":"","out-width":"700px","output":"true","read-only":"false","results":"markup","warning":"false"}},{"code":"# Example categorical data\nx <- c(\"Red\", \"Small\", \"Circle\")\ny <- c(\"Blue\", \"Small\", \"Square\")\n\n# ----- Hamming Distance -----\nhamming_distance <- sum(x != y)\nprint(paste(\"Hamming distance:\", hamming_distance))","id":8,"options":{"autorun":"true","classes":"","comment":"","context":"interactive","dpi":72,"editor-font-scale":"1","editor-max-height":"","editor-quick-suggestions":"false","editor-word-wrap":"true","fig-cap":"","fig-height":5,"fig-width":7,"label":"hamming-distance","message":"false","out-height":"","out-width":"700px","output":"true","read-only":"false","results":"markup","warning":"false"}},{"code":"library(cluster)\nlibrary(tibble)\nlibrary(dplyr)\n\n# Create dataset\nsubjects <- tibble::tibble(\n  Subject_ID = c(\"001\", \"002\", \"003\", \"004\", \"005\"),\n  Age = c(28, 34, 22, 45, 30),                \n  Handedness = c(\"Right\", \"Left\", \"Right\", \"Right\", \"Left\"),  \n  Eye_Colour = c(\"Blue\", \"Blue\", \"Green\", \"Hazel\", \"Brown\"),  \n  Knows_Python = c(\"Yes\", \"No\", \"Yes\", \"No\", \"Yes\")           \n)\n\n# Convert character columns to factors (important for Gower)\nsubjects <- subjects %>%\n  mutate(across(where(is.character), as.factor))\n\n# Compute Gower distance \ngower_dist <- daisy(subjects[, -1], metric = \"gower\")  # exclude Subject_ID\n\nprint(round(as.matrix(gower_dist), 3))","id":9,"options":{"autorun":"true","classes":"","comment":"","context":"interactive","dpi":72,"editor-font-scale":"1","editor-max-height":"","editor-quick-suggestions":"false","editor-word-wrap":"true","fig-cap":"","fig-height":5,"fig-width":7,"label":"gower-mixed-fixed","message":"false","out-height":"","out-width":"700px","output":"true","read-only":"false","results":"markup","warning":"false"}},{"code":"library(cluster)\nlibrary(factoextra)\nlibrary(dplyr)\nlibrary(tibble)\n\nsubjects <- tibble(\n  Subject_ID = c(\"001\", \"002\", \"003\", \"004\", \"005\"),\n  Age = c(28, 34, 22, 45, 30),\n  Handedness = as.factor(c(\"Right\", \"Left\", \"Right\", \"Right\", \"Left\")),\n  Eye_Colour = as.factor(c(\"Blue\", \"Blue\", \"Green\", \"Hazel\", \"Brown\")),\n  Knows_Python = as.factor(c(\"Yes\", \"No\", \"Yes\", \"No\", \"Yes\"))\n)\nsubjects <- subjects %>%\n  mutate(across(where(is.character), as.factor))\ngower_dist <- daisy(subjects[, -1], metric = \"gower\")\n\n# Visualize matrix\nlibrary(factoextra)\nfviz_dist(gower_dist) ","id":10,"options":{"autorun":"true","classes":"","comment":"","context":"interactive","dpi":72,"editor-font-scale":"1","editor-max-height":"","editor-quick-suggestions":"false","editor-word-wrap":"true","fig-cap":"Visualization of Gower distance matrix using factoextra.","fig-height":5,"fig-width":7,"label":"visualize-gower","message":"false","out-height":"","out-width":"80%","output":"true","read-only":"false","results":"markup","warning":"false"}},{"code":"set.seed(42)\n\n# Generate synthetic 2D data\nx <- rbind(\n  matrix(rnorm(100, mean = 0, sd = 0.3), ncol = 2),\n  matrix(rnorm(100, mean = 3, sd = 0.3), ncol = 2)\n)\ncolnames(x) <- c(\"x\", \"y\")\n\n# Apply k-means with 2 clusters\nkm <- kmeans(x, centers = 2, nstart = 20)\n\n# Visualize results\nlibrary(ggplot2)\ndata <- data.frame(x, cluster = factor(km$cluster))\nggplot(data, aes(x, y, color = cluster)) +\n  geom_point(size = 3) +\n  geom_point(data = as.data.frame(km$centers), aes(x, y), color = \"black\", size = 5, shape = 8) +\n  labs(title = \"K-Means Clustering\",\n       subtitle = \"Centroids shown as black stars\") +\n  theme_minimal()","id":11,"options":{"autorun":"true","classes":"","comment":"","context":"interactive","dpi":72,"editor-font-scale":"1","editor-max-height":"","editor-quick-suggestions":"false","editor-word-wrap":"true","fig-cap":"","fig-height":5,"fig-width":7,"label":"kmeans-example","message":"false","out-height":"","out-width":"80%","output":"true","read-only":"false","results":"markup","warning":"false"}},{"code":"library(ggplot2)\nlibrary(dplyr)\n\nset.seed(42)\nx <- rnorm(1000) / 2\ny <- c(rnorm(500) + 5, rnorm(500)) / 10\ndata <- data.frame(x, y)\n\nggplot(data, aes(x, y)) +\n  geom_point(size = 1, color = \"black\") +\n  theme_minimal(base_size = 14) +\n  labs(title = \"Original Data (different scales)\")","id":12,"options":{"autorun":"true","classes":"","comment":"","context":"interactive","dpi":72,"editor-font-scale":"1","editor-max-height":"","editor-quick-suggestions":"false","editor-word-wrap":"true","fig-cap":"Original data (different scales)","fig-height":5,"fig-width":7,"label":"kmeans-step1","message":"false","out-height":"","out-width":"80%","output":"true","read-only":"false","results":"markup","warning":"true","warnings":"false"}},{"code":"km_raw <- kmeans(data, centers = 2)\ndata$cluster_raw <- as.factor(km_raw$cluster)\n\nggplot(data, aes(x, y, color = cluster_raw)) +\n  geom_point(size = 1) +\n  scale_color_manual(values = c(\"tomato\", \"steelblue\")) +\n  theme_minimal(base_size = 14) +\n  labs(title = \"Non-normalized K-Means\")","id":13,"options":{"autorun":"true","classes":"","comment":"","context":"interactive","dpi":72,"editor-font-scale":"1","editor-max-height":"","editor-quick-suggestions":"false","editor-word-wrap":"true","fig-cap":"Non-normalized K-Means clustering","fig-height":5,"fig-width":7,"label":"kmeans-step2","message":"false","out-height":"","out-width":"80%","output":"true","read-only":"false","results":"markup","warning":"false"}},{"code":"normalize <- function(v) (v - min(v)) / (max(v) - min(v))\ndata_norm <- data %>% mutate(xn = normalize(x), yn = normalize(y))\nkm_norm <- kmeans(data_norm[, c(\"xn\", \"yn\")], centers = 2)\ndata_norm$cluster_norm <- as.factor(km_norm$cluster)\n\nggplot(data_norm, aes(xn, yn, color = cluster_norm)) +\n  geom_point(size = 1) +\n  scale_color_manual(values = c(\"tomato\", \"steelblue\")) +\n  theme_minimal(base_size = 14) +\n  labs(title = \"Normalized (0–1) K-Means\")","id":14,"options":{"autorun":"true","classes":"","comment":"","context":"interactive","dpi":72,"editor-font-scale":"1","editor-max-height":"","editor-quick-suggestions":"false","editor-word-wrap":"true","fig-cap":"Normalized (0–1) K-Means clustering","fig-height":5,"fig-width":7,"label":"kmeans-step3","message":"false","out-height":"","out-width":"80%","output":"true","read-only":"false","results":"markup","warning":"false"}},{"code":"standardize <- function(v) (v - mean(v)) / sd(v)\ndata_std <- data %>% mutate(xs = standardize(x), ys = standardize(y))\nkm_std <- kmeans(data_std[, c(\"xs\", \"ys\")], centers = 2)\ndata_std$cluster_std <- as.factor(km_std$cluster)\n\nggplot(data_std, aes(xs, ys, color = cluster_std)) +\n  geom_point(size = 1) +\n  scale_color_manual(values = c(\"tomato\", \"steelblue\")) +\n  theme_minimal(base_size = 14) +\n  labs(title = \"Standardized (Z-score) K-Means\")","id":15,"options":{"autorun":"true","classes":"","comment":"","context":"interactive","dpi":72,"editor-font-scale":"1","editor-max-height":"","editor-quick-suggestions":"false","editor-word-wrap":"true","fig-cap":"Standardized (Z-score) K-Means clustering","fig-height":5,"fig-width":7,"label":"kmeans-step4","message":"false","out-height":"","out-width":"80%","output":"true","read-only":"false","results":"markup","warning":"false"}},{"code":"# Load dataset\ndata(\"iris\")\n\n# Select only numeric features for clustering\niris_data <- iris[, 1:4]","id":16,"options":{"autorun":"true","classes":"","comment":"","context":"interactive","dpi":72,"editor-font-scale":"1","editor-max-height":"","editor-quick-suggestions":"false","editor-word-wrap":"true","fig-cap":"","fig-height":5,"fig-width":7,"label":"iris-prepare","message":"false","out-height":"","out-width":"700px","output":"true","read-only":"false","results":"markup","warning":"false"}},{"code":"library(ggplot2)\n\n# Compute WSS for k = 1:10\n\nwss <- sapply(1:10, function(k) {\nkmeans(iris_data, centers = k, nstart = 20)$tot.withinss\n})\n\n# Create Elbow plot\n\nelbow_df <- data.frame(k = 1:10, WSS = wss)\n\nggplot(elbow_df, aes(k, WSS)) +\ngeom_line(color = \"steelblue\", linewidth = 1.2) +\ngeom_point(size = 3, color = \"tomato\") +\nscale_x_continuous(breaks = 1:10) +\nlabs(title = \"Elbow Method — Iris Dataset\",\nx = \"Number of clusters (k)\",\ny = \"Total Within-Cluster Sum of Squares (WSS)\") +\ntheme_minimal()","id":17,"options":{"autorun":"true","classes":"","comment":"","context":"interactive","dpi":72,"editor-font-scale":"1","editor-max-height":"","editor-quick-suggestions":"false","editor-word-wrap":"true","fig-cap":"","fig-height":5,"fig-width":7,"label":"iris-elbow","message":"false","out-height":"","out-width":"90%","output":"true","read-only":"false","results":"markup","warning":"false"}},{"code":"library(factoextra)\n\nfviz_nbclust(iris_data, kmeans, method = 'wss') + \n  geom_vline(xintercept = 3, linetype = 2) +\nlabs(\ntitle = \"Elbow Method for Determining Optimal k\",\nsubtitle = \"Dashed line indicates the chosen number of clusters (k = 4)\"\n)","id":18,"options":{"autorun":"true","classes":"","comment":"","context":"interactive","dpi":72,"editor-font-scale":"1","editor-max-height":"","editor-quick-suggestions":"false","editor-word-wrap":"true","fig-cap":"","fig-height":5,"fig-width":7,"label":"elbow-fviz","message":"true","messages":"false","out-height":"","out-width":"80%","output":"true","read-only":"false","results":"markup","warning":"false"}},{"code":"set.seed(42)\nkm_iris <- kmeans(iris_data, centers = 3, nstart = 20)\n\n# Print the results\nprint(km_iris)","id":19,"options":{"autorun":"true","classes":"","comment":"","context":"interactive","dpi":72,"editor-font-scale":"1","editor-max-height":"","editor-quick-suggestions":"false","editor-word-wrap":"true","fig-cap":"","fig-height":5,"fig-width":7,"label":"iris-kmeans","message":"false","out-height":"","out-width":"700px","output":"true","read-only":"false","results":"markup","warning":"false"}},{"code":"# Add cluster assignments to the dataset\niris_clustered <- cbind(iris, cluster = factor(km_iris$cluster))\n\n# Show first few results\nhead(iris_clustered)","id":20,"options":{"autorun":"true","classes":"","comment":"","context":"interactive","dpi":72,"editor-font-scale":"1","editor-max-height":"","editor-quick-suggestions":"false","editor-word-wrap":"true","fig-cap":"","fig-height":5,"fig-width":7,"label":"iris-kmeans","message":"false","out-height":"","out-width":"700px","output":"true","read-only":"false","results":"markup","warning":"false"}},{"code":"# Total, within, and between-cluster sums of squares\n\nTSS <- sum(scale(iris_data, scale = FALSE)^2)\nWSS <- km_iris$tot.withinss\nBSS <- TSS - WSS\nratio <- BSS / TSS\n\ncat(\"TSS:\", round(TSS, 2), \"\\n\")\ncat(\"WSS:\", round(WSS, 2), \"\\n\")\ncat(\"BSS:\", round(BSS, 2), \"\\n\")\ncat(\"Explained variance (BSS/TSS):\", round(ratio, 3), \"\\n\")","id":21,"options":{"autorun":"true","classes":"","comment":"","context":"interactive","dpi":72,"editor-font-scale":"1","editor-max-height":"","editor-quick-suggestions":"false","editor-word-wrap":"true","fig-cap":"","fig-height":5,"fig-width":7,"label":"iris-measures","message":"false","out-height":"","out-width":"700px","output":"true","read-only":"false","results":"markup","warning":"false"}},{"code":"library(GGally)\nggpairs(iris, aes(color = Species))","id":22,"options":{"autorun":"true","classes":"","comment":"","context":"interactive","dpi":72,"editor-font-scale":"1","editor-max-height":"","editor-quick-suggestions":"false","editor-word-wrap":"true","fig-cap":"","fig-height":5,"fig-width":7,"label":"eda","message":"false","out-height":"","out-width":"80%","output":"true","read-only":"false","results":"markup","warning":"false"}},{"code":"# Compute ratio of between- to within-group variance for each feature\nlibrary(dplyr)\n\niris_var <- iris %>%\n  group_by(Species) %>%\n  summarise(across(where(is.numeric), mean))\n\n# Between-class variance\noverall_means <- colMeans(iris[, 1:4])\nbetween_var <- colSums((as.matrix(iris_var[, -1]) - overall_means)^2)\n\n# Within-class variance\nwithin_var <- sapply(iris[, 1:4], function(v) tapply(v, iris$Species, var))\nwithin_var <- colMeans(within_var)\n\n# Ratio\ndiscriminative_ratio <- between_var / within_var\ndiscriminative_ratio","id":23,"options":{"autorun":"true","classes":"","comment":"","context":"interactive","dpi":72,"editor-font-scale":"1","editor-max-height":"","editor-quick-suggestions":"false","editor-word-wrap":"true","fig-cap":"","fig-height":5,"fig-width":7,"label":"discriminative-measures","message":"false","out-height":"","out-width":"700px","output":"true","read-only":"false","results":"markup","warning":"false"}},{"code":"library(ggplot2)\n\n# Compare Sepal.Width vs Petal.Length\nggplot(iris, aes(Sepal.Width, fill = Species)) +\n  geom_density(alpha = 0.5) +\n  labs(title = \"Distribution of Sepal.Width by Species\") +\n  theme_minimal()\n\nggplot(iris, aes(Petal.Length, fill = Species)) +\n  geom_density(alpha = 0.5) +\n  labs(title = \"Distribution of Petal.Length by Species\") +\n  theme_minimal()","id":24,"options":{"autorun":"true","classes":"","comment":"","context":"interactive","dpi":72,"editor-font-scale":"1","editor-max-height":"","editor-quick-suggestions":"false","editor-word-wrap":"true","fig-cap":"","fig-height":5,"fig-width":7,"label":"sepal-length-plots","message":"false","out-height":"","out-width":"80%","output":"true","read-only":"false","results":"markup","warning":"false"}},{"code":"ggplot(iris_clustered, aes(Petal.Length, Petal.Width, color = cluster)) +\ngeom_point(size = 3) +\nlabs(title = \"K-Means Clustering of Iris Data (k = 3)\",\nsubtitle = \"Color shows cluster assignment\") +\ntheme_minimal()","id":25,"options":{"autorun":"true","classes":"","comment":"","context":"interactive","dpi":72,"editor-font-scale":"1","editor-max-height":"","editor-quick-suggestions":"false","editor-word-wrap":"true","fig-cap":"","fig-height":5,"fig-width":7,"label":"iris-plots","message":"false","out-height":"","out-width":"80%","output":"true","read-only":"false","results":"markup","warning":"false"}},{"code":"fviz_cluster(km_iris, data = iris_data,\npalette = c(\"#2E9FDF\", \"#00AFBB\", \"#E7B800\"),\nellipse.type = \"euclid\", # Concentration ellipse\nstar.plot = FALSE, # Add segments from centroids to items\nrepel = TRUE, # Avoid label overplotting (slow)\nggtheme = theme_minimal()\n)","id":26,"options":{"autorun":"true","classes":"","comment":"","context":"interactive","dpi":72,"editor-font-scale":"1","editor-max-height":"","editor-quick-suggestions":"false","editor-word-wrap":"true","fig-cap":"","fig-height":5,"fig-width":7,"label":"fviz_clust_iris","message":"false","out-height":"","out-width":"80%","output":"true","read-only":"false","results":"markup","warning":"true","warnings":"false"}},{"code":"library(cluster)\nset.seed(42)\n\n# K-means result for k = 3 (from previous section)\nkm_iris <- kmeans(iris[, 1:4], centers = 3, nstart = 20)\n\n# Compute silhouette width\nsil_iris <- silhouette(km_iris$cluster, dist(iris[, 1:4]))\n\n# Display summary statistics\nsummary(sil_iris)","id":27,"options":{"autorun":"true","classes":"","comment":"","context":"interactive","dpi":72,"editor-font-scale":"1","editor-max-height":"","editor-quick-suggestions":"false","editor-word-wrap":"true","fig-cap":"","fig-height":5,"fig-width":7,"label":"silhouette-iris","message":"false","out-height":"","out-width":"700px","output":"true","read-only":"false","results":"markup","warning":"false"}},{"code":"plot(sil_iris, border = NA, main = \"Silhouette Plot — Iris Dataset (k = 3)\")","id":28,"options":{"autorun":"true","classes":"","comment":"","context":"interactive","dpi":72,"editor-font-scale":"1","editor-max-height":"","editor-quick-suggestions":"false","editor-word-wrap":"true","fig-cap":"Silhouette plot for K-Means clustering (k = 3) on the Iris dataset","fig-height":5,"fig-width":7,"label":"silhouette-plot","message":"true","out-height":"","out-width":"80%","output":"true","read-only":"false","results":"markup","warning":"true"}},{"code":"sil_widths <- sapply(2:10, function(k) {\nkm <- kmeans(iris[, 1:4], centers = k, nstart = 20)\nss <- silhouette(km$cluster, dist(iris[, 1:4]))\nmean(ss[, \"sil_width\"])\n})\n\nsil_df <- data.frame(k = 2:10, Silhouette = sil_widths)\n\nlibrary(ggplot2)\nggplot(sil_df, aes(k, Silhouette)) +\ngeom_line(color = \"steelblue\", linewidth = 1.2) +\ngeom_point(size = 3, color = \"tomato\") +\nscale_x_continuous(breaks = 2:10) +\nlabs(title = \"Average Silhouette Width by Number of Clusters\",\nx = \"Number of clusters (k)\",\ny = \"Average Silhouette Width\") +\ntheme_minimal()\n\nlibrary(factoextra)\n\nfviz_nbclust(iris_data, kmeans, method = 'silhouette')","id":29,"options":{"autorun":"true","classes":"","comment":"","context":"interactive","dpi":72,"editor-font-scale":"1","editor-max-height":"","editor-quick-suggestions":"false","editor-word-wrap":"true","fig-cap":"","fig-height":5,"fig-width":7,"label":"silhouette-elbow","message":"false","out-height":"","out-width":"80%","output":"true","read-only":"false","results":"markup","warning":"false"}},{"code":"library(cluster)\nlibrary(ggplot2)\n\niris_data <- iris[, 1:4]\n\n# Apply k-medoids clustering (PAM = Partitioning Around Medoids)\nset.seed(123)\npam_result <- pam(iris_data, k = 3, metric = \"euclidean\")\n\niris_pam <- iris\niris_pam$cluster <- as.factor(pam_result$clustering)\n\n# Visualize clusters (Petal.Length vs Petal.Width)\nggplot(iris_pam, aes(Petal.Length, Petal.Width, color = cluster, shape = Species)) +\n  geom_point(size = 3, alpha = 0.7) +\n  geom_point(data = as.data.frame(pam_result$medoids), \n             aes(Petal.Length, Petal.Width), \n             color = \"black\", size = 5, shape = 8) +\n  labs(title = \"k-Medoids Clustering (PAM)\", \n       subtitle = \"Medoids shown as black stars\",\n       x = \"Petal Length\", y = \"Petal Width\") +\n  theme_minimal(base_size = 14)","id":30,"options":{"autorun":"true","classes":"","comment":"","context":"interactive","dpi":72,"editor-font-scale":"1","editor-max-height":"","editor-quick-suggestions":"false","editor-word-wrap":"true","fig-cap":"k-Medoids clustering using the PAM algorithm on the iris dataset.","fig-height":5,"fig-width":7,"label":"pam-basic","message":"false","out-height":"","out-width":"80%","output":"true","read-only":"false","results":"markup","warning":"false"}},{"code":"fviz_cluster(pam_result, data = iris_pm,\n             palette = c(\"#2E9FDF\", \"#00AFBB\", \"#E7B800\"),\n             ellipse.type = \"euclid\", # Concentration ellipse\n             star.plot = FALSE, # Add segments from centroids to items\n             repel = TRUE, # Avoid label overplotting (slow)\n             ggtheme = theme_minimal()\n)       ","id":31,"options":{"autorun":"true","classes":"","comment":"","context":"interactive","dpi":72,"editor-font-scale":"1","editor-max-height":"","editor-quick-suggestions":"false","editor-word-wrap":"true","fig-cap":"k-Medoids clustering using the PAM algorithm via PCA.","fig-height":5,"fig-width":7,"label":"fviz_PCA","message":"false","out-height":"","out-width":"80%","output":"true","read-only":"false","results":"markup","warning":"false"}},{"code":"set.seed(123)\nkmeans_result <- kmeans(iris_data, centers = 3, nstart = 20)\n\niris_compare <- iris\niris_compare$kmeans_cluster <- as.factor(kmeans_result$cluster)\niris_compare$kmedoids_cluster <- as.factor(pam_result$clustering)\n\n# Combine plots side by side\nlibrary(patchwork)\n\np1 <- ggplot(iris_compare, aes(Petal.Length, Petal.Width, color = kmeans_cluster)) +\n  geom_point(size = 3, alpha = 0.7) +\n  geom_point(data = as.data.frame(kmeans_result$centers),\n             aes(Petal.Length, Petal.Width),\n             color = \"black\", size = 5, shape = 8) +\n  labs(title = \"k-Means\", subtitle = \"Centroids (means) shown as black stars\") +\n  theme_minimal(base_size = 13)\n\np2 <- ggplot(iris_compare, aes(Petal.Length, Petal.Width, color = kmedoids_cluster)) +\n  geom_point(size = 3, alpha = 0.7) +\n  geom_point(data = as.data.frame(pam_result$medoids),\n             aes(Petal.Length, Petal.Width),\n             color = \"black\", size = 5, shape = 8) +\n  labs(title = \"k-Medoids (PAM)\", subtitle = \"Medoids (real points) shown as black stars\") +\n  theme_minimal(base_size = 13)\n\np1 + p2","id":32,"options":{"autorun":"true","classes":"","comment":"","context":"interactive","dpi":72,"editor-font-scale":"1","editor-max-height":"","editor-quick-suggestions":"false","editor-word-wrap":"true","fig-cap":"Comparison between k-Means and k-Medoids clustering on the same dataset.","fig-height":5,"fig-width":7,"label":"kmeans-vs-pam","message":"true","out-height":"","out-width":"80%","output":"true","read-only":"false","results":"markup","warning":"true"}},{"code":"library(cluster)\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(factoextra)\n\nlibrary(kmed)\n\n# Load dataset\ndata(\"heart\")","id":33,"options":{"autorun":"true","classes":"","comment":"","context":"interactive","dpi":72,"editor-font-scale":"1","editor-max-height":"","editor-quick-suggestions":"false","editor-word-wrap":"true","fig-cap":"Finding optimal k and discriminative features in the Heart Disease dataset using PAM (Gower distance).","fig-height":5,"fig-width":7,"label":"pam-heart-optimal","message":"false","out-height":"","out-width":"80%","output":"true","read-only":"false","results":"markup","warning":"false"}},{"code":"# the iris dataset \ndf_iris <- iris[, 1:4]\n\n# random data generated from the iris dataset\ndf_random <- apply(df_iris, 2, function(x){\n  runif(length(x), min(x), max(x))\n})\ndf_random <- as.data.frame(df_random)\n\n# standardize the dataset\ndf_iris_scaled <- scale(df_iris)\ndf_random_scaled <- scale(df_random)\n\nlibrary(hopkins)\n\n# compute Hopkins statistic for iris dataset\nset.seed(123)\ncat(\"The iris dataset:\", hopkins(df_iris_scaled, m = nrow(df_iris_scaled) - 1))\n\n# Compute Hopkins statistic for a random dataset\nset.seed(123)\ncat(\"The random dataset:\", hopkins(df_random_scaled, m = nrow(df_random_scaled) - 1))","id":34,"options":{"autorun":"true","classes":"","comment":"","context":"interactive","dpi":72,"editor-font-scale":"1","editor-max-height":"","editor-quick-suggestions":"false","editor-word-wrap":"true","fig-cap":"","fig-height":5,"fig-width":7,"label":"example-of hopkins","message":"true","messages":"false","out-height":"","out-width":"700px","output":"true","read-only":"false","results":"markup","warning":"true","warnings":"false"}},{"code":"fviz_dist(dist(df_iris_scaled), show_labels = FALSE) +\n  labs(title = \"Iris data\")","id":35,"options":{"autorun":"true","classes":"","comment":"","context":"interactive","dpi":72,"editor-font-scale":"1","editor-max-height":"","editor-quick-suggestions":"false","editor-word-wrap":"true","fig-cap":"","fig-height":5,"fig-width":7,"label":"plot-iris-data","message":"true","out-height":"","out-width":"80%","output":"true","read-only":"false","results":"markup","warning":"true"}},{"code":"fviz_dist(dist(df_random_scaled), show_labels = FALSE) + \n  labs(title = \"Random data\")","id":36,"options":{"autorun":"true","classes":"","comment":"","context":"interactive","dpi":72,"editor-font-scale":"1","editor-max-height":"","editor-quick-suggestions":"false","editor-word-wrap":"true","fig-cap":"","fig-height":5,"fig-width":7,"label":"plot_random-data","message":"true","out-height":"","out-width":"80%","output":"true","read-only":"false","results":"markup","warning":"true","warnings":"false"}},{"code":"# Elbow method \nfviz_nbclust(df_iris_scaled, kmeans, method = 'wss') + \n  geom_vline(xintercept = 3, linetype = 2) + \n  labs(subtitle = 'Elbow method')","id":37,"options":{"autorun":"true","classes":"","comment":"","context":"interactive","dpi":72,"editor-font-scale":"1","editor-max-height":"","editor-quick-suggestions":"false","editor-word-wrap":"true","fig-cap":"","fig-height":5,"fig-width":7,"label":"plot1","message":"true","out-height":"","out-width":"80%","output":"true","read-only":"false","results":"markup","warning":"true"}},{"code":"# Silhouette method\nfviz_nbclust(df_iris_scaled, kmeans, method = 'silhouette') + \n  labs(subtitle = 'Silhouette method')","id":38,"options":{"autorun":"true","classes":"","comment":"","context":"interactive","dpi":72,"editor-font-scale":"1","editor-max-height":"","editor-quick-suggestions":"false","editor-word-wrap":"true","fig-cap":"","fig-height":5,"fig-width":7,"label":"plot2","message":"true","out-height":"","out-width":"80%","output":"true","read-only":"false","results":"markup","warning":"true"}},{"code":"# Gap statistic\n# nboot = 50 to keep the function speedy.\n# recommended value: nboot= 500 for your analysis.\n# Use verbose = FALSE to hide computing progression.\nfviz_nbclust(df_iris_scaled, kmeans, nstart = 25, method = 'gap_stat', nboot = 50) + \n  labs(subtitle = 'Gap statistic method')","id":39,"options":{"autorun":"true","classes":"","comment":"","context":"interactive","dpi":72,"editor-font-scale":"1","editor-max-height":"","editor-quick-suggestions":"false","editor-word-wrap":"true","fig-cap":"","fig-height":5,"fig-width":7,"label":"plot3","message":"true","out-height":"","out-width":"80%","output":"true","read-only":"false","results":"markup","warning":"true"}},{"code":"library(\"NbClust\")\n\nnb <- NbClust(df_iris_scaled, distance = 'euclidean', min.nc = 2, max.nc = 10, method = 'kmeans')\n\n# The result of NbClust using the function fviz_nbclust() \n\nlibrary(\"factoextra\")\nfviz_nbclust(nb)","id":40,"options":{"autorun":"true","classes":"","comment":"","context":"interactive","dpi":72,"editor-font-scale":"1","editor-max-height":"","editor-quick-suggestions":"false","editor-word-wrap":"true","fig-cap":"","fig-height":5,"fig-width":7,"label":"unnamed-chunk-40","message":"true","messages":"false","out-height":"","out-width":"80%","output":"true","read-only":"false","results":"markup","warning":"false"}}];

</script>
<script type="module">
// Declare startupMessageQWebR globally
globalThis.qwebrStartupMessage = document.createElement("p");

// Verify if OffScreenCanvas is supported
globalThis.qwebrOffScreenCanvasSupport = function() {
  return typeof OffscreenCanvas !== 'undefined'
}

// Function to set the button text
globalThis.qwebrSetInteractiveButtonState = function(buttonText, enableCodeButton = true) {
  document.querySelectorAll(".qwebr-button-run").forEach((btn) => {
    btn.innerHTML = buttonText;
    btn.disabled = !enableCodeButton;
  });
}

// Function to update the status message in non-interactive cells
globalThis.qwebrUpdateStatusMessage = function(message) {
  document.querySelectorAll(".qwebr-status-text.qwebr-cell-needs-evaluation").forEach((elem) => {
    elem.innerText = message;
  });
}

// Function to update the status message
globalThis.qwebrUpdateStatusHeader = function(message) {
  qwebrStartupMessage.innerHTML = `
    <i class="fa-solid fa-spinner fa-spin qwebr-icon-status-spinner"></i>
    <span>${message}</span>`;
}

// Function to return true if element is found, false if not
globalThis.qwebrCheckHTMLElementExists = function(selector) {
  const element = document.querySelector(selector);
  return !!element;
}

// Function that detects whether reveal.js slides are present
globalThis.qwebrIsRevealJS = function() {
  // If the '.reveal .slides' selector exists, RevealJS is likely present
  return qwebrCheckHTMLElementExists('.reveal .slides');
}

// Initialize the Quarto sidebar element
function qwebrSetupQuartoSidebar() {
  var newSideBarDiv = document.createElement('div');
  newSideBarDiv.id = 'quarto-margin-sidebar';
  newSideBarDiv.className = 'sidebar margin-sidebar';
  newSideBarDiv.style.top = '0px';
  newSideBarDiv.style.maxHeight = 'calc(0px + 100vh)';

  return newSideBarDiv;
}

// Position the sidebar in the document
function qwebrPlaceQuartoSidebar() {
  // Get the reference to the element with id 'quarto-document-content'
  var referenceNode = document.getElementById('quarto-document-content');

  // Create the new div element
  var newSideBarDiv = qwebrSetupQuartoSidebar();

  // Insert the new div before the 'quarto-document-content' element
  referenceNode.parentNode.insertBefore(newSideBarDiv, referenceNode);
}

function qwebrPlaceMessageContents(content, html_location = "title-block-header", revealjs_location = "title-slide") {

  // Get references to header elements
  const headerHTML = document.getElementById(html_location);
  const headerRevealJS = document.getElementById(revealjs_location);

  // Determine where to insert the quartoTitleMeta element
  if (headerHTML || headerRevealJS) {
    // Append to the existing "title-block-header" element or "title-slide" div
    (headerHTML || headerRevealJS).appendChild(content);
  } else {
    // If neither headerHTML nor headerRevealJS is found, insert after "webr-monaco-editor-init" script
    const monacoScript = document.getElementById("qwebr-monaco-editor-init");
    const header = document.createElement("header");
    header.setAttribute("id", "title-block-header");
    header.appendChild(content);
    monacoScript.after(header);
  }
}



function qwebrOffScreenCanvasSupportWarningMessage() {
  
  // Verify canvas is supported.
  if(qwebrOffScreenCanvasSupport()) return;

  // Create the main container div
  var calloutContainer = document.createElement('div');
  calloutContainer.classList.add('callout', 'callout-style-default', 'callout-warning', 'callout-titled');

  // Create the header div
  var headerDiv = document.createElement('div');
  headerDiv.classList.add('callout-header', 'd-flex', 'align-content-center');

  // Create the icon container div
  var iconContainer = document.createElement('div');
  iconContainer.classList.add('callout-icon-container');

  // Create the icon element
  var iconElement = document.createElement('i');
  iconElement.classList.add('callout-icon');

  // Append the icon element to the icon container
  iconContainer.appendChild(iconElement);

  // Create the title container div
  var titleContainer = document.createElement('div');
  titleContainer.classList.add('callout-title-container', 'flex-fill');
  titleContainer.innerText = 'Warning: Web Browser Does Not Support Graphing!';

  // Append the icon container and title container to the header div
  headerDiv.appendChild(iconContainer);
  headerDiv.appendChild(titleContainer);

  // Create the body container div
  var bodyContainer = document.createElement('div');
  bodyContainer.classList.add('callout-body-container', 'callout-body');

  // Create the paragraph element for the body content
  var paragraphElement = document.createElement('p');
  paragraphElement.innerHTML = 'This web browser does not have support for displaying graphs through the <code>quarto-webr</code> extension since it lacks an <code>OffScreenCanvas</code>. Please upgrade your web browser to one that supports <code>OffScreenCanvas</code>.';

  // Append the paragraph element to the body container
  bodyContainer.appendChild(paragraphElement);

  // Append the header div and body container to the main container div
  calloutContainer.appendChild(headerDiv);
  calloutContainer.appendChild(bodyContainer);

  // Append the main container div to the document depending on format
  qwebrPlaceMessageContents(calloutContainer, "title-block-header"); 

}


// Function that attaches the document status message and diagnostics
function displayStartupMessage(showStartupMessage, showHeaderMessage) {
  if (!showStartupMessage) {
    return;
  }

  // Create the outermost div element for metadata
  const quartoTitleMeta = document.createElement("div");
  quartoTitleMeta.classList.add("quarto-title-meta");

  // Create the first inner div element
  const firstInnerDiv = document.createElement("div");
  firstInnerDiv.setAttribute("id", "qwebr-status-message-area");

  // Create the second inner div element for "WebR Status" heading and contents
  const secondInnerDiv = document.createElement("div");
  secondInnerDiv.setAttribute("id", "qwebr-status-message-title");
  secondInnerDiv.classList.add("quarto-title-meta-heading");
  secondInnerDiv.innerText = "WebR Status";

  // Create another inner div for contents
  const secondInnerDivContents = document.createElement("div");
  secondInnerDivContents.setAttribute("id", "qwebr-status-message-body");
  secondInnerDivContents.classList.add("quarto-title-meta-contents");

  // Describe the WebR state
  qwebrStartupMessage.innerText = "🟡 Loading...";
  qwebrStartupMessage.setAttribute("id", "qwebr-status-message-text");
  // Add `aria-live` to auto-announce the startup status to screen readers
  qwebrStartupMessage.setAttribute("aria-live", "assertive");

  // Append the startup message to the contents
  secondInnerDivContents.appendChild(qwebrStartupMessage);

  // Add a status indicator for COOP and COEP Headers if needed
  if (showHeaderMessage) {
    const crossOriginMessage = document.createElement("p");
    crossOriginMessage.innerText = `${crossOriginIsolated ? '🟢' : '🟡'} COOP & COEP Headers`;
    crossOriginMessage.setAttribute("id", "qwebr-coop-coep-header");
    secondInnerDivContents.appendChild(crossOriginMessage);
  }

  // Combine the inner divs and contents
  firstInnerDiv.appendChild(secondInnerDiv);
  firstInnerDiv.appendChild(secondInnerDivContents);
  quartoTitleMeta.appendChild(firstInnerDiv);

  // Place message on webpage
  qwebrPlaceMessageContents(quartoTitleMeta); 
}

function qwebrAddCommandHistoryModal() {
  // Create the modal div
  var modalDiv = document.createElement('div');
  modalDiv.id = 'qwebr-history-modal';
  modalDiv.className = 'qwebr-modal';

  // Create the modal content div
  var modalContentDiv = document.createElement('div');
  modalContentDiv.className = 'qwebr-modal-content';

  // Create the span for closing the modal
  var closeSpan = document.createElement('span');
  closeSpan.id = 'qwebr-command-history-close-btn';
  closeSpan.className = 'qwebr-modal-close';
  closeSpan.innerHTML = '&times;';

  // Create the h1 element for the modal
  var modalH1 = document.createElement('h1');
  modalH1.textContent = 'R History Command Contents';

  // Create an anchor element for downloading the Rhistory file 
  var downloadLink = document.createElement('a');
  downloadLink.href = '#';
  downloadLink.id = 'qwebr-download-history-btn';
  downloadLink.className = 'qwebr-download-btn';

  // Create an 'i' element for the icon
  var icon = document.createElement('i');
  icon.className = 'bi bi-file-code';

  // Append the icon to the anchor element
  downloadLink.appendChild(icon);

  // Add the text 'Download R History' to the anchor element
  downloadLink.appendChild(document.createTextNode(' Download R History File'));

  // Create the pre for command history contents
  var commandContentsPre = document.createElement('pre');
  commandContentsPre.id = 'qwebr-command-history-contents';
  commandContentsPre.className = 'qwebr-modal-content-code';

  // Append the close span, h1, and history contents pre to the modal content div
  modalContentDiv.appendChild(closeSpan);
  modalContentDiv.appendChild(modalH1);
  modalContentDiv.appendChild(downloadLink);
  modalContentDiv.appendChild(commandContentsPre);

  // Append the modal content div to the modal div
  modalDiv.appendChild(modalContentDiv);

  // Append the modal div to the body
  document.body.appendChild(modalDiv);
}

function qwebrRegisterRevealJSCommandHistoryModal() {
  // Select the <ul> element inside the <div> with data-panel="Custom0"
  let ulElement = document.querySelector('div[data-panel="Custom0"] > ul.slide-menu-items');

  // Find the last <li> element with class slide-tool-item
  let lastItem = ulElement.querySelector('li.slide-tool-item:last-child');

  // Calculate the next data-item value
  let nextItemValue = 0;
  if (lastItem) {
      nextItemValue = parseInt(lastItem.dataset.item) + 1;
  }

  // Create a new <li> element
  let newListItem = document.createElement('li');
  newListItem.className = 'slide-tool-item';
  newListItem.dataset.item = nextItemValue.toString(); // Set the next available data-item value

  // Create the <a> element inside the <li>
  let newLink = document.createElement('a');
  newLink.href = '#';
  newLink.id = 'qwebrRHistoryButton'; // Set the ID for the new link
  
  // Create the <kbd> element inside the <a>
  let newKbd = document.createElement('kbd');
  newKbd.textContent = ' '; // Set to empty as we are not registering a keyboard shortcut

  // Create text node for the link text
  let newText = document.createTextNode(' View R History');

  // Append <kbd> and text node to <a>
  newLink.appendChild(newKbd);
  newLink.appendChild(newText);

  // Append <a> to <li>
  newListItem.appendChild(newLink);

  // Append <li> to <ul>
  ulElement.appendChild(newListItem);
}

// Handle setting up the R history modal
function qwebrCodeLinks() {

  if (qwebrIsRevealJS()) {
    qwebrRegisterRevealJSCommandHistoryModal();
    return;
  }

  // Create the container div
  var containerDiv = document.createElement('div');
  containerDiv.className = 'quarto-code-links';

  // Create the h2 element
  var h2 = document.createElement('h2');
  h2.textContent = 'webR Code Links';

  // Create the ul element
  var ul = document.createElement('ul');

  // Create the li element
  var li = document.createElement('li');

  // Create the a_history_btn element
  var a_history_btn = document.createElement('a');
  a_history_btn.href = 'javascript:void(0)';
  a_history_btn.setAttribute('id', 'qwebrRHistoryButton');

  // Create the i_history_btn element
  var i_history_btn = document.createElement('i');
  i_history_btn.className = 'bi bi-file-code';

  // Create the text node for the link text
  var text_history_btn = document.createTextNode('View R History');

  // Append the icon element and link text to the a element
  a_history_btn.appendChild(i_history_btn);
  a_history_btn.appendChild(text_history_btn);

  // Append the a element to the li element
  li.appendChild(a_history_btn);

  // Append the li element to the ul element
  ul.appendChild(li);

  // Append the h2 and ul elements to the container div
  containerDiv.appendChild(h2);
  containerDiv.appendChild(ul);

  // Append the container div to the element with the ID 'quarto-margin-sidebar'
  var sidebar = document.getElementById('quarto-margin-sidebar');
    
  // If the sidebar element is not found, create it
  if(!sidebar) {
    qwebrPlaceQuartoSidebar();
  }
  
  // Re-select the sidebar element (if it was just created)
  sidebar = document.getElementById('quarto-margin-sidebar');   


  // If the sidebar element exists, append the container div to it
  if(sidebar) {
    // Append the container div to the sidebar
    sidebar.appendChild(containerDiv);
    // Force the sidebar to be clickable by removing the 'zindex-bottom' class
    // added in pre-release: https://github.com/quarto-dev/quarto-cli/commit/f0c53a1ffcaa1de4eccbf07803b096898248adcc
    sidebar.className = 'sidebar margin-sidebar';
  } else {
    // Get a debugger ...
    console.warn('Element with ID "quarto-margin-sidebar" not found.');
  }
}

// Call the function to append the code links for qwebR into the right sidebar
qwebrCodeLinks();

// Add the command history modal
qwebrAddCommandHistoryModal();

displayStartupMessage(qwebrShowStartupMessage, qwebrShowHeaderMessage);
qwebrOffScreenCanvasSupportWarningMessage();
</script>
<script type="module">
// Define a global storage and retrieval solution ----

// Store commands executed in R
globalThis.qwebrRCommandHistory = [];

// Function to retrieve the command history
globalThis.qwebrFormatRHistory = function() {
   return qwebrRCommandHistory.join("\n\n");
}

// Retrieve HTML Elements ----

// Get the command modal
const command_history_modal = document.getElementById("qwebr-history-modal");

// Get the button that opens the command modal
const command_history_btn = document.getElementById("qwebrRHistoryButton");

// Get the <span> element that closes the command modal
const command_history_close_span = document.getElementById("qwebr-command-history-close-btn");

// Get the download button for r history information
const command_history_download_btn = document.getElementById("qwebr-download-history-btn");

// Plug in command history into modal/download button ----

// Function to populate the modal with command history
function populateCommandHistoryModal() {
    document.getElementById("qwebr-command-history-contents").innerHTML = qwebrFormatRHistory() || "No commands have been executed yet.";
}

// Function to format the current date and time to
// a string with the format YYYY-MM-DD-HH-MM-SS
function formatDateTime() {
    const now = new Date();

    const year = now.getFullYear();
    const day = String(now.getDate()).padStart(2, '0');
    const month = String(now.getMonth() + 1).padStart(2, '0'); // Months are zero-based
    const hours = String(now.getHours()).padStart(2, '0');
    const minutes = String(now.getMinutes()).padStart(2, '0');
    const seconds = String(now.getSeconds()).padStart(2, '0');

    return `${year}-${month}-${day}-${hours}-${minutes}-${seconds}`;
}


// Function to convert document title with datetime to a safe filename
function safeFileName() {
    // Get the current page title
    let pageTitle = document.title;

    // Combine the current page title with the current date and time
    let pageNameWithDateTime = `Rhistory-${pageTitle}-${formatDateTime()}`;

    // Replace unsafe characters with safe alternatives
    let safeFilename = pageNameWithDateTime.replace(/[\\/:\*\?! "<>\|]/g, '-');

    return safeFilename;
}


// Function to download list contents as text file
function downloadRHistory() {
    // Get the current page title + datetime and use it as the filename
    const filename = `${safeFileName()}.R`;

    // Get the text contents of the R History list
    const text = qwebrFormatRHistory();

    // Create a new Blob object with the text contents
    const blob = new Blob([text], { type: 'text/plain' });
  
    // Create a new anchor element for the download
    const a = document.createElement('a');
    a.style.display = 'none';
    a.href = URL.createObjectURL(blob);
    a.download = filename;

    // Append the anchor to the body, click it, and remove it
    document.body.appendChild(a);
    a.click();
    document.body.removeChild(a);
}

// Register event handlers ----

// When the user clicks the View R History button, open the command modal
command_history_btn.onclick = function() {
    populateCommandHistoryModal();
    command_history_modal.style.display = "block";
}

// When the user clicks on <span> (x), close the command modal
command_history_close_span.onclick = function() {
    command_history_modal.style.display = "none";
}

// When the user clicks anywhere outside of the command modal, close it
window.onclick = function(event) {
    if (event.target == command_history_modal) {
        command_history_modal.style.display = "none";
    }
}

// Add an onclick event listener to the download button so that
// the user can download the R history as a text file
command_history_download_btn.onclick = function() {
    downloadRHistory();
};
</script>
<script type="module">
// Supported Evaluation Types for Context
globalThis.EvalTypes = Object.freeze({
  Interactive: 'interactive',
  Setup: 'setup',
  Output: 'output',
});

// Function that obtains the font size for a given element 
globalThis.qwebrCurrentFontSizeOnElement = function(element, cssProperty = 'font-size') {

  const currentFontSize = parseFloat(
    window
    .getComputedStyle(element)
    .getPropertyValue(cssProperty)
  );
  
  return currentFontSize;
}

// Function to determine font scaling
globalThis.qwebrScaledFontSize = function(div, qwebrOptions) {
  // Determine if we should compute font-size using RevealJS's `--r-main-font-size` 
  // or if we can directly use the document's `font-size`.
  const cssProperty = document.body.classList.contains('reveal') ? 
    "--r-main-font-size" : "font-size";
  
  // Get the current font size on the div element
  const elementFontSize = qwebrCurrentFontSizeOnElement(div, cssProperty);

  // Determine the scaled font size value
  const scaledFontSize = ((qwebrOptions['editor-font-scale'] ?? 1) * elementFontSize) ?? 17.5;

  return scaledFontSize;
}


// Function that dispatches the creation request
globalThis.qwebrCreateHTMLElement = function (
  cellData
) {

  // Extract key components
  const evalType = cellData.options.context;
  const qwebrCounter = cellData.id;

  // We make an assumption that insertion points are defined by the Lua filter as:
  // qwebr-insertion-location-{qwebrCounter} 
  const elementLocator = document.getElementById(`qwebr-insertion-location-${qwebrCounter}`);

  // Figure out the routine to use to insert the element.
  let qwebrElement;
  switch ( evalType ) {
    case EvalTypes.Interactive:
      qwebrElement = qwebrCreateInteractiveElement(qwebrCounter, cellData.options);
      break;
    case EvalTypes.Output: 
      qwebrElement = qwebrCreateNonInteractiveOutputElement(qwebrCounter, cellData.options);
      break;
    case EvalTypes.Setup: 
      qwebrElement = qwebrCreateNonInteractiveSetupElement(qwebrCounter, cellData.options);
      break;
    default: 
      qwebrElement = document.createElement('div');
      qwebrElement.textContent = 'Error creating `quarto-webr` element';
  }

  // Insert the dynamically generated object at the document location.
  elementLocator.appendChild(qwebrElement);
};

// Function that setups the interactive element creation
globalThis.qwebrCreateInteractiveElement = function (qwebrCounter, qwebrOptions) {

  // Create main div element
  var mainDiv = document.createElement('div');
  mainDiv.id = 'qwebr-interactive-area-' + qwebrCounter;
  mainDiv.className = `qwebr-interactive-area`;
  if (qwebrOptions.classes) {
    mainDiv.className += " " + qwebrOptions.classes
  }

  // Add a unique cell identifier that users can customize
  if (qwebrOptions.label) {
    mainDiv.setAttribute('data-id', qwebrOptions.label);
  }

  // Create toolbar div
  var toolbarDiv = document.createElement('div');
  toolbarDiv.className = 'qwebr-editor-toolbar';
  toolbarDiv.id = 'qwebr-editor-toolbar-' + qwebrCounter;

  // Create a div to hold the left buttons
  var leftButtonsDiv = document.createElement('div');
  leftButtonsDiv.className = 'qwebr-editor-toolbar-left-buttons';

  // Create a div to hold the right buttons
  var rightButtonsDiv = document.createElement('div');
  rightButtonsDiv.className = 'qwebr-editor-toolbar-right-buttons';

  // Create Run Code button
  var runCodeButton = document.createElement('button');
  runCodeButton.className = 'btn btn-default qwebr-button qwebr-button-run';
  runCodeButton.disabled = true;
  runCodeButton.type = 'button';
  runCodeButton.id = 'qwebr-button-run-' + qwebrCounter;
  runCodeButton.textContent = '🟡 Loading webR...';
  runCodeButton.title = `Run code (Shift + Enter)`;

  // Append buttons to the leftButtonsDiv
  leftButtonsDiv.appendChild(runCodeButton);

  // Create Reset button
  var resetButton = document.createElement('button');
  resetButton.className = 'btn btn-light btn-xs qwebr-button qwebr-button-reset';
  resetButton.type = 'button';
  resetButton.id = 'qwebr-button-reset-' + qwebrCounter;
  resetButton.title = 'Start over';
  resetButton.innerHTML = '<i class="fa-solid fa-arrows-rotate"></i>';

  // Create Copy button
  var copyButton = document.createElement('button');
  copyButton.className = 'btn btn-light btn-xs qwebr-button qwebr-button-copy';
  copyButton.type = 'button';
  copyButton.id = 'qwebr-button-copy-' + qwebrCounter;
  copyButton.title = 'Copy code';
  copyButton.innerHTML = '<i class="fa-regular fa-copy"></i>';

  // Append buttons to the rightButtonsDiv
  rightButtonsDiv.appendChild(resetButton);
  rightButtonsDiv.appendChild(copyButton);

  // Create console area div
  var consoleAreaDiv = document.createElement('div');
  consoleAreaDiv.id = 'qwebr-console-area-' + qwebrCounter;
  consoleAreaDiv.className = 'qwebr-console-area';

  // Create editor div
  var editorDiv = document.createElement('div');
  editorDiv.id = 'qwebr-editor-' + qwebrCounter;
  editorDiv.className = 'qwebr-editor';

  // Create output code area div
  var outputCodeAreaDiv = document.createElement('div');
  outputCodeAreaDiv.id = 'qwebr-output-code-area-' + qwebrCounter;
  outputCodeAreaDiv.className = 'qwebr-output-code-area';
  outputCodeAreaDiv.setAttribute('aria-live', 'assertive');

  // Create pre element inside output code area
  var preElement = document.createElement('pre');
  preElement.style.visibility = 'hidden';
  outputCodeAreaDiv.appendChild(preElement);

  // Create output graph area div
  var outputGraphAreaDiv = document.createElement('div');
  outputGraphAreaDiv.id = 'qwebr-output-graph-area-' + qwebrCounter;
  outputGraphAreaDiv.className = 'qwebr-output-graph-area';

  // Append buttons to the toolbar
  toolbarDiv.appendChild(leftButtonsDiv);
  toolbarDiv.appendChild(rightButtonsDiv);

  // Append all elements to the main div
  mainDiv.appendChild(toolbarDiv);
  consoleAreaDiv.appendChild(editorDiv);
  consoleAreaDiv.appendChild(outputCodeAreaDiv);
  mainDiv.appendChild(consoleAreaDiv);
  mainDiv.appendChild(outputGraphAreaDiv);

  return mainDiv;
}

// Function that adds output structure for non-interactive output
globalThis.qwebrCreateNonInteractiveOutputElement = function(qwebrCounter, qwebrOptions) {
  // Create main div element
  var mainDiv = document.createElement('div');
  mainDiv.id = 'qwebr-noninteractive-area-' + qwebrCounter;
  mainDiv.className = `qwebr-noninteractive-area`;
  if (qwebrOptions.classes) {
    mainDiv.className += " " + qwebrOptions.classes
  }
  
  // Add a unique cell identifier that users can customize
  if (qwebrOptions.label) {
    mainDiv.setAttribute('data-id', qwebrOptions.label);
  }
  
  // Create a status container div
  var statusContainer = createLoadingContainer(qwebrCounter);

  // Create output code area div
  var outputCodeAreaDiv = document.createElement('div');
  outputCodeAreaDiv.id = 'qwebr-output-code-area-' + qwebrCounter;
  outputCodeAreaDiv.className = 'qwebr-output-code-area';
  outputCodeAreaDiv.setAttribute('aria-live', 'assertive');

  // Create pre element inside output code area
  var preElement = document.createElement('pre');
  preElement.style.visibility = 'hidden';
  outputCodeAreaDiv.appendChild(preElement);

  // Create output graph area div
  var outputGraphAreaDiv = document.createElement('div');
  outputGraphAreaDiv.id = 'qwebr-output-graph-area-' + qwebrCounter;
  outputGraphAreaDiv.className = 'qwebr-output-graph-area';

  // Append all elements to the main div
  mainDiv.appendChild(statusContainer);
  mainDiv.appendChild(outputCodeAreaDiv);
  mainDiv.appendChild(outputGraphAreaDiv);

  return mainDiv;
};

// Function that adds a stub in the page to indicate a setup cell was used.
globalThis.qwebrCreateNonInteractiveSetupElement = function(qwebrCounter, qwebrOptions) {
  // Create main div element
  var mainDiv = document.createElement('div');
  mainDiv.id = `qwebr-noninteractive-setup-area-${qwebrCounter}`;
  mainDiv.className = `qwebr-noninteractive-setup-area`;
  if (qwebrOptions.classes) {
    mainDiv.className += " " + qwebrOptions.classes
  }


  // Add a unique cell identifier that users can customize
  if (qwebrOptions.label) {
    mainDiv.setAttribute('data-id', qwebrOptions.label);
  }

  // Create a status container div
  var statusContainer = createLoadingContainer(qwebrCounter);

  // Append status onto the main div
  mainDiv.appendChild(statusContainer);

  return mainDiv;
}


// Function to create loading container with specified ID
globalThis.createLoadingContainer = function(qwebrCounter) {

  // Create a status container
  const container = document.createElement('div');
  container.id = `qwebr-non-interactive-loading-container-${qwebrCounter}`;
  container.className = 'qwebr-non-interactive-loading-container qwebr-cell-needs-evaluation';

  // Create an R project logo to indicate its a code space
  const rProjectIcon = document.createElement('i');
  rProjectIcon.className = 'fa-brands fa-r-project fa-3x qwebr-r-project-logo';

  // Setup a loading icon from font awesome
  const spinnerIcon = document.createElement('i');
  spinnerIcon.className = 'fa-solid fa-spinner fa-spin fa-1x qwebr-icon-status-spinner';

  // Add a section for status text
  const statusText = document.createElement('p');
  statusText.id = `qwebr-status-text-${qwebrCounter}`;
  statusText.className = `qwebr-status-text qwebr-cell-needs-evaluation`;
  statusText.innerText = 'Loading webR...';

  // Incorporate an inner container
  const innerContainer = document.createElement('div');

  // Append elements to the inner container
  innerContainer.appendChild(spinnerIcon);
  innerContainer.appendChild(statusText);

  // Append elements to the main container
  container.appendChild(rProjectIcon);
  container.appendChild(innerContainer);

  return container;
}
</script>
<script type="module">
// Function to install a single package
async function qwebrInstallRPackage(packageName) {
  await mainWebR.evalRVoid(`webr::install('${packageName}');`);
}

// Function to load a single package
async function qwebrLoadRPackage(packageName) {
  await mainWebR.evalRVoid(`require('${packageName}', quietly = TRUE)`);
}

// Generic function to process R packages
async function qwebrProcessRPackagesWithStatus(packages, processType, displayStatusMessageUpdate = true) {
  // Switch between contexts
  const messagePrefix = processType === 'install' ? 'Installing' : 'Loading';

  // Modify button state
  qwebrSetInteractiveButtonState(`🟡 ${messagePrefix} package ...`, false);

  // Iterate over packages
  for (let i = 0; i < packages.length; i++) {
    const activePackage = packages[i];
    const formattedMessage = `${messagePrefix} package ${i + 1} out of ${packages.length}: ${activePackage}`;

    // Display the update in header
    if (displayStatusMessageUpdate) {
      qwebrUpdateStatusHeader(formattedMessage);
    }

    // Display the update in non-active areas
    qwebrUpdateStatusMessage(formattedMessage);

    // Run package installation
    if (processType === 'install') {
      await qwebrInstallRPackage(activePackage);
    } else {
      await qwebrLoadRPackage(activePackage);
    }
  }

  // Clean slate
  if (processType === 'load') {
    await mainWebR.flush();
  }
}

// Start a timer
const initializeWebRTimerStart = performance.now();

// Encase with a dynamic import statement
globalThis.qwebrInstance = import(qwebrCustomizedWebROptions.baseURL + "webr.mjs").then(
  async ({ WebR, ChannelType }) => {
    // Populate WebR options with defaults or new values based on `webr` meta
    globalThis.mainWebR = new WebR(qwebrCustomizedWebROptions);

    // Initialization WebR
    await mainWebR.init();

    // Setup a shelter
    globalThis.mainWebRCodeShelter = await new mainWebR.Shelter();

    // Setup a pager to allow processing help documentation
    await mainWebR.evalRVoid('webr::pager_install()');

    // Setup a viewer to allow processing htmlwidgets.
    // This might not be available in old webr version
    await mainWebR.evalRVoid('try({ webr::viewer_install() })');

    // Override the existing install.packages() to use webr::install()
    await mainWebR.evalRVoid('webr::shim_install()');

    // Specify the repositories to pull from
    // Note: webR does not use the `repos` option, but instead uses `webr_pkg_repos`
    // inside of `install()`. However, other R functions still pull from `repos`.
    await mainWebR.evalRVoid(`
      options(
        webr_pkg_repos = c(${qwebrPackageRepoURLS.map(repoURL => `'${repoURL}'`).join(',')}),
        repos = c(${qwebrPackageRepoURLS.map(repoURL => `'${repoURL}'`).join(',')})
      )
    `);

    // Check to see if any packages need to be installed
    if (qwebrSetupRPackages) {
      // Obtain only a unique list of packages
      const uniqueRPackageList = Array.from(new Set(qwebrInstallRPackagesList));

      // Install R packages one at a time (either silently or with a status update)
      await qwebrProcessRPackagesWithStatus(uniqueRPackageList, 'install', qwebrShowStartupMessage);

      if (qwebrAutoloadRPackages) {
        // Load R packages one at a time (either silently or with a status update)
        await qwebrProcessRPackagesWithStatus(uniqueRPackageList, 'load', qwebrShowStartupMessage);
      }
    }
  }
);

// Stop timer
const initializeWebRTimerEnd = performance.now();

</script>
<script type="module">
// Function to verify a given JavaScript Object is empty
globalThis.qwebrIsObjectEmpty = function (arr) {
    return Object.keys(arr).length === 0;
}

// Global version of the Escape HTML function that converts HTML
// characters to their HTML entities.
globalThis.qwebrEscapeHTMLCharacters = function(unsafe) {
    return unsafe
      .replace(/&/g, "&amp;")
      .replace(/</g, "&lt;")
      .replace(/>/g, "&gt;")
      .replace(/"/g, "&quot;")
      .replace(/'/g, "&#039;");
};

// Passthrough results
globalThis.qwebrIdentity = function(x) {
    return x;
};

// Append a comment
globalThis.qwebrPrefixComment = function(x, comment) {
    return `${comment}${x}`;
};

// Function to store the code in the history
globalThis.qwebrLogCodeToHistory = function(codeToRun, options) {
    qwebrRCommandHistory.push(
        `# Ran code in ${options.label} at ${new Date().toLocaleString()} ----\n${codeToRun}`
    );
};

// Function to attach a download button onto the canvas
// allowing the user to download the image.
function qwebrImageCanvasDownloadButton(canvas, canvasContainer) {

    // Create the download button
    const downloadButton = document.createElement('button');
    downloadButton.className = 'qwebr-canvas-image-download-btn';
    downloadButton.textContent = 'Download Image';
    canvasContainer.appendChild(downloadButton);

    // Trigger a download of the image when the button is clicked
    downloadButton.addEventListener('click', function() {
        const image = canvas.toDataURL('image/png');
        const link = document.createElement('a');
        link.href = image;
        link.download = 'qwebr-canvas-image.png';
        link.click();
    });
}


// Function to parse the pager results
globalThis.qwebrParseTypePager = async function (msg) {

    // Split out the event data
    const { path, title, deleteFile } = msg.data;

    // Process the pager data by reading the information from disk
    const paged_data = await mainWebR.FS.readFile(path).then((data) => {
        // Obtain the file content
        let content = new TextDecoder().decode(data);

        // Remove excessive backspace characters until none remain
        while(content.match(/.[\b]/)){
            content = content.replace(/.[\b]/g, '');
        }

        // Returned cleaned data
        return content;
    });

    // Unlink file if needed
    if (deleteFile) {
        await mainWebR.FS.unlink(path);
    }

    // Return extracted data with spaces
    return paged_data;
};


// Function to parse the browse results
globalThis.qwebrParseTypeBrowse = async function (msg) {

    // msg.type === "browse"
    const path = msg.data.url;

    // Process the browse data by reading the information from disk
    const browse_data = await mainWebR.FS.readFile(path).then((data) => {
        // Obtain the file content
        let content = new TextDecoder().decode(data);

        return content;
    });

    // Return extracted data as-is
    return browse_data;
};

// Function to run the code using webR and parse the output
globalThis.qwebrComputeEngine = async function(
    codeToRun,
    elements,
    options) {

    // Call into the R compute engine that persists within the document scope.
    // To be prepared for all scenarios, the following happens:
    // 1. We setup a canvas device to write to by making a namespace call into the {webr} package
    // 2. We use values inside of the options array to set the figure size.
    // 3. We capture the output stream information (STDOUT and STERR)
    // 4. We disable the current device's image creation.
    // 5. Piece-wise parse the results into the different output areas

    // Create a pager variable for help/file contents
    let pager = [];

    // Handle how output is processed
    let showMarkup = options.results === "markup" && options.output !== "asis";
    let processOutput;

    if (showMarkup) {
        processOutput = qwebrEscapeHTMLCharacters;
    } else {
        processOutput = qwebrIdentity;
    }

    // ----
    // Convert from Inches to Pixels by using DPI (dots per inch)
    // for bitmap devices (dpi * inches = pixels)
    let fig_width = options["fig-width"] * options["dpi"];
    let fig_height = options["fig-height"] * options["dpi"];

    // Initialize webR
    await mainWebR.init();

    // Configure capture output
    let captureOutputOptions = {
        withAutoprint: true,
        captureStreams: true,
        captureConditions: false,
        // env: webR.objs.emptyEnv, // maintain a global environment for webR v0.2.0
    };

    // Determine if the browser supports OffScreen
    if (qwebrOffScreenCanvasSupport()) {
        // Mirror default options of webr::canvas()
        // with changes to figure height and width.
        captureOutputOptions.captureGraphics = {
            width: fig_width,
            height: fig_height,
            bg: "white", // default: transparent
            pointsize: 12,
            capture: true
        };
    }  else {
        // Disable generating graphics
        captureOutputOptions.captureGraphics = false;
    }

    // Store the code to run in history
    qwebrLogCodeToHistory(codeToRun, options);

    // Setup a webR canvas by making a namespace call into the {webr} package
    // Evaluate the R code
    // Remove the active canvas silently
    const result = await mainWebRCodeShelter.captureR(
        `${codeToRun}`,
        captureOutputOptions
    );

    // -----

    // Start attempting to parse the result data
    processResultOutput:try {

        // Avoid running through output processing
        if (options.results === "hide" || options.output === "false") {
            break processResultOutput;
        }

        // Merge output streams of STDOUT and STDErr (messages and errors are combined.)
        // Require both `warning` and `message` to be true to display `STDErr`.
        const out = result.output
        .filter(
            evt => evt.type === "stdout" ||
            ( evt.type === "stderr" && (options.warning === "true" && options.message === "true"))
        )
        .map((evt, index) => {
            const className = `qwebr-output-code-${evt.type}`;
            const outputResult = qwebrPrefixComment(processOutput(evt.data), options.comment);
            return `<code id="${className}-editor-${elements.id}-result-${index + 1}" class="${className}">${outputResult}</code>`;
        })
        .join("\n");


        // Clean the state
        // We're now able to process pager events.
        // As a result, we cannot maintain a true 1-to-1 output order
        // without individually feeding each line
        const msgs = await mainWebR.flush();

        // Use `map` to process the filtered "pager" events asynchronously
        const pager = [];
        const browse = [];

        await Promise.all(
            msgs.map(
                async (msg) => {

                    const msgType = msg.type || "unknown";

                    switch(msgType) {
                        case 'pager':
                            const pager_data = await qwebrParseTypePager(msg);
                            pager.push(pager_data);
                            break;
                        case 'browse':
                            const browse_data = await qwebrParseTypeBrowse(msg);
                            browse.push(browse_data);
                            break;
                    }
                    return;
                }
            )
        );

        // Nullify the output area of content
        elements.outputCodeDiv.innerHTML = "";
        elements.outputGraphDiv.innerHTML = "";

        // Design an output object for messages
        const pre = document.createElement("pre");
        if (/\S/.test(out)) {
            // Display results as HTML elements to retain output styling
            const div = document.createElement("div");
            div.innerHTML = out;

            // Calculate a scaled font-size value
            const scaledFontSize = qwebrScaledFontSize(
                elements.outputCodeDiv, options);

            // Override output code cell size
            pre.style.fontSize = `${scaledFontSize}px`;
            pre.appendChild(div);
        } else {
            // If nothing is present, hide the element.
            pre.style.visibility = "hidden";
        }

        elements.outputCodeDiv.appendChild(pre);

        // Determine if we have graphs to display
        if (result.images.length > 0) {

            // Create figure element
            const figureElement = document.createElement("figure");
            figureElement.className = "qwebr-canvas-image";

            // Place each rendered graphic onto a canvas element
            result.images.forEach((img) => {

                // Construct canvas for object
                const canvas = document.createElement("canvas");

                // Add an image download button
                qwebrImageCanvasDownloadButton(canvas, figureElement);

                // Set canvas size to image
                canvas.width = img.width;
                canvas.height = img.height;

                // Apply output truncations
                canvas.style.width = options["out-width"] ? options["out-width"] : `${fig_width}px`;
                if (options["out-height"]) {
                    canvas.style.height = options["out-height"];
                }

                // Apply styling
                canvas.style.display = "block";
                canvas.style.margin = "auto";

                // Draw image onto Canvas
                const ctx = canvas.getContext("2d");
                ctx.drawImage(img, 0, 0, img.width, img.height);

                // Append canvas to figure output area
                figureElement.appendChild(canvas);

            });

            if (options['fig-cap']) {
                // Create figcaption element
                const figcaptionElement = document.createElement('figcaption');
                figcaptionElement.innerText = options['fig-cap'];
                // Append figcaption to figure
                figureElement.appendChild(figcaptionElement);
            }

            elements.outputGraphDiv.appendChild(figureElement);

        }

        // Display the pager data
        if (pager.length > 0) {
            // Use the `pre` element to preserve whitespace.
            pager.forEach((paged_data, index) => {
                const pre_pager = document.createElement("pre");
                pre_pager.innerText = paged_data;
                pre_pager.classList.add("qwebr-output-code-pager");
                pre_pager.setAttribute("id", `qwebr-output-code-pager-editor-${elements.id}-result-${index + 1}`);
                elements.outputCodeDiv.appendChild(pre_pager);
            });
        }

        // Display the browse data
        if (browse.length > 0) {
            // Use the `pre` element to preserve whitespace.
            browse.forEach((browse_data, index) => {
                const iframe_browse = document.createElement('iframe');
                iframe_browse.classList.add("qwebr-output-code-browse");
                iframe_browse.setAttribute("id", `qwebr-output-code-browse-editor-${elements.id}-result-${index + 1}`);
                iframe_browse.style.width = "100%";
                iframe_browse.style.minHeight = "500px";
                elements.outputCodeDiv.appendChild(iframe_browse);

                iframe_browse.contentWindow.document.open();
                iframe_browse.contentWindow.document.write(browse_data);
                iframe_browse.contentWindow.document.close();
            });
        }
    } finally {
        // Clean up the remaining code
        mainWebRCodeShelter.purge();
    }
};

// Function to execute the code (accepts code as an argument)
globalThis.qwebrExecuteCode = async function (
    codeToRun,
    id,
    options = {}) {

    // If options are not passed, we fall back on the bare minimum to handle the computation
    if (qwebrIsObjectEmpty(options)) {
        options = {
            "context": "interactive",
            "fig-width": 7, "fig-height": 5,
            "out-width": "700px", "out-height": "",
            "dpi": 72,
            "results": "markup",
            "warning": "true", "message": "true",
        };
    }

    // Next, we access the compute areas values
    const elements = {
        runButton: document.getElementById(`qwebr-button-run-${id}`),
        outputCodeDiv: document.getElementById(`qwebr-output-code-area-${id}`),
        outputGraphDiv: document.getElementById(`qwebr-output-graph-area-${id}`),
        id: id,
    }

    // Disallowing execution of other code cells
    document.querySelectorAll(".qwebr-button-run").forEach((btn) => {
        btn.disabled = true;
    });

    if (options.context == EvalTypes.Interactive) {
        // Emphasize the active code cell
        elements.runButton.innerHTML = '<i class="fa-solid fa-spinner fa-spin qwebr-icon-status-spinner"></i> <span>Run Code</span>';
    }

    // Evaluate the code and parse the output into the document
    await qwebrComputeEngine(codeToRun, elements, options);

    // Switch to allowing execution of code
    document.querySelectorAll(".qwebr-button-run").forEach((btn) => {
        btn.disabled = false;
    });

    if (options.context == EvalTypes.Interactive) {
        // Revert to the initial code cell state
        elements.runButton.innerHTML = '<i class="fa-solid fa-play qwebr-icon-run-code"></i> <span>Run Code</span>';
    }
}

</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN" && texText && texText.data) {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../libs/style.css">
</head>

<body class="nav-sidebar floating quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../chapters/clustring.html">Clustering</a></li><li class="breadcrumb-item"><a href="../chapters/clustring.html"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Clustering</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header sidebar-header-stacked">
      <a href="../index.html" class="sidebar-logo-link">
      </a>
    <div class="sidebar-title mb-0 py-0">
      <a href="../">Statistics and Information Systems</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Note</span></span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Explanatory Data Analysis</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/chapter4_EDA.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Exploratory data analysis (EDA)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/chapter3_dplyr.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Data Wrangling</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/chapter2_data_visualization.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Data Visualization</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/project.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Project</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/Exam-Sample.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Sample of Questions</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/Outlier_Detection.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Outlier Detection: Understading and Handling</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/missing_values.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Missing Values</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/Decision_trees.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Decision Trees</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">Clustering</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/clustring.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Clustering</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text">Classification</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/chapter5_logistic_regression.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Logistic Regression</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true">
 <span class="menu-text">Data</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/chapter1_data_ethics.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Data Ethics</span></span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#applications-of-clustering" id="toc-applications-of-clustering" class="nav-link active" data-scroll-target="#applications-of-clustering"><span class="header-section-number">10.1</span> Applications of Clustering</a></li>
  <li><a href="#distance-and-similarity-in-clustering" id="toc-distance-and-similarity-in-clustering" class="nav-link" data-scroll-target="#distance-and-similarity-in-clustering"><span class="header-section-number">10.2</span> Distance and Similarity in Clustering</a>
  <ul>
  <li><a href="#common-distance-metrics" id="toc-common-distance-metrics" class="nav-link" data-scroll-target="#common-distance-metrics"><span class="header-section-number">10.2.1</span> Common Distance Metrics</a>
  <ul class="collapse">
  <li><a href="#euclidean-distance" id="toc-euclidean-distance" class="nav-link" data-scroll-target="#euclidean-distance"><span class="header-section-number">10.2.1.1</span> <strong>Euclidean Distance</strong></a></li>
  <li><a href="#manhattan-or-city-block-distance" id="toc-manhattan-or-city-block-distance" class="nav-link" data-scroll-target="#manhattan-or-city-block-distance"><span class="header-section-number">10.2.1.2</span> <strong>Manhattan (or City-Block) Distance</strong></a></li>
  <li><a href="#minkowski-distance" id="toc-minkowski-distance" class="nav-link" data-scroll-target="#minkowski-distance"><span class="header-section-number">10.2.1.3</span> <strong>Minkowski Distance</strong></a></li>
  <li><a href="#chebyshev-distance" id="toc-chebyshev-distance" class="nav-link" data-scroll-target="#chebyshev-distance"><span class="header-section-number">10.2.1.4</span> Chebyshev Distance</a></li>
  <li><a href="#mahalanobis-distance" id="toc-mahalanobis-distance" class="nav-link" data-scroll-target="#mahalanobis-distance"><span class="header-section-number">10.2.1.5</span> <strong>Mahalanobis Distance</strong></a></li>
  <li><a href="#cosine-and-correlation-distance" id="toc-cosine-and-correlation-distance" class="nav-link" data-scroll-target="#cosine-and-correlation-distance"><span class="header-section-number">10.2.1.6</span> Cosine and Correlation Distance</a></li>
  </ul></li>
  <li><a href="#distances-for-binary-data" id="toc-distances-for-binary-data" class="nav-link" data-scroll-target="#distances-for-binary-data"><span class="header-section-number">10.2.2</span> Distances for Binary Data</a>
  <ul class="collapse">
  <li><a href="#simple-matching-coefficient-similarity" id="toc-simple-matching-coefficient-similarity" class="nav-link" data-scroll-target="#simple-matching-coefficient-similarity"><span class="header-section-number">10.2.2.1</span> <strong>Simple Matching Coefficient (Similarity)</strong></a></li>
  <li><a href="#simple-matching-distance" id="toc-simple-matching-distance" class="nav-link" data-scroll-target="#simple-matching-distance"><span class="header-section-number">10.2.2.2</span> <strong>Simple Matching Distance</strong></a></li>
  </ul></li>
  <li><a href="#distances-for-categorical-data" id="toc-distances-for-categorical-data" class="nav-link" data-scroll-target="#distances-for-categorical-data"><span class="header-section-number">10.2.3</span> Distances for Categorical Data</a>
  <ul class="collapse">
  <li><a href="#hamming-distance" id="toc-hamming-distance" class="nav-link" data-scroll-target="#hamming-distance"><span class="header-section-number">10.2.3.1</span> <strong>Hamming Distance</strong></a></li>
  <li><a href="#gower-distance" id="toc-gower-distance" class="nav-link" data-scroll-target="#gower-distance"><span class="header-section-number">10.2.3.2</span> <strong>Gower Distance</strong></a></li>
  </ul></li>
  <li><a href="#visualizing-distance-matrices" id="toc-visualizing-distance-matrices" class="nav-link" data-scroll-target="#visualizing-distance-matrices"><span class="header-section-number">10.2.4</span> Visualizing distance matrices</a></li>
  </ul></li>
  <li><a href="#partition-based-clustering-k-means-and-k-medoids" id="toc-partition-based-clustering-k-means-and-k-medoids" class="nav-link" data-scroll-target="#partition-based-clustering-k-means-and-k-medoids"><span class="header-section-number">10.3</span> Partition-Based Clustering: <span class="math inline">\(k\)</span>-Means and <span class="math inline">\(k\)</span>-Medoids</a>
  <ul>
  <li><a href="#k-means-clustering" id="toc-k-means-clustering" class="nav-link" data-scroll-target="#k-means-clustering"><span class="header-section-number">10.3.1</span> <span class="math inline">\(K\)</span>-Means Clustering</a>
  <ul class="collapse">
  <li><a href="#properties-and-limitations-of-k-means" id="toc-properties-and-limitations-of-k-means" class="nav-link" data-scroll-target="#properties-and-limitations-of-k-means"><span class="header-section-number">10.3.1.1</span> Properties and Limitations of <span class="math inline">\(K\)</span>-Means</a></li>
  <li><a href="#measures-of-cluster-quality" id="toc-measures-of-cluster-quality" class="nav-link" data-scroll-target="#measures-of-cluster-quality"><span class="header-section-number">10.3.1.2</span> Measures of Cluster Quality</a></li>
  <li><a href="#analysis-of-iris-dataset" id="toc-analysis-of-iris-dataset" class="nav-link" data-scroll-target="#analysis-of-iris-dataset"><span class="header-section-number">10.3.1.3</span> Analysis of <code>iris</code> Dataset</a></li>
  </ul></li>
  <li><a href="#k-medoids-clustering" id="toc-k-medoids-clustering" class="nav-link" data-scroll-target="#k-medoids-clustering"><span class="header-section-number">10.3.2</span> <span class="math inline">\(K\)</span>-Medoids Clustering</a>
  <ul class="collapse">
  <li><a href="#pam-algorithm" id="toc-pam-algorithm" class="nav-link" data-scroll-target="#pam-algorithm"><span class="header-section-number">10.3.2.1</span> PAM Algorithm</a></li>
  <li><a href="#example" id="toc-example" class="nav-link" data-scroll-target="#example"><span class="header-section-number">10.3.2.2</span> Example</a></li>
  <li><a href="#implementation-pam-in-r" id="toc-implementation-pam-in-r" class="nav-link" data-scroll-target="#implementation-pam-in-r"><span class="header-section-number">10.3.2.3</span> Implementation PAM in R</a></li>
  <li><a href="#estimating-the-optimal-number-of-clusters" id="toc-estimating-the-optimal-number-of-clusters" class="nav-link" data-scroll-target="#estimating-the-optimal-number-of-clusters"><span class="header-section-number">10.3.2.4</span> Estimating the optimal number of clusters</a></li>
  <li><a href="#example-of-pam-in-r" id="toc-example-of-pam-in-r" class="nav-link" data-scroll-target="#example-of-pam-in-r"><span class="header-section-number">10.3.2.5</span> Example of PAM in R</a></li>
  <li><a href="#exercise" id="toc-exercise" class="nav-link" data-scroll-target="#exercise"><span class="header-section-number">10.3.2.6</span> Exercise</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#cluster-validation" id="toc-cluster-validation" class="nav-link" data-scroll-target="#cluster-validation"><span class="header-section-number">10.4</span> Cluster Validation</a>
  <ul>
  <li><a href="#assessing-clustering-tendency" id="toc-assessing-clustering-tendency" class="nav-link" data-scroll-target="#assessing-clustering-tendency"><span class="header-section-number">10.4.1</span> Assessing Clustering Tendency</a>
  <ul class="collapse">
  <li><a href="#methods-for-assessing-clustering-tendency" id="toc-methods-for-assessing-clustering-tendency" class="nav-link" data-scroll-target="#methods-for-assessing-clustering-tendency"><span class="header-section-number">10.4.1.1</span> Methods for assessing clustering tendency</a></li>
  </ul></li>
  <li><a href="#determing-the-optimal-number-of-clusters" id="toc-determing-the-optimal-number-of-clusters" class="nav-link" data-scroll-target="#determing-the-optimal-number-of-clusters"><span class="header-section-number">10.4.2</span> Determing the optimal number of clusters</a>
  <ul class="collapse">
  <li><a href="#elbow-method" id="toc-elbow-method" class="nav-link" data-scroll-target="#elbow-method"><span class="header-section-number">10.4.2.1</span> Elbow method</a></li>
  <li><a href="#average-silhouette-method" id="toc-average-silhouette-method" class="nav-link" data-scroll-target="#average-silhouette-method"><span class="header-section-number">10.4.2.2</span> Average silhouette method</a></li>
  <li><a href="#gap-statistic-method" id="toc-gap-statistic-method" class="nav-link" data-scroll-target="#gap-statistic-method"><span class="header-section-number">10.4.2.3</span> Gap statistic method</a></li>
  <li><a href="#computing-the-number-of-clusters-using-r" id="toc-computing-the-number-of-clusters-using-r" class="nav-link" data-scroll-target="#computing-the-number-of-clusters-using-r"><span class="header-section-number">10.4.2.4</span> Computing the number of clusters using R</a></li>
  </ul></li>
  <li><a href="#cluster-validation-statistics" id="toc-cluster-validation-statistics" class="nav-link" data-scroll-target="#cluster-validation-statistics"><span class="header-section-number">10.4.3</span> Cluster Validation Statistics</a>
  <ul class="collapse">
  <li><a href="#internal-measures-for-cluster-validation" id="toc-internal-measures-for-cluster-validation" class="nav-link" data-scroll-target="#internal-measures-for-cluster-validation"><span class="header-section-number">10.4.3.1</span> Internal measures for cluster validation</a></li>
  </ul></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">
<script src="https://cdn.jsdelivr.net/npm/monaco-editor@0.47.0/min/vs/loader.js"></script>
<script type="module" id="qwebr-monaco-editor-init">

  // Configure the Monaco Editor's loader
  require.config({
    paths: {
      'vs': 'https://cdn.jsdelivr.net/npm/monaco-editor@0.47.0/min/vs'
    }
  });
</script>
<script type="module">
// Function to update Monaco Editors when body class changes
function updateMonacoEditorsOnBodyClassChange() {
    // Select the body element
    const body = document.querySelector('body');

    // Options for the observer (which mutations to observe)
    const observerOptions = {
        attributes: true,  // Observe changes to attributes
        attributeFilter: ['class'] // Only observe changes to the 'class' attribute
    };

    // Callback function to execute when mutations are observed
    const bodyClassChangeCallback = function(mutationsList, observer) {
        for(let mutation of mutationsList) {
            if (mutation.type === 'attributes' && mutation.attributeName === 'class') {
                // Class attribute has changed
                // Update all Monaco Editors on the page
                updateMonacoEditorTheme();
            }
        }
    };

    // Create an observer instance linked to the callback function
    const observer = new MutationObserver(bodyClassChangeCallback);

    // Start observing the target node for configured mutations
    observer.observe(body, observerOptions);
}

// Function to update all instances of Monaco Editors on the page
function updateMonacoEditorTheme() {
    // Determine what VS Theme to use
    const vsThemeToUse = document.body.classList.contains("quarto-dark") ? 'vs-dark' : 'vs' ;

    // Iterate through all initialized Monaco Editors
    qwebrEditorInstances.forEach( function(editorInstance) { 
        editorInstance.updateOptions({ theme: vsThemeToUse }); 
    });
}

// Call the function to start observing changes to body class
updateMonacoEditorsOnBodyClassChange();
</script>
<script type="module">
// Global array to store Monaco Editor instances
globalThis.qwebrEditorInstances = [];

function isValidCodeLineNumbers(stringCodeLineNumbers) {
  // Regular expression to match valid input strings
  const regex = /^(\d+(-\d+)?)(,\d+(-\d+)?)*$/;
  return regex.test(stringCodeLineNumbers);
}

// Function that builds and registers a Monaco Editor instance    
globalThis.qwebrCreateMonacoEditorInstance = function (cellData) {

  const initialCode = cellData.code;
  const qwebrCounter = cellData.id;
  const qwebrOptions = cellData.options;

  // Retrieve the previously created document elements
  let runButton = document.getElementById(`qwebr-button-run-${qwebrCounter}`);
  let resetButton = document.getElementById(`qwebr-button-reset-${qwebrCounter}`);
  let copyButton = document.getElementById(`qwebr-button-copy-${qwebrCounter}`);
  let editorDiv = document.getElementById(`qwebr-editor-${qwebrCounter}`);

  // Load the Monaco Editor and create an instance
  let editor;
  require(['vs/editor/editor.main'], function () {
    editor = monaco.editor.create(editorDiv, {
      value: initialCode,
      language: 'r',
      theme: 'vs-light',
      automaticLayout: true,           // Works wonderfully with RevealJS
      scrollBeyondLastLine: false,
      minimap: {
        enabled: false
      },
      fontSize: qwebrScaledFontSize(editorDiv, qwebrOptions),         
      renderLineHighlight: "none",      // Disable current line highlighting
      hideCursorInOverviewRuler: true,  // Remove cursor indictor in right hand side scroll bar
      readOnly: qwebrOptions['read-only'] ?? false,
      quickSuggestions: qwebrOptions['editor-quick-suggestions'] ?? false,
      wordWrap: (qwebrOptions['editor-word-wrap'] == 'true' ? "on" : "off")
    });

    // Store the official counter ID to be used in keyboard shortcuts
    editor.__qwebrCounter = qwebrCounter;

    // Store the official div container ID
    editor.__qwebrEditorId = `qwebr-editor-${qwebrCounter}`;

    // Store the initial code value and options
    editor.__qwebrinitialCode = initialCode;
    editor.__qwebrOptions = qwebrOptions;

    // Set at the model level the preferred end of line (EOL) character to LF.
    // This prevent `\r\n` from being given to the webR engine if the user is on Windows.
    // See details in: https://github.com/coatless/quarto-webr/issues/94
    // Associated error text: 
    // Error: <text>:1:7 unexpected input

    // Retrieve the underlying model
    const model = editor.getModel();
    // Set EOL for the model
    model.setEOL(monaco.editor.EndOfLineSequence.LF);
    
    // Dynamically modify the height of the editor window if new lines are added.
    let ignoreEvent = false;
    const updateHeight = () => {
      // Increment editor height by 2 to prevent vertical scroll bar from appearing
      const contentHeight = editor.getContentHeight() + 2;

      // Retrieve editor-max-height option
      const maxEditorHeight = qwebrOptions['editor-max-height'];

      // If editor-max-height is missing, allow infinite growth. Otherwise, threshold.
      const editorHeight = !maxEditorHeight ?  contentHeight : Math.min(contentHeight, maxEditorHeight);

      // We're avoiding a width change
      //editorDiv.style.width = `${width}px`;
      editorDiv.style.height = `${editorHeight}px`;
      try {
        ignoreEvent = true;

        // The key to resizing is this call
        editor.layout();
      } finally {
        ignoreEvent = false;
      }
    };

    // Function to generate decorations to highlight lines
    // in the editor based on input string.
    function decoratorHighlightLines(codeLineNumbers) {
      // Store the lines to be lighlight
      let linesToHighlight = [];
      
      // Parse the codeLineNumbers string to get the line numbers to highlight
      // First, split the string by commas
      codeLineNumbers.split(',').forEach(part => {
        // Check if we have a range of lines
        if (part.includes('-')) {
            // Handle range of lines (e.g., "6-8")
            const [start, end] = part.split('-').map(Number);
            for (let i = start; i <= end; i++) {
                linesToHighlight.push(i);
            }
        } else {
            // Handle single line (e.g., "7")
            linesToHighlight.push(Number(part));
        }
      });
  
      // Create monaco decorations for the lines to highlight
      const decorations = linesToHighlight.map(lineNumber => ({
          range: new monaco.Range(lineNumber, 1, lineNumber, 1),
          options: {
              isWholeLine: true,
              className: 'qwebr-editor-highlight-line'
          }
      }));
  
      // Return decorations to be applied to the editor
      return decorations;
    }

    // Ensure that the editor-code-line-numbers option is set and valid
    // then apply styling
    if (qwebrOptions['editor-code-line-numbers']) {
      // Remove all whitespace from the string
      const codeLineNumbers = qwebrOptions['editor-code-line-numbers'].replace(/\s/g,'');
      // Check if the string is valid for line numbers, e.g., "1,3-5,7"
      if (isValidCodeLineNumbers(codeLineNumbers)) {
        // Apply the decorations to the editor
        editor.createDecorationsCollection(decoratorHighlightLines(codeLineNumbers));
      } else {
        // Warn the user that the input is invalid
        console.warn(`Invalid "editor-code-line-numbers" value in code cell ${qwebrOptions['label']}: ${codeLineNumbers}`);
      }
    }

    // Helper function to check if selected text is empty
    function isEmptyCodeText(selectedCodeText) {
      return (selectedCodeText === null || selectedCodeText === undefined || selectedCodeText === "");
    }

    // Registry of keyboard shortcuts that should be re-added to each editor window
    // when focus changes.
    const addWebRKeyboardShortCutCommands = () => {
      // Add a keydown event listener for Shift+Enter to run all code in cell
      editor.addCommand(monaco.KeyMod.Shift | monaco.KeyCode.Enter, () => {

        // Retrieve all text inside the editor
        qwebrExecuteCode(editor.getValue(), editor.__qwebrCounter, editor.__qwebrOptions);
      });

      // Add a keydown event listener for CMD/Ctrl+Enter to run selected code
      editor.addCommand(monaco.KeyMod.CtrlCmd | monaco.KeyCode.Enter, () => {

        // Get the selected text from the editor
        const selectedText = editor.getModel().getValueInRange(editor.getSelection());
        // Check if no code is selected
        if (isEmptyCodeText(selectedText)) {
          // Obtain the current cursor position
          let currentPosition = editor.getPosition();
          // Retrieve the current line content
          let currentLine = editor.getModel().getLineContent(currentPosition.lineNumber);

          // Propose a new position to move the cursor to
          let newPosition = new monaco.Position(currentPosition.lineNumber + 1, 1);

          // Check if the new position is beyond the last line of the editor
          if (newPosition.lineNumber > editor.getModel().getLineCount()) {
            // Add a new line at the end of the editor
            editor.executeEdits("addNewLine", [{
            range: new monaco.Range(newPosition.lineNumber, 1, newPosition.lineNumber, 1),
            text: "\n", 
            forceMoveMarkers: true,
            }]);
          }
          
          // Run the entire line of code.
          qwebrExecuteCode(currentLine, editor.__qwebrCounter, editor.__qwebrOptions);

          // Move cursor to new position
          editor.setPosition(newPosition);
        } else {
          // Code to run when Ctrl+Enter is pressed with selected code
          qwebrExecuteCode(selectedText, editor.__qwebrCounter, editor.__qwebrOptions);
        }
      });
    }

    // Register an on focus event handler for when a code cell is selected to update
    // what keyboard shortcut commands should work.
    // This is a workaround to fix a regression that happened with multiple
    // editor windows since Monaco 0.32.0 
    // https://github.com/microsoft/monaco-editor/issues/2947
    editor.onDidFocusEditorText(addWebRKeyboardShortCutCommands);

    // Register an on change event for when new code is added to the editor window
    editor.onDidContentSizeChange(updateHeight);

    // Manually re-update height to account for the content we inserted into the call
    updateHeight();

    // Store the editor instance in the global dictionary
    qwebrEditorInstances[editor.__qwebrCounter] = editor;

  });

  // Add a click event listener to the run button
  runButton.onclick = function () {
    qwebrExecuteCode(editor.getValue(), editor.__qwebrCounter, editor.__qwebrOptions);
  };

  // Add a click event listener to the reset button
  copyButton.onclick = function () {
    // Retrieve current code data
    const data = editor.getValue();
    
    // Write code data onto the clipboard.
    navigator.clipboard.writeText(data || "");
  };
  
  // Add a click event listener to the copy button
  resetButton.onclick = function () {
    editor.setValue(editor.__qwebrinitialCode);
  };
  
}
</script>

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../chapters/clustring.html">Clustering</a></li><li class="breadcrumb-item"><a href="../chapters/clustring.html"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Clustering</span></a></li></ol></nav>
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Clustering</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p>Cluster analysis, or <em>Clustering</em>, is a technique used to find groups of objects such that the objects within the same group are similar (or closely realted) to one another, while the objects from different groups are dissimilar (or unrelated).</p>
<section id="applications-of-clustering" class="level2" data-number="10.1">
<h2 data-number="10.1" class="anchored" data-anchor-id="applications-of-clustering"><span class="header-section-number">10.1</span> Applications of Clustering</h2>
<p>Clustering techniques are widely used across multiple disciplines to discover patterns, structure data, and support decision-making. Below are some common and illustrative applications.</p>
<p><strong>Customer Segmentation</strong></p>
<p>In marketing and business analytics, clustering helps identify groups of customers with similar behaviors, preferences, or purchasing habits. This segmentation allows companies to optimize advertising strategies, personalize product offerings, and design campaigns for specific focus groups.</p>
<p><strong>Example</strong>: Grouping supermarket customers based on purchase frequency, product categories, and spending level.</p>
<p><strong>Web Visitor Segmentation</strong></p>
<p>Web analytics platforms use clustering to classify website visitors according to their browsing patterns, time spent on pages, or interaction behaviors. This segmentation supports personalized content delivery and improved user experience.</p>
<p><strong>Example</strong>: Optimizing web navigation or recommendations for distinct <em>user segments</em> such as new visitors vs.&nbsp;returning users.</p>
<p><strong>Data Aggregation and Reduction</strong></p>
<p>Clustering can be used to represent large datasets by a smaller set of representative elements (centroids or medoids).<br>
This reduces computational complexity and facilitates data visualization.</p>
<p><strong>Example</strong>:<br>
Reducing the color palette of an image to <em>k representative colors</em> using algorithms like <em>k-means</em>.</p>
<p><strong>Text Collection Organization</strong></p>
<p>In natural language processing (NLP), clustering is applied to group similar documents or texts into topics or themes.<br>
It is particularly useful when the number or nature of topics is <em>unknown in advance</em>.</p>
<p><strong>Example</strong>:<br>
Grouping news articles, research abstracts, or emails into topic clusters.</p>
<p><strong>Biology and Taxonomy</strong></p>
<p>In biological sciences, clustering supports the classification of living organisms based on genetic, morphological, or behavioral similarities.<br>
It forms the basis for hierarchical structures such as <em>kingdom, phylum, class, order, family, genus,</em> and <em>species</em>.</p>
<p><strong>Example</strong>:<br>
Clustering DNA sequences to identify genetic relationships among species.</p>
<p><strong>Information Retrieval</strong></p>
<p>In computer science and library systems, clustering helps organize large document collections to improve search and retrieval efficiency. By grouping related documents, search engines can return more <em>contextually relevant</em> results.</p>
<p><strong>Example</strong>:<br>
Document clustering for semantic search or grouping research papers by field of study.</p>
</section>
<section id="distance-and-similarity-in-clustering" class="level2" data-number="10.2">
<h2 data-number="10.2" class="anchored" data-anchor-id="distance-and-similarity-in-clustering"><span class="header-section-number">10.2</span> Distance and Similarity in Clustering</h2>
<p>The notion of <em>distance</em> or <em>similarity</em> lies at the heart of clustering. Since clustering aims to group similar observations together, we must have a way to measure how close or far two observations are from each other in the feature space. These measures quantify the degree of resemblance (similarity) or difference (dissimilarity) between data points.</p>
<blockquote class="blockquote">
<p>The main goal is to partition a set of data points into clusters where <strong>intra-cluster</strong> distances (distances between points within the same cluster) are <strong>minimized</strong>, and <strong>inter-cluster</strong> distances (distances between points from different clusters) are <strong>maximized</strong>.</p>
</blockquote>
<p>Thus, the main goal of clustering can be rewritten as:</p>
<blockquote class="blockquote">
<p>The main goal is to partition a set of data points into clusters where intra-cluster similarities (similarities between points within the same cluster) are maximized, and inter-cluster similarities (similarities between points from different clusters) are minimized.</p>
</blockquote>
<p>To avoid confusion, remember that <em>distance</em> and <em>similarity</em> are inverse concepts: when two objects are close (small distance), they are considered similar (high similarity).<br>
The table below summarizes their relationship and how each measure behaves in clustering.</p>
<table class="caption-top table">
<colgroup>
<col style="width: 13%">
<col style="width: 12%">
<col style="width: 25%">
<col style="width: 25%">
<col style="width: 23%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;"><strong>Concept</strong></th>
<th style="text-align: left;"><strong>Meaning</strong></th>
<th style="text-align: left;"><strong>High Value Indicates</strong></th>
<th style="text-align: left;"><strong>Low Value Indicates</strong></th>
<th style="text-align: left;"><strong>Goal in Clustering</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><strong>Distance</strong></td>
<td style="text-align: left;">A measure of dissimilarity between two objects</td>
<td style="text-align: left;">Objects are far apart (dissimilar)</td>
<td style="text-align: left;">Objects are close together (similar)</td>
<td style="text-align: left;"><strong>Minimize intra-cluster distances</strong> and <strong>maximize inter-cluster distances</strong></td>
</tr>
<tr class="even">
<td style="text-align: left;"><strong>Similarity</strong></td>
<td style="text-align: left;">A measure of closeness or resemblance between two objects</td>
<td style="text-align: left;">Objects are close together (similar)</td>
<td style="text-align: left;">Objects are far apart (dissimilar)</td>
<td style="text-align: left;"><strong>Maximize intra-cluster similarities</strong> and <strong>minimize inter-cluster similarities</strong></td>
</tr>
</tbody>
</table>
<div class="cell">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="clustring_files/figure-html/similarity-vs-distance-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption>Relationship between distance and similarity — points in the same cluster have high similarity (low distance).</figcaption>
</figure>
</div>
</div>
</div>
<p>A <strong>distance metric</strong> <span class="math inline">\(d(\mathbf{x}, \mathbf{y})\)</span> measures the dissimilarity between two points <span class="math inline">\(\mathbf{x}=(x_1, x_2, \ldots, x_p)\)</span> and <span class="math inline">\(\mathbf{y} = (y_1, y_2, \ldots, y_p)\)</span>. Formally, a function <span class="math inline">\(d: X \times X \rightarrow \mathbb{R}\)</span> is a <em>metric</em> if it satisfies: <span class="math display">\[
\begin{aligned}
1.\;&amp; d(\mathbf{x}, \mathbf{y}) \ge 0 &amp;&amp; \text{(non-negativity)} \\
2.\;&amp; d(\mathbf{x}, \mathbf{y}) = 0 \iff \mathbf{x} = \mathbf{y} &amp;&amp; \text{(identity)} \\
3.\;&amp; d(\mathbf{x}, \mathbf{y}) = d(\mathbf{y}, \mathbf{x}) &amp;&amp; \text{(symmetry)} \\
4.\;&amp; d(\mathbf{x}, \mathbf{y}) \le d(\mathbf{x}, \mathbf{z}) + d(\mathbf{z}, \mathbf{y}) &amp;&amp; \text{(triangle inequality)}
\end{aligned}
\]</span></p>
<p>A <strong>similarity measure</strong> <span class="math inline">\(s(\mathbf{x}, \mathbf{y})\)</span> expresses how close or related two points are.<br>
It usually satisfies: <span class="math display">\[
\begin{aligned}
1.\;&amp; s(\mathbf{x}, \mathbf{y}) \ge 0 &amp;&amp; \text{(non-negativity)} \\
2.\;&amp; s(\mathbf{x}, \mathbf{y}) = s(\mathbf{y}, \mathbf{x}) &amp;&amp; \text{(symmetry)} \\
3.\;&amp; s(\mathbf{x}, \mathbf{y}) \in [0, 1] &amp;&amp; \text{(boundedness)} \\
4.\;&amp; s(\mathbf{x}, \mathbf{x}) = 1 &amp;&amp; \text{(maximum self-similarity)}
\end{aligned}
\]</span> A simple transformation links both concepts: <span class="math display">\[
s(\mathbf{x}, \mathbf{y}) = \frac{1}{1 + d(\mathbf{x}, \mathbf{y})}, \quad \text{where } s(\mathbf{x}, \mathbf{y}) \in [0, 1].
\]</span></p>
<section id="common-distance-metrics" class="level3" data-number="10.2.1">
<h3 data-number="10.2.1" class="anchored" data-anchor-id="common-distance-metrics"><span class="header-section-number">10.2.1</span> Common Distance Metrics</h3>
<p>Different clustering algorithms may behave very differently depending on the metric used.<br>
Below are the most widely used <strong>distance measures</strong>.</p>
<section id="euclidean-distance" class="level4" data-number="10.2.1.1">
<h4 data-number="10.2.1.1" class="anchored" data-anchor-id="euclidean-distance"><span class="header-section-number">10.2.1.1</span> <strong>Euclidean Distance</strong></h4>
<p>The most common metric, representing the straight-line distance between two points in <span class="math inline">\(\mathbb{R}^p\)</span>: <span class="math display">\[
d_E(\mathbf{x}, \mathbf{y}) = \sqrt{\sum_{i=1}^{p} (x_i - y_i)^2}
\]</span></p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>Euclidean distance is sensitive to scale; therefore, variables should usually be standardized before applying it.</p>
</div>
</div>
<div id="qwebr-insertion-location-1"></div>
<noscript>Please enable JavaScript to experience the dynamic code cell content on this page.</noscript>
</section>
<section id="manhattan-or-city-block-distance" class="level4" data-number="10.2.1.2">
<h4 data-number="10.2.1.2" class="anchored" data-anchor-id="manhattan-or-city-block-distance"><span class="header-section-number">10.2.1.2</span> <strong>Manhattan (or City-Block) Distance</strong></h4>
<p>This distance sums the absolute differences across all coordinates: <span class="math display">\[
d_M(\mathbf{x}, \mathbf{y}) = \sum_{i=1}^{p} |x_i - y_i|
\]</span></p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>The Manhattan distance is more robust to outliers and suitable when features represent grid-like or discrete steps.</p>
</div>
</div>
<div id="qwebr-insertion-location-2"></div>
<noscript>Please enable JavaScript to experience the dynamic code cell content on this page.</noscript>
<div class="cell">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="clustring_files/figure-html/distance-compare-1.png" class="img-fluid figure-img" style="width:80.0%"></p>
<figcaption>Comparison of Euclidean and Manhattan distance between two points</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="minkowski-distance" class="level4" data-number="10.2.1.3">
<h4 data-number="10.2.1.3" class="anchored" data-anchor-id="minkowski-distance"><span class="header-section-number">10.2.1.3</span> <strong>Minkowski Distance</strong></h4>
<p>A generalization of Euclidean and Manhattan distances, controlled by a parameter <span class="math inline">\(r\)</span>: <span class="math display">\[
d_r(\mathbf{x}, \mathbf{y}) = \left( \sum_{i=1}^{p} |x_i - y_i|^r \right)^{1/r}
\]</span></p>
<ul>
<li><p>When <span class="math inline">\(r = 1\)</span>, it becomes Manhattan distance.</p></li>
<li><p>When <span class="math inline">\(r = 2\)</span>, it becomes Euclidean distance.</p></li>
<li><p>Larger values of <span class="math inline">\(r\)</span> emphasize large coordinate differences.</p></li>
</ul>
<div id="qwebr-insertion-location-3"></div>
<noscript>Please enable JavaScript to experience the dynamic code cell content on this page.</noscript>
<div class="cell">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="clustring_files/figure-html/minkowski-distance-1.png" class="img-fluid figure-img" style="width:80.0%"></p>
<figcaption>Shapes of Minkowski (Lp) distances around a point for different p values</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="chebyshev-distance" class="level4" data-number="10.2.1.4">
<h4 data-number="10.2.1.4" class="anchored" data-anchor-id="chebyshev-distance"><span class="header-section-number">10.2.1.4</span> Chebyshev Distance</h4>
<p>Also known as the <span class="math inline">\(L_\infty\)</span> norm, this distance takes the largest coordinate difference: <span class="math display">\[
d_C(\mathbf{x}, \mathbf{y}) = \max_i |x_i - y_i|
\]</span> It measures how far apart two points are along the dimension where they differ most.</p>
<div id="qwebr-insertion-location-4"></div>
<noscript>Please enable JavaScript to experience the dynamic code cell content on this page.</noscript>
<div class="cell">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="clustring_files/figure-html/chebyshev-vs-euclidean-manhattan-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption>Comparison of Chebyshev, Euclidean, and Manhattan distances between A and B</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="mahalanobis-distance" class="level4" data-number="10.2.1.5">
<h4 data-number="10.2.1.5" class="anchored" data-anchor-id="mahalanobis-distance"><span class="header-section-number">10.2.1.5</span> <strong>Mahalanobis Distance</strong></h4>
<p>A scale-invariant distance that accounts for correlations between variables: <span class="math display">\[
d_{Mah}(\mathbf{x}, \mathbf{y}) = \sqrt{(x - y)^{\top} \boldsymbol{\Sigma}^{-1} (x - y)}
\]</span> where <span class="math inline">\(\boldsymbol{\Sigma}\)</span> is the covariance matrix of the data. Two points with the same Mahalanobis distance from the mean are equally likely under a multivariate normal model, regardless of the variable scales or correlations.</p>
<div id="qwebr-insertion-location-5"></div>
<noscript>Please enable JavaScript to experience the dynamic code cell content on this page.</noscript>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Tip
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Choosing an Appropriate Metric</strong></p>
<p>The choice of metric depends on the <strong>data characteristics</strong> and the <strong>clustering goal</strong>:</p>
<ul>
<li>Use <strong>Euclidean</strong> when features are continuous and scaled.<br>
</li>
<li>Use <strong>Manhattan</strong> for grid-like or sparse data.<br>
</li>
<li>Use <strong>Mahalanobis</strong> when features are correlated.<br>
</li>
<li>Use <strong>Chebyshev</strong> for problems sensitive to maximum deviations.<br>
</li>
<li>Use <strong>Minkowski</strong> for flexible control between Manhattan and Euclidean.</li>
</ul>
</div>
</div>
</section>
<section id="cosine-and-correlation-distance" class="level4" data-number="10.2.1.6">
<h4 data-number="10.2.1.6" class="anchored" data-anchor-id="cosine-and-correlation-distance"><span class="header-section-number">10.2.1.6</span> Cosine and Correlation Distance</h4>
<p>For data where <em>direction</em> or <em>orientation</em> matters more than magnitude — such as text represented by TF-IDF vectors or normalized embeddings — Euclidean distance is not ideal. Instead, we use <em>cosine similarity</em> or <em>correlation distance</em>.</p>
<p>The <em>cosine similarity</em> between two vectors <span class="math inline">\(\mathbf{x}\)</span> and <span class="math inline">\(\mathbf{y}\)</span> is defined as <span class="math display">\[
s_{\text{cosine}}(\mathbf{x}, \mathbf{y}) = \frac{\mathbf{x} \cdot \mathbf{y}}{\|\mathbf{x}\| \, \|\mathbf{y}\|}
\]</span> where <span class="math inline">\(\mathbf{x} \cdot \mathbf{y}\)</span> is the <strong>dot product</strong> of the two vectors, and <span class="math inline">\(\|\mathbf{x}\|\)</span> and <span class="math inline">\(\|\mathbf{y}\|\)</span> are their**Euclidean norms*.</p>
<p>This similarity measures the <em>cosine of the angle</em> between the two vectors in a multidimensional space.</p>
<ul>
<li><p>A value of <strong>1</strong> means the vectors point in the <strong>same direction</strong> (perfectly similar).</p></li>
<li><p>A value of <strong>0</strong> means the vectors are <strong>orthogonal</strong> (no similarity).</p></li>
<li><p>A value of <strong>–1</strong> means they point in <strong>opposite directions</strong> (perfectly dissimilar).</p></li>
</ul>
<p>The corresponding <em>cosine distance</em> is: <span class="math display">\[
d_{\text{cosine}}(\mathbf{x}, \mathbf{y}) = 1 - s_{\text{cosine}}(\mathbf{x}, \mathbf{y})
\]</span></p>
<div id="qwebr-insertion-location-6"></div>
<noscript>Please enable JavaScript to experience the dynamic code cell content on this page.</noscript>
<div class="callout.tip">
<p>Cosine-based metrics are particularly useful for <em>directional data</em>, where the <em>pattern</em> or <em>orientation</em> of features matters more than their magnitude —<br>
for example, in <em>text mining</em> (TF-IDF vectors), <em>recommendation systems</em>, or <em>image feature embeddings</em>.</p>
</div>
</section>
</section>
<section id="distances-for-binary-data" class="level3" data-number="10.2.2">
<h3 data-number="10.2.2" class="anchored" data-anchor-id="distances-for-binary-data"><span class="header-section-number">10.2.2</span> Distances for Binary Data</h3>
<p>When the data are <strong>binary</strong> (0 or 1), such as presence/absence, success/failure, or yes/no attributes, specialized similarity and distance measures are used.</p>
<p>Let <span class="math inline">\(o_1, o_2 \in \{0,1\}^d\)</span> be two binary observations described by <span class="math inline">\(d\)</span> attributes.</p>
<p>We define: <span class="math display">\[
\begin{aligned}
f_{11} &amp;= \text{number of attributes where } o_1 = 1 \text{ and } o_2 = 1, \\
f_{00} &amp;= \text{number of attributes where } o_1 = 0 \text{ and } o_2 = 0, \\
f_{10} &amp;= \text{number of attributes where } o_1 = 1 \text{ and } o_2 = 0, \\
f_{01} &amp;= \text{number of attributes where } o_1 = 0 \text{ and } o_2 = 1.
\end{aligned}
\]</span></p>
<section id="simple-matching-coefficient-similarity" class="level4" data-number="10.2.2.1">
<h4 data-number="10.2.2.1" class="anchored" data-anchor-id="simple-matching-coefficient-similarity"><span class="header-section-number">10.2.2.1</span> <strong>Simple Matching Coefficient (Similarity)</strong></h4>
<p><span class="math display">\[
s_{SMC}(o_1, o_2) = \frac{f_{11} + f_{00}}{f_{11} + f_{00} + f_{10} + f_{01}} = \frac{f_{11} + f_{00}}{d}
\]</span></p>
<p>This coefficient measures the proportion of attributes where the two observations match — whether both are 1s or both are 0s.</p>
</section>
<section id="simple-matching-distance" class="level4" data-number="10.2.2.2">
<h4 data-number="10.2.2.2" class="anchored" data-anchor-id="simple-matching-distance"><span class="header-section-number">10.2.2.2</span> <strong>Simple Matching Distance</strong></h4>
<p><span class="math display">\[
d_{SMC}(o_1, o_2) = 1 - s_{SMC}(o_1, o_2) = \frac{f_{01} + f_{10}}{d}
\]</span> This represents the proportion of mismatches between two binary objects.</p>
<div id="qwebr-insertion-location-7"></div>
<noscript>Please enable JavaScript to experience the dynamic code cell content on this page.</noscript>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><p>If two binary vectors are identical,<span class="math inline">\(s_{SMC} = 1\)</span> and <span class="math inline">\(d_{sMC} = 0\)</span>.</p></li>
<li><p>If they are completely opposite, <span class="math inline">\(s_{SMC} = 0\)</span> and <span class="math inline">\(d_{sMC} = 1\)</span>.</p></li>
<li><p>The SMC treats <span class="math inline">\(0\)</span>s and <span class="math inline">\(1\)</span>s symmetrically, so it is best used when both states are equally meaningful.</p></li>
</ul>
</div>
</div>
</section>
</section>
<section id="distances-for-categorical-data" class="level3" data-number="10.2.3">
<h3 data-number="10.2.3" class="anchored" data-anchor-id="distances-for-categorical-data"><span class="header-section-number">10.2.3</span> Distances for Categorical Data</h3>
<p>When data contain <strong>categorical</strong> or <strong>mixed-type variables</strong>, standard numeric distances (like Euclidean) are not suitable.<br>
Instead, we use measures that handle <strong>qualitative comparisons</strong> directly.</p>
<p>Let <span class="math inline">\(\mathbf{x} = (x_1, \ldots, x_p)\)</span> and <span class="math inline">\(\mathbf{y} = (y_1, \ldots, y_p)\)</span> be two observations described by <span class="math inline">\(p\)</span> categorical or mixed-type attributes.</p>
<section id="hamming-distance" class="level4" data-number="10.2.3.1">
<h4 data-number="10.2.3.1" class="anchored" data-anchor-id="hamming-distance"><span class="header-section-number">10.2.3.1</span> <strong>Hamming Distance</strong></h4>
<p>The <strong>Hamming distance</strong> counts the number of mismatches between two vectors: <span class="math display">\[
\text{d}_{Hamming}(\mathbf{x}, \mathbf{y}) = \sum_{i=1}^{p} \delta(x_i, y_i)
\]</span> where <span class="math display">\[
\delta(x_i, y_i) =
\begin{cases}
0, &amp; \text{if } x_i = y_i \\
1, &amp; \text{if } x_i \neq y_i
\end{cases}
\]</span> It measures how many positions differ between two categorical strings or binary vectors.</p>
<div id="qwebr-insertion-location-8"></div>
<noscript>Please enable JavaScript to experience the dynamic code cell content on this page.</noscript>
</section>
<section id="gower-distance" class="level4" data-number="10.2.3.2">
<h4 data-number="10.2.3.2" class="anchored" data-anchor-id="gower-distance"><span class="header-section-number">10.2.3.2</span> <strong>Gower Distance</strong></h4>
<p>The <strong>Gower distance</strong> <span class="citation" data-cites="Gower1971">(<a href="#ref-Gower1971" role="doc-biblioref">Gower 1971</a>)</span> allows comparing <strong>mixed-type data</strong> (numerical, categorical, binomial).</p>
<p>For two observations <span class="math inline">\(i\)</span> and <span class="math inline">\(k\)</span>, and each variable <span class="math inline">\(k\)</span>, Gower’s method computes a partial <em>similarity score</em> <span class="math inline">\(s_{ijk}\)</span> as follows:</p>
<ul>
<li><p><strong>Numeric variables (continuous or discrete)</strong>: <span class="math display">\[
s_{ijk} = 1 - \frac{|x_{ik} - x_{jk}|}{R_k}
\]</span> where <span class="math inline">\(R_k\)</span> is the range of variable <span class="math inline">\(k\)</span>.</p></li>
<li><p><strong>Categorical (or binary) variables</strong>: <span class="math display">\[
s_{ijk} = \begin{cases}
1 &amp; \quad \text{if} \quad x_{ik} = x_{jk}\\
0 &amp; \quad \text{if} \quad x_{ik} \neq x_{jk}
\end{cases}
\]</span> Then, the <em>overall similarity</em> between <span class="math inline">\(i\)</span> and <span class="math inline">\(j\)</span> is <span class="math display">\[
S_{ij} = \frac{\sum_k s_{ijk} \delta_{ijk}}{\sum_k \delta_{ijk}}
\]</span> where <span class="math inline">\(\delta_{ijk} = 1\)</span> if variable <span class="math inline">\(k\)</span> is valid for both <span class="math inline">\(i\)</span> and <span class="math inline">\(j\)</span> (i.e, non-missing), else <span class="math inline">\(0\)</span>.</p></li>
</ul>
<p>Finally, to convert similarity to a distance, one often uses <span class="math display">\[
D_{ij} = 1 - S_{ij}
\]</span></p>
<p><a href="https://crispinagar.github.io/blogs/gower-distance.html"><strong>Example</strong></a></p>
<p>As an example, consider the following table which shows information about a number of individuals (identified by “Subject ID”) with four attributes:</p>
<ul>
<li><em>Age</em> – a continuous numeric variable</li>
<li><em>Handedness</em> – a binary variable, whether the individual is left- or right-handed.</li>
<li><em>Eye colour</em> - a categorical variable</li>
<li><em>Knows Python</em> - a dichotomous variable (while two people who know python may have a similar education, both of them not knowing Python does not imply they have similar backgrounds).</li>
</ul>
<table class="caption-top table">
<thead>
<tr class="header">
<th style="text-align: center;">Subject ID</th>
<th style="text-align: center;">Age</th>
<th style="text-align: center;">Handedness</th>
<th style="text-align: center;">Eye Colour</th>
<th style="text-align: center;">Knows Python</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">001</td>
<td style="text-align: center;">28</td>
<td style="text-align: center;">Right</td>
<td style="text-align: center;">Blue</td>
<td style="text-align: center;">Yes</td>
</tr>
<tr class="even">
<td style="text-align: center;">002</td>
<td style="text-align: center;">34</td>
<td style="text-align: center;">Left</td>
<td style="text-align: center;">Blue</td>
<td style="text-align: center;">No</td>
</tr>
<tr class="odd">
<td style="text-align: center;">003</td>
<td style="text-align: center;">22</td>
<td style="text-align: center;">Right</td>
<td style="text-align: center;">Green</td>
<td style="text-align: center;">Yes</td>
</tr>
<tr class="even">
<td style="text-align: center;">004</td>
<td style="text-align: center;">45</td>
<td style="text-align: center;">Right</td>
<td style="text-align: center;">Hazel</td>
<td style="text-align: center;">No</td>
</tr>
<tr class="odd">
<td style="text-align: center;">005</td>
<td style="text-align: center;">30</td>
<td style="text-align: center;">Left</td>
<td style="text-align: center;">Brown</td>
<td style="text-align: center;">Yes</td>
</tr>
</tbody>
</table>
<p>Let us look at individuals 001 and 002, and calculate the score for each variable in turn:</p>
<ul>
<li><p><em>Age</em>: <span class="math display">\[
s_{\textrm{age}} = 1 - \frac{|28 - 34|}{23} = 0.74
\]</span> where the range <span class="math inline">\(R_k = 23\)</span> is the range of ages in the sample, which has a minimum of <span class="math inline">\(22\)</span> and a maximum of <span class="math inline">\(45\)</span>.</p></li>
<li><p><em>Handedness</em>:</p></li>
</ul>
<p>Since the individuals have different handedness, <span class="math inline">\(s_{\text{handedness}} = 0\)</span>.</p>
<ul>
<li><p><em>Eye colour</em>: They have the same eyes, <span class="math inline">\(s_{\text{eyes}} = 1\)</span>.</p></li>
<li><p><em>Knows Python</em>:</p></li>
</ul>
<p>Individuals 001 knows python whereas 002 does not; so, <span class="math inline">\(s_{\text{python}} = 0\)</span>.</p>
<p>We have no missing data, so all the <span class="math inline">\(\delta_{ijk} = 1\)</span>. The overall similarity score between 001 and 002 is therefore <span class="math display">\[
S = \frac{0.74 \times 1 + 0 \times 1 + 1 \times 1 + 0 \times 1}{1 + 1 + 1 + 1} = \frac{1.74}{4} = 0.435
\]</span> So, the Gower distance between these two individuals is <span class="math display">\[
D = 1 - 0.435 = 0.565
\]</span></p>
<p>Repeating the calculation for all pairs of indivials, we obtain the distance matrix, which can be used for clustering them into groups.</p>
<p>For calculating Gower distance in R, we can use <code>daisy()</code> from the library <code>cluster</code>. However, it is important to note that always convert categorical characters to factors before using this function.</p>
<div id="qwebr-insertion-location-9"></div>
<noscript>Please enable JavaScript to experience the dynamic code cell content on this page.</noscript>
<p>As you see that the individuals who are most similar are 001 and 003 <span class="math inline">\((D = 0.315)\)</span> and the most different are 004 and 005 <span class="math inline">\((D = 0.913)\)</span>.</p>
</section>
</section>
<section id="visualizing-distance-matrices" class="level3" data-number="10.2.4">
<h3 data-number="10.2.4" class="anchored" data-anchor-id="visualizing-distance-matrices"><span class="header-section-number">10.2.4</span> Visualizing distance matrices</h3>
<p>Datasets usually contain many observations (more than just two points).</p>
<p>When we compute pairwise distances between all observations, we obtain a <em>distance matrix</em> — a square table where each cell represents the dissimilarity between two observations.</p>
<p>Mathematically, if a dataset has <span class="math inline">\(n\)</span> observations, the distance matrix has <span class="math inline">\(n \times n\)</span> entries: <span class="math display">\[
D_{ij} = d(\mathbf{x}_i, \mathbf{x}_j)
\]</span> where <span class="math inline">\(D_{ij}\)</span> is the distance between observation <span class="math inline">\(i\)</span> and <span class="math inline">\(j\)</span>.</p>
<p>Because this matrix contains all pairwise comparisons, it provides a complete picture of how observations relate to one another.</p>
<p>However, as the number of observations grows, the matrix quickly becomes difficult to interpret numerically — it is just a sea of numbers.</p>
<p>To extract insights, we often visualize the distance matrix as a heatmap or similarity map.</p>
<p>Visualizing distance matrices helps us:</p>
<ul>
<li><p><strong>Detect structure</strong> – clusters appear as blocks or dark/light patches.</p></li>
<li><p><strong>Spot outliers</strong> – points that are dissimilar from everyone else.</p></li>
<li><p><strong>Compare metrics</strong> – see how distance measures produce different patterns.</p></li>
<li><p><strong>Build intuitio</strong> – for what <em>closeness</em> or <em>difference</em> means in multidimensional space.</p></li>
</ul>
<div id="qwebr-insertion-location-10"></div>
<noscript>Please enable JavaScript to experience the dynamic code cell content on this page.</noscript>
<p>The color level is proportional to the value of the dissimilarity between observations: pure red if <span class="math inline">\(\text{dist}(\mathbf{x}_i, \mathbf{x}_j) = 0\)</span> nad pure blue if <span class="math inline">\(\text{dist}(\mathbf{x}_i, \mathbf{x}_j) = 1\)</span>, here. Objects belonging to the same cluster are displayed in consecutive order.</p>
<p>In this example, subjects <code>001</code> and <code>002</code> are quite similar (close in age, same eye color). Subject <code>004</code> (older, hazel eyes, does not know Python) stands out as most dissimilar from others.</p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-1-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-1" role="tab" aria-controls="tabset-1-1" aria-selected="true" href="">Exercise 1</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-1-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-2" role="tab" aria-controls="tabset-1-2" aria-selected="false" href="">Exercise 2</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-1-3-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-3" role="tab" aria-controls="tabset-1-3" aria-selected="false" href="">Exercise 3</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-1-4-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-4" role="tab" aria-controls="tabset-1-4" aria-selected="false" href="">Exercise 3</a></li></ul>
<div class="tab-content">
<div id="tabset-1-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-1-1-tab">
<p><strong>1. Create two 3-dimensional points and calculate the distance</strong></p>
<p>Let <span class="math inline">\(A = (1, 3, 5)\)</span> and <span class="math inline">\(B = (4, 9, 6)\)</span>.</p>
<p>Compute manually and in R the following distances between <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span>:</p>
<ul>
<li><p>Euclidean</p></li>
<li><p>Manhattan</p></li>
<li><p>Minkowski with <span class="math inline">\(r = 3\)</span></p></li>
<li><p>Chebyshev</p></li>
</ul>
<p><strong>2. Explore sensitivity to scale</strong></p>
<p>Multiply the second coordinate of both points by 10 and recompute all distances. How does this change the results?</p>
</div>
<div id="tabset-1-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-1-2-tab">
<p>Two species are described by four binary characteristics:</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Feature</th>
<th>Species A</th>
<th>Species B</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Has fins</td>
<td>1</td>
<td>1</td>
</tr>
<tr class="even">
<td>Lays eggs</td>
<td>1</td>
<td>0</td>
</tr>
<tr class="odd">
<td>Has scales</td>
<td>1</td>
<td>1</td>
</tr>
<tr class="even">
<td>Warm-blooded</td>
<td>0</td>
<td>1</td>
</tr>
</tbody>
</table>
<ol type="1">
<li><p>Compute manually:</p>
<ul>
<li>( f_{11}, f_{00}, f_{10}, f_{01} )</li>
<li>The <em>Simple Matching Coefficient (SMC)</em><br>
</li>
<li>The <em>Simple Matching Distance (SMD)</em></li>
</ul></li>
<li><p>Verify your results using R.</p></li>
<li><p>Which pair of features contributes to dissimilarity?</p></li>
</ol>
</div>
<div id="tabset-1-3" class="tab-pane" role="tabpanel" aria-labelledby="tabset-1-3-tab">
<p>Two students rate three projects as “Good”, “Average”, or “Poor”:</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Project</th>
<th>Student 1</th>
<th>Student 2</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>A</td>
<td>Good</td>
<td>Good</td>
</tr>
<tr class="even">
<td>B</td>
<td>Poor</td>
<td>Average</td>
</tr>
<tr class="odd">
<td>C</td>
<td>Good</td>
<td>Poor</td>
</tr>
</tbody>
</table>
<p>Compute the <em>Hamming distance</em> (number of mismatches).</p>
<p><strong>Hint</strong>: Use</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a>data[] <span class="ot">&lt;-</span> <span class="fu">lapply</span>(data, <span class="cf">function</span>(col) <span class="cf">if</span> (<span class="fu">is.character</span>(col)) <span class="fu">as.factor</span>(col) <span class="cf">else</span> col)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</div>
<div id="tabset-1-4" class="tab-pane" role="tabpanel" aria-labelledby="tabset-1-4-tab">
<p>We want to analyse the <code>flower</code> dataset which is available at library <code>cluseter</code>.</p>
<p>Based on the following information, a) find the best distance matrix. and b) visulize the distance matrix.</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(cluster)</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(flower)</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(flower, <span class="dv">3</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>  V1 V2 V3 V4 V5 V6  V7 V8
1  0  1  1  4  3 15  25 15
2  1  0  0  2  1  3 150 50
3  0  1  0  3  3  1 150 50</code></pre>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb4"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Data structure</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(flower)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>'data.frame':   18 obs. of  8 variables:
 $ V1: Factor w/ 2 levels "0","1": 1 2 1 1 1 1 1 1 2 2 ...
 $ V2: Factor w/ 2 levels "0","1": 2 1 2 1 2 2 1 1 2 2 ...
 $ V3: Factor w/ 2 levels "0","1": 2 1 1 2 1 1 1 2 1 1 ...
 $ V4: Factor w/ 5 levels "1","2","3","4",..: 4 2 3 4 5 4 4 2 3 5 ...
 $ V5: Ord.factor w/ 3 levels "1"&lt;"2"&lt;"3": 3 1 3 2 2 3 3 2 1 2 ...
 $ V6: Ord.factor w/ 18 levels "1"&lt;"2"&lt;"3"&lt;"4"&lt;..: 15 3 1 16 2 12 13 7 4 14 ...
 $ V7: num  25 150 150 125 20 50 40 100 25 100 ...
 $ V8: num  15 50 50 50 15 40 20 15 15 60 ...</code></pre>
</div>
</div>
</div>
</div>
</div>
</section>
</section>
<section id="partition-based-clustering-k-means-and-k-medoids" class="level2" data-number="10.3">
<h2 data-number="10.3" class="anchored" data-anchor-id="partition-based-clustering-k-means-and-k-medoids"><span class="header-section-number">10.3</span> Partition-Based Clustering: <span class="math inline">\(k\)</span>-Means and <span class="math inline">\(k\)</span>-Medoids</h2>
<p><em>Partitioning clustering</em> are clustering methods used to classify observations, within a dataset, into multiple groups based ion their similrity. The algorithms require the analyst to specify the number of clusters to be generated.</p>
<p>The commonly used partitioning clustering includes:</p>
<ul>
<li><span class="math inline">\(K\)</span>-means clustering <span class="citation" data-cites="macqueen1967">(<a href="#ref-macqueen1967" role="doc-biblioref">MacQueen 1967</a>)</span> in which ,each cluster is represented by the center or means of the data points belonging to the cluster. The <span class="math inline">\(K\)</span>-means method is sensitive to anomalous data points and outliers.</li>
<li><span class="math inline">\(K\)</span>-medoids clustering or PAM (Partitioning Around Medoids) <span class="citation" data-cites="kaufman1990">(<a href="#ref-kaufman1990" role="doc-biblioref">Kaufman and Rousseeuw 1990</a>)</span> in which , each cluster is reprsented by one of the objects in the cluster. PAM is less sensitive to outliers compared to <span class="math inline">\(K\)</span>-means.</li>
<li>CLARA (Clustering Large Applications) algorithm, which is an extension to PAM adapted for large data sets.</li>
</ul>
<section id="k-means-clustering" class="level3" data-number="10.3.1">
<h3 data-number="10.3.1" class="anchored" data-anchor-id="k-means-clustering"><span class="header-section-number">10.3.1</span> <span class="math inline">\(K\)</span>-Means Clustering</h3>
<p>K-Means aims to partition <span class="math inline">\(n\)</span> observations into <span class="math inline">\(K\)</span> clusters such that each observation belongs to the cluster with the nearest <strong>centroid</strong> (mean of points).</p>
<p>Each cluster is represented by its <em>centroid</em>, which may not be an actual data point.</p>
<p><strong><span class="math inline">\(K\)</span>-means basic ideas</strong></p>
<p>This basic idea behind <span class="math inline">\(K\)</span>-means clustering consists of defining clusters so that the total intra-cluster variation (known as <em>total within-cluster variation</em>) is minimized.</p>
<p>There are several <span class="math inline">\(K\)</span>-means algorithms available. The standard algorithm is the <em>Hartigan-Wong algorithm</em> <span class="citation" data-cites="hartigan1979">(<a href="#ref-hartigan1979" role="doc-biblioref">Hartigan and Wong 1979</a>)</span> which defines the total within-cluster variation as the sum of squared distances Euclidean distances between items and the corresponding centroid: <span class="math display">\[
W(C_k) = \sum_{x_i \in C_k} (x_i - \mu_k)^2
\]</span> where <span class="math inline">\(x_i\)</span> design a data point belonging to the cluster <span class="math inline">\(C_k\)</span> and <span class="math inline">\(\mu_k\)</span> is the mean value of the points assigned to the cluster <span class="math inline">\(C_k\)</span>.</p>
<p>Each observation (<span class="math inline">\(x_i\)</span>) is assigned to a given cluster such that the sum of squares (SS) distances of the observation to their assigned cluster <span class="math inline">\(\mu_k\)</span> is minimum.</p>
<p>We define the <em>total within-cluster</em> variation as follow: <span class="math display">\[
\text{tot.withinss} = \sum_{k=1}^K W(C_k) = \sum_{k=1}^K \sum_{x_i \in C_k} (x_i - \mu_k)^2
\]</span></p>
<p>The <em>total within-cluster sum of square</em> measures the compactness (i.e.&nbsp;<em>goodness</em>) of the clustering and we want it to be as small as possible.</p>
<p><strong><span class="math inline">\(K\)</span>-means Algorithm</strong></p>
<p>Given a dataset <span class="math inline">\(\mathbf{X}= \{\mathbf{x}_1, \mathbf{x}_2, \ldots, \mathbf{x}_n\}\)</span>:</p>
<ol type="1">
<li>Choose the number of clusters <span class="math inline">\(K\)</span>.<br>
</li>
<li>Initialize <span class="math inline">\(k\)</span> centroids randomly.<br>
</li>
<li><strong>Assign step:</strong> Assign each observation <span class="math inline">\(\mathbf{x}_i\)</span> to the nearest centroid based on the Euclidean distance between the object and the centroid:</li>
<li><span class="math display">\[
c_i = \arg\min_k \|\mathbf{x}_i - \mu_k\|^2
\]</span> where <span class="math inline">\(\mu_k\)</span> is the <span class="math inline">\(k\)</span>st centroid.</li>
<li><strong>Update step:</strong> Recalculate each centroid as the mean of points in its cluster: <span class="math display">\[
\mu_k = \frac{1}{n_k} \sum_{\mathbf{x}_i \in C_k} \mathbf{x}_i
\]</span></li>
<li>Repeat steps 3–4 until centroids stop changing (convergence) or the maximum number of iterations is reached.</li>
</ol>
<p>For better understanding, see this <a href="https://blog.dailydoseofds.com/p/an-animated-guide-to-kmeans">video</a></p>
<div id="qwebr-insertion-location-11"></div>
<noscript>Please enable JavaScript to experience the dynamic code cell content on this page.</noscript>
<section id="properties-and-limitations-of-k-means" class="level4" data-number="10.3.1.1">
<h4 data-number="10.3.1.1" class="anchored" data-anchor-id="properties-and-limitations-of-k-means"><span class="header-section-number">10.3.1.1</span> Properties and Limitations of <span class="math inline">\(K\)</span>-Means</h4>
<p>Although <span class="math inline">\(K\)</span>-means is one of the most popular clustering algorithms, its effectiveness depends on the structure and scale of the data. Understanding its limitations helps decide when to use it — and when to choose a more robust alternative like <span class="math inline">\(K\)</span>-Medoids.</p>
<section id="data-type-and-cluster-shape" class="level5" data-number="10.3.1.1.1">
<h5 data-number="10.3.1.1.1" class="anchored" data-anchor-id="data-type-and-cluster-shape"><span class="header-section-number">10.3.1.1.1</span> <strong>Data Type and Cluster Shape</strong></h5>
<p><span class="math inline">\(K\)</span>-Means works best when:</p>
<ul>
<li><p>All variables are numeric</p></li>
<li><p>and measured on a comparable scale.</p></li>
<li><p>The clusters are <em>spherical</em> (or roughly circular in 2D).</p></li>
<li><p>Each cluster has <em>similar variance</em> and <em>density</em>.</p></li>
</ul>
<p>When clusters are elongated, overlapping, or non-spherical, <span class="math inline">\(K\)</span>-Means may assign points incorrectly because it relies on <em>Euclidean distance</em>.</p>
</section>
<section id="sensitivity-to-scale" class="level5" data-number="10.3.1.1.2">
<h5 data-number="10.3.1.1.2" class="anchored" data-anchor-id="sensitivity-to-scale"><span class="header-section-number">10.3.1.1.2</span> <strong>Sensitivity to Scale</strong></h5>
<p>In clustering, the distance between data points determines how groups are formed.</p>
<p>If variables are measured on very different scales (for example, income in euros and age in years), the variable with the largest numerical range will dominate the distance calculation. As a result, the algorithm may ignore other variables, even if they carry meaningful structure. To correct this imbalance, we use <strong>scaling transformations</strong>, which adjust the magnitude or spread of each variable before computing distances.</p>
<p><strong>Normalization (Min–Max Scaling)</strong> Normalization rescales all variables to a fixed range, usually between <span class="math inline">\(0\)</span> and <span class="math inline">\(1\)</span>: <span class="math display">\[
x' = \frac{x - \min(x)}{\max(x) - \min(x)}
\]</span> This transformation preserves the shape of the distribution but ensures all features contribute equally in magnitude to the distance measure. It is particularly effective when all features have bounded ranges or similar distributions.</p>
<p><strong>Standardization (Z-score Scaling)</strong> Standardization rescales variables so they have mean 0 and standard deviation 1: <span class="math display">\[
x' = \frac{x - \bar{x}}{s_x}
\]</span> where <span class="math inline">\(\bar{x}\)</span> is the mean and <span class="math inline">\(s_x\)</span> is the standard deviation.</p>
<p>This approach centers the data and adjusts for variance, which helps when features have different dispersions or units of measurement. Standardization is preferred when features are expected to follow roughly Gaussian distributions, or when outliers might distort min–max scaling.</p>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Important
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Why It Matters for <span class="math inline">\(k\)</span>-Means and Similar Algorithms</strong></p>
<ul>
<li><p><span class="math inline">\(K\)</span>-means relies on Euclidean distance, which is sensitive to scale. Without scaling, one feature can dominate, producing distorted clusters.</p></li>
<li><p>After scaling or standardization, all variables contribute more fairly, and the clusters tend to reflect combined variation across features.</p></li>
<li><p>Scaling can change the cluster boundaries, but it does not change the underlying data relationships — it only ensures that distances are comparable.</p></li>
</ul>
</div>
</div>
<p>We will show the effect of normalization and standardization on the data.</p>
<div id="qwebr-insertion-location-12"></div>
<noscript>Please enable JavaScript to experience the dynamic code cell content on this page.</noscript>
<p>Now, we apply <span class="math inline">\(K\)</span>-means on the raw dataset.</p>
<div id="qwebr-insertion-location-13"></div>
<noscript>Please enable JavaScript to experience the dynamic code cell content on this page.</noscript>
<p>Now, we normalize the dataset and apply <span class="math inline">\(k\)</span>-means.</p>
<div id="qwebr-insertion-location-14"></div>
<noscript>Please enable JavaScript to experience the dynamic code cell content on this page.</noscript>
<p>It is the time to standarize the dataset before applyong <span class="math inline">\(k\)</span>-means.</p>
<div id="qwebr-insertion-location-15"></div>
<noscript>Please enable JavaScript to experience the dynamic code cell content on this page.</noscript>
</section>
</section>
<section id="measures-of-cluster-quality" class="level4" data-number="10.3.1.2">
<h4 data-number="10.3.1.2" class="anchored" data-anchor-id="measures-of-cluster-quality"><span class="header-section-number">10.3.1.2</span> Measures of Cluster Quality</h4>
<p>To evaluate and compare clustering results, we rely on <em>internal validation measures</em> — those that assess how compact and well-separated the clusters are, using only the data itself.</p>
<p>The most common measures include:</p>
<section id="within-cluster-sum-of-squares-wss" class="level5" data-number="10.3.1.2.1">
<h5 data-number="10.3.1.2.1" class="anchored" data-anchor-id="within-cluster-sum-of-squares-wss"><span class="header-section-number">10.3.1.2.1</span> <strong>Within-Cluster Sum of Squares (WSS)</strong></h5>
<p>The <em>Within-Cluster Sum of Squares</em> measures how tightly the data points in a cluster are grouped around their centroid. <span class="math display">\[
\text{WSS} = \sum_{k=1}^{K} \sum_{\mathbf{x}_i \in C_k} \|\mathbf{x}_i - \boldsymbol{\mu}_k\|^2
\]</span> where <span class="math inline">\(C_k\)</span> is the set of points in cluster <span class="math inline">\(k\)</span>, <span class="math inline">\(\boldsymbol{\mu}_k\)</span> is the centroid of cluster <span class="math inline">\(k\)</span>, and <span class="math inline">\(\|\cdot\|^2\)</span> shows the squared Euclidean distance between a point and its centroid.</p>
<p>A smaller WSS means <em>more compact clusters</em>.</p>
</section>
<section id="between-cluster-sum-of-squares-bss" class="level5" data-number="10.3.1.2.2">
<h5 data-number="10.3.1.2.2" class="anchored" data-anchor-id="between-cluster-sum-of-squares-bss"><span class="header-section-number">10.3.1.2.2</span> <strong>Between-Cluster Sum of Squares (BSS)</strong></h5>
<p>The <em>Between-Cluster Sum of Squares</em> measures how far apart the cluster centroids are from the overall mean of the dataset. <span class="math display">\[
\text{BSS} = \sum_{k=1}^{K} n_k \| \boldsymbol{\mu}_k - \boldsymbol{\mu} \|^2
\]</span> where <span class="math inline">\(n_k\)</span> is the number of points in cluster <span class="math inline">\(k\)</span>, <span class="math inline">\(\boldsymbol{\mu}_k\)</span> is the centroid of cluster <span class="math inline">\(k\)</span>, and <span class="math inline">\(\boldsymbol{\mu}\)</span> is the global mean of all data points.</p>
<p>A larger BSS means <em>better separation</em> between clusters.</p>
</section>
<section id="total-sum-of-squares-tss" class="level5" data-number="10.3.1.2.3">
<h5 data-number="10.3.1.2.3" class="anchored" data-anchor-id="total-sum-of-squares-tss"><span class="header-section-number">10.3.1.2.3</span> <strong>Total Sum of Squares (TSS)</strong></h5>
<p>The <em>Total Sum of Squares</em> represents the overall variation in the dataset: <span class="math display">\[
\text{TSS} = \sum_{i=1}^{n} \|\mathbf{x}_i - \boldsymbol{\mu}\|^2
\]</span></p>
<p>This relationship always holds: <span class="math display">\[
\text{TSS} = \text{BSS} + \text{WSS}
\]</span></p>
<p>This decomposition allows us to express clustering performance as a proportion of explained variance: <span class="math display">\[
\text{Ratio} = \frac{\text{BSS}}{\text{TSS}}
\]</span></p>
<p>A higher ratio means that the clusters explain a greater proportion of the data’s variance.</p>
</section>
<section id="silhouette-coefficient" class="level5" data-number="10.3.1.2.4">
<h5 data-number="10.3.1.2.4" class="anchored" data-anchor-id="silhouette-coefficient"><span class="header-section-number">10.3.1.2.4</span> <strong>Silhouette Coefficient</strong></h5>
<p>The <em>Silhouette Coefficient</em> combines <em>cohesion</em> (how close points are within a cluster) and <em>separation</em> (how far points are from other clusters): <span class="math display">\[
s(i) = \frac{b(i) - a(i)}{\max(a(i), b(i))}
\]</span> where <span class="math inline">\(a(i)\)</span> is the average distance from point <span class="math inline">\(i\)</span> to all other points in its cluster, and <span class="math inline">\(b(i)\)</span> is the smallest average distance from point <span class="math inline">\(i\)</span> to points in another cluster.</p>
<p>Values range from <span class="math inline">\(–1\)</span> to <span class="math inline">\(1\)</span>, where values <strong>close to <span class="math inline">\(1\)</span></strong> indicate that observations are well-clustered, values <strong>around <span class="math inline">\(0\)</span></strong> suggest that points lie near cluster boundaries, and <strong>negative</strong> values indicate that observations are likely misclassified or assigned to the wrong cluster.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Summary</strong></p>
<table class="caption-top table">
<thead>
<tr class="header">
<th style="text-align: left;">Measure</th>
<th style="text-align: left;">Description</th>
<th style="text-align: left;">Ideal Value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><strong>WSS</strong></td>
<td style="text-align: left;">Compactness within clusters</td>
<td style="text-align: left;">Low</td>
</tr>
<tr class="even">
<td style="text-align: left;"><strong>BSS</strong></td>
<td style="text-align: left;">Separation between clusters</td>
<td style="text-align: left;">High</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><strong>BSS / TSS</strong></td>
<td style="text-align: left;">Proportion of explained variance</td>
<td style="text-align: left;">High</td>
</tr>
<tr class="even">
<td style="text-align: left;"><strong>Silhouette</strong></td>
<td style="text-align: left;">Cohesion and separation combined</td>
<td style="text-align: left;">Close to 1</td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Important
</div>
</div>
<div class="callout-body-container callout-body">
<p>Good clustering minimizes <strong>WSS</strong> and maximizes <strong>BSS</strong>, producing compact, well-separated groups.<br>
The <strong>Elbow Method</strong> helps find a balance between simplicity (few clusters) and accuracy (tight, distinct groups).</p>
</div>
</div>
<p><strong>Implementation in R</strong></p>
<p>The standard R function for <span class="math inline">\(K\)</span>-means clustering is <code>stats::kmeans()</code> which simplified format is as follow:</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb6"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="fu">kmeans</span>(x, centers, <span class="at">iter.max =</span> <span class="dv">10</span>, <span class="at">nstart =</span> <span class="dv">1</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<p>where: - <code>x</code>: numeric matrix, numeric data frame or a numeric vevtor - <code>centers</code>: possible values are the number of clusters (<span class="math inline">\(k\)</span>) or a set of initial (distinct) cluster centers. If a number, a random set of (distinct) rows in <span class="math inline">\(x\)</span> is chosen as the initial centers. - <code>iter.max</code>: the maximum number of iterations allowed. Default value if <span class="math inline">\(10\)</span>. - <code>nstart</code>: the number of random starting partitions when centers is a number. Trying <code>nstart &gt; 1</code> is often recommended.</p>
<p>To create a beautiful graph of the clusters generated with the <code>kmeans()</code> function, will use the <code>factoextra</code> package.</p>
<p><strong>Computing <span class="math inline">\(K\)</span>-means clustering</strong></p>
<p>As <span class="math inline">\(K\)</span>-means clustering algorithm starts with <span class="math inline">\(K\)</span> randomly selected centroids, it is always recommended to use the <code>set.seed()</code> function in order to set a seed for <code>R</code>’s random number generator. The aim of using this function is to make reproducible the results.</p>
<p>The <code>R</code> code below performs <span class="math inline">\(K\)</span>-means clustering with <span class="math inline">\(K = 4\)</span>:</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb7"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>km.res <span class="ot">&lt;-</span> <span class="fu">kmeans</span>(df, <span class="at">k =</span> <span class="dv">4</span>, <span class="at">nstart =</span> <span class="dv">25</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Tip
</div>
</div>
<div class="callout-body-container callout-body">
<p>Actually, <span class="math inline">\(K\)</span>-means starts by randomly choosing <span class="math inline">\(K\)</span> points as <em>initial centroids</em>. Depending on these starting points, the algorithm can converge to <em>different local minima</em> — meaning the results may vary across runs. So, <code>nstart</code> means number of random initial sets of centroids to try and then, R will run the algorithm that many times and keep the best result (the one with the lowest total within-cluster sum of squares).</p>
<p>The default value of <code>nstart</code> in R is one. But, it is strongly recommended to compute <span class="math inline">\(K\)</span>-means clustering with a large value of <code>nstart</code> such as <span class="math inline">\(25\)</span> or <span class="math inline">\(50\)</span>, in order to have a more stable result.</p>
</div>
</div>
<p>With the function <code>print()</code>, the results of <code>kmeans()</code> that for example in this note, saved in <code>km.res</code></p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb8"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(km.res)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<p>The printed output displys: - the cluster means or centers, that is a matrix which rows are cluster number and columns are variables. - the clustering vector which is a vector of integers (from 1 to <span class="math inline">\(K\)</span>) indicating the cluster to which each point is allocated.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>It is possible to compute the mean of each variable in the dataset by clusters using the original dataset.</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb9"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="fu">aggregate</span>(df, <span class="at">by =</span> <span class="fu">list</span>(<span class="at">cluster=</span>km.res<span class="sc">$</span>cluster), mean)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>It the user is intersted in adding the clusters to the original data, use the following R code</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb10"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cbind</span>(df, <span class="at">cluster =</span> km.res<span class="sc">$</span>cluster)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</div>
</div>
<p><code>kmeans()</code> function returns a list of components, including: - <em>cluster</em>: a vector of integers (from <span class="math inline">\(1\)</span> to <span class="math inline">\(k\)</span>) indicating the cluster to which each point is allocated. - <em>centers</em>: a matrix of cluster centers (cluster means) - <em>totss</em>: the total sum of squares (TSS). It measures the total variance in the data. - <em>withinss</em>: vector of within-cluster sum of squares, one component per cluster - <em>tot.withinss</em>: total within-cluster sum of squares, i.e., <span class="math inline">\(\text{sum}(withinss)\)</span> - <em>betweenss</em>: the between-cluster sum of squares, i.e., <em>totss - tot.withinss</em> - <em>size</em>: the number of observations in each cluster</p>
<p>These components can be accessed as follow:</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb11"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Cluster number for each of the observations</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>km.res<span class="sc">$</span>cluster </span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Cluster size</span></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>km.res<span class="sc">$</span>size</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Cluster means</span></span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a>km.res<span class="sc">$</span>centers</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<p><strong>Visualizing <span class="math inline">\(K\)</span>-means Clusters</strong></p>
<p>It is a good idea to plot the cluster results. These can be used to assess the choice of the number of clusters as well as comparing two different cluster analyses.</p>
<p>The idea is to visualize the data in scatter plot with coloring tach data point according to its cluster assignment.</p>
<p>The problem is that the data contains more than 2 variables and the question is what variables to choose for the <span class="math inline">\(x\)</span>-<span class="math inline">\(y\)</span> scatter plot. A <strong>solution</strong> is to reduce the number of dimensions by applying a dimensionality reduction algorithm, such as <em>principal component analysis (PCA)</em>.</p>
<p>In other words, if we have a multi-dimensional dataset, a solution is to perform <em>PCA</em> and to plot data points according to the first two principal components coordinates.</p>
<p>The function <code>factoextra::fviz_cluster()</code> can be used to easily visulize <span class="math inline">\(K\)</span>-means clusters. It takes <span class="math inline">\(K\)</span>-means results and the original data as arguments. In the resulting plot, observations are represented by points, using orincipal components if the number of variables is greater than <span class="math inline">\(2\)</span>. It is also possible to draw concentration ellipse around each cluster.</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb12"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="fu">fviz_cluster</span>(km.res, <span class="at">data =</span> df,</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="at">palette =</span> <span class="fu">c</span>(<span class="st">"#2E9FDF"</span>, <span class="st">"#00AFBB"</span>, <span class="st">"#E7B800"</span>, <span class="st">"#FC4E07"</span>), <span class="co">#Define colors</span></span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a><span class="at">ellipse.type =</span> <span class="st">"euclid"</span>, <span class="co"># Concentration ellipse</span></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a><span class="at">star.plot =</span> <span class="cn">TRUE</span>, <span class="co"># Add segments from centroids to items</span></span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a><span class="at">repel =</span> <span class="cn">TRUE</span>, <span class="co"># Avoid label overplotting (slow)</span></span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a><span class="at">ggtheme =</span> <span class="fu">theme_minimal</span>()</span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Important
</div>
</div>
<div class="callout-body-container callout-body">
<p><span class="math inline">\(K\)</span>-means clustering is very simple and fast algorithm. It can efficiently deal with very large data sets.</p>
</div>
</div>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Important
</div>
</div>
<div class="callout-body-container callout-body">
<p><span class="math inline">\(K\)</span>-means has some weaknesses, including:</p>
<ul>
<li>It assumes prior knowledge of the data and requires the analyst to choose the appropriate number of cluster (<span class="math inline">\(k\)</span>) in advance.</li>
</ul>
<p><em>Solution</em>: Compute <span class="math inline">\(K\)</span>-means for a range of <span class="math inline">\(K\)</span> values, for example by varying <span class="math inline">\(k\)</span> between <span class="math inline">\(2\)</span> and <span class="math inline">\(10\)</span>. Then choose the best <span class="math inline">\(k\)</span> by comparing the clustering results obtained for different <span class="math inline">\(k\)</span> values.</p>
<ul>
<li>The final results obtained is sensitive to the initial random selection of cluster centers. <em>Why is this a problem?</em> Because, for every different run of the algorithm on the same data set, you may choose different set of initial centers. This may lead to different clustering results on different runs of the algorithm.</li>
</ul>
<p><em>Solution</em>: Compute <span class="math inline">\(K\)</span>-means algorithm several times with different initial cluster centers. The run with the lowest total within-cluster sum of square is selected as the final clustering solution.</p>
<ul>
<li>It is sensitive to outliers.</li>
</ul>
<p><em>Solution</em>: To avoid distortions caused by excessive outliers, it is possible to use PAM algorithm, which is less sensitive to outliers.</p>
</div>
</div>
</section>
</section>
<section id="analysis-of-iris-dataset" class="level4" data-number="10.3.1.3">
<h4 data-number="10.3.1.3" class="anchored" data-anchor-id="analysis-of-iris-dataset"><span class="header-section-number">10.3.1.3</span> Analysis of <code>iris</code> Dataset</h4>
<p>The classic <code>iris</code> dataset contains <span class="math inline">\(150\)</span> flower observations from three species (<em>setosa</em>, <em>versicolor</em>, <em>virginica</em>). Each observation has four numeric features: <code>Sepal.Length</code>, <code>Sepal.Width</code>, <code>Petal.Length</code>, and <code>Petal.Width</code></p>
<div id="qwebr-insertion-location-16"></div>
<noscript>Please enable JavaScript to experience the dynamic code cell content on this page.</noscript>
<p>Suppose that we do not know that there are three groups and the goal is to determine the optimal number of clusters using <em>Elbow method</em></p>
<div id="qwebr-insertion-location-17"></div>
<noscript>Please enable JavaScript to experience the dynamic code cell content on this page.</noscript>
<p>The plot represents the variance within the clusters. It decreases as <span class="math inline">\(k\)</span> increases, but it can be seen a bend (or <em>elbow</em>) at <span class="math inline">\(k = 3\)</span>, matching the three known species.</p>
<p>Another way to visualize the elbow method for choosing the optimal number of clusters is by using the function <code>factoextra::fviz_nbclust()</code>. We can also add a vertical dashed line to indicate the chosen value of <span class="math inline">\(k\)</span>.</p>
<div id="qwebr-insertion-location-18"></div>
<noscript>Please enable JavaScript to experience the dynamic code cell content on this page.</noscript>
<p>Now, we apply <span class="math inline">\(k\)</span>-means algorithm with <span class="math inline">\(k = 3\)</span>.</p>
<div id="qwebr-insertion-location-19"></div>
<noscript>Please enable JavaScript to experience the dynamic code cell content on this page.</noscript>
<div id="qwebr-insertion-location-20"></div>
<noscript>Please enable JavaScript to experience the dynamic code cell content on this page.</noscript>
<p>We compute cluster quality measures.</p>
<div id="qwebr-insertion-location-21"></div>
<noscript>Please enable JavaScript to experience the dynamic code cell content on this page.</noscript>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>What are “discriminative features”?</strong></p>
<p><em>Discriminative features</em> are those that <em>best separate groups or clusters</em> in your data. They are the variables that most strongly differentiate one cluster (or class) from another.</p>
<p>There are two most famous approach to find discriminative features:</p>
<ul>
<li><p>Exploratory approach</p></li>
<li><p>Statistical approach</p></li>
</ul>
<p><strong>Exploratory approach</strong></p>
<div id="qwebr-insertion-location-22"></div>
<noscript>Please enable JavaScript to experience the dynamic code cell content on this page.</noscript>
<p>In this plot, you will notice that:</p>
<ul>
<li><p>Setosa is perfectly separated in the <code>Petal.Length</code>–<code>Petal.Width</code> plane.</p></li>
<li><p>Versicolor and Virginica overlap slightly but still show visible separation.</p></li>
</ul>
<p>That is why we often choose <code>Petal.Length</code> and <code>Petal.Width</code> for visualization — they are the most discriminative pair of features.</p>
<p><strong>Statistical approach</strong> We can quantify which features are most discriminative by computing, for each variable: - The between-group variance (BSS) - The within-group variance (WSS) and comparing their ratio.</p>
<div id="qwebr-insertion-location-23"></div>
<noscript>Please enable JavaScript to experience the dynamic code cell content on this page.</noscript>
<p>The higher this ratio, the better that feature separates the species.</p>
<p>In this results, <code>Petal.Width</code> is clearly the most discriminative feature.</p>
<p>At first glance, it seems that <code>Sepal.Width</code> (124.96) should be more discriminative than <code>Petal.Length</code> (79.51) because its ratio is higher — but this needs context</p>
<p><strong>What the ratio measures?</strong> The ratio BSS/WSS BSS/WSS for each feature is: <span class="math display">\[
\text{Ratio} = \frac{Between-Class&nbsp;Variance}{Within-Class Variance}
\]</span> This tells you, for that one variable alone, how distinct the species means are compared to the variability within each species.</p>
<p>So, mathematically, if <code>Sepal.Width</code> has a higher ratio, it means that species differ more in <code>Sepal.Width</code> (on average) than they do within themselves. <strong>But “discriminative” depends on combined separability</strong></p>
<p>The tricky part is that <code>Sepal.Width</code> alone does not visually separate the species well, even if its numeric ratio looks high. Let us check the data visually:</p>
<div id="qwebr-insertion-location-24"></div>
<noscript>Please enable JavaScript to experience the dynamic code cell content on this page.</noscript>
<p>You see that: - For <code>Sepal.Width</code>, there is a lot of overlap between Versicolor and Virginica. The means differ, but not enough to separate groups clearly.</p>
<ul>
<li>For <code>Petal.Length</code>, Setosa is completely separated, and Versicolor/Virginica overlap less.</li>
</ul>
<p>So even though <code>Sepal.Width</code>’s ratio is high, its overlap pattern means it is less useful for distinguishing all three species.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Tip
</div>
</div>
<div class="callout-body-container callout-body">
<p>The <em>BSS/WSS ratio</em> is a helpful indicator, but not the whole story. Always complement numerical measures with <em>visual inspection</em>.</p>
</div>
</div>
</div>
</div>
<p>Now, based on the most discriminative features, <code>Petal.Length</code> and <code>Petal.Width</code>, we visualize the clusters.</p>
<div id="qwebr-insertion-location-25"></div>
<noscript>Please enable JavaScript to experience the dynamic code cell content on this page.</noscript>
<p>Another way to visulize <span class="math inline">\(K\)</span>-means clusters is using the function <code>fviz_cluster()</code> that used the PCA (the <code>iris_data</code> has 4 variables) with the following code</p>
<div id="qwebr-insertion-location-26"></div>
<noscript>Please enable JavaScript to experience the dynamic code cell content on this page.</noscript>
<p>We can also evaluat clustering with the Silhouette coefficient</p>
<div id="qwebr-insertion-location-27"></div>
<noscript>Please enable JavaScript to experience the dynamic code cell content on this page.</noscript>
<div id="qwebr-insertion-location-28"></div>
<noscript>Please enable JavaScript to experience the dynamic code cell content on this page.</noscript>
<p>The <em>average silhouette width </em>(displayed in the summary) gives an overall quality score.</p>
<ul>
<li><p>Values &gt; <span class="math inline">\(0.5\)</span> indicate clear, well-separated clusters.</p></li>
<li><p>Values around <span class="math inline">\(0.25\)</span>–<span class="math inline">\(0.5\)</span> indicate overlapping clusters.</p></li>
<li><p>Values &lt; <span class="math inline">\(0.25\)</span> indicate poor structure or misclassification.</p></li>
</ul>
<p>In the <code>iris</code> dataset, the average silhouette is typically around <span class="math inline">\(0.55\)</span>–<span class="math inline">\(0.60\)</span>, confirming that <span class="math inline">\(k=3\)</span> is a reasonable choice.</p>
<ul>
<li><em>Setosa</em> usually has near-perfect silhouette values, while <em>Versicolor</em> and <em>Virginica</em> show some overlap — as expected.</li>
</ul>
<p>We can compute the average silhouette width for different numbers of clusters.</p>
<div id="qwebr-insertion-location-29"></div>
<noscript>Please enable JavaScript to experience the dynamic code cell content on this page.</noscript>
<p>Based on the Silhouette plots, the highest average silhouette width occurs at <span class="math inline">\(k = 2\)</span>. This means that, mathematically, dividing the data into two clusters gives the tightest and most well-separated grouping according to the Silhouette metric.</p>
<p>However, <strong>the best numerical score does not always mean the most meaningful clustering</strong>.</p>
<p>At <span class="math inline">\(k =2\)</span>, the algorithm merges two of the real Iris species (versicolor and virginica) into a single cluster. The result has high compactness, but low interpretive accuracy.</p>
<p>At <span class="math inline">\(k = 3\)</span>, the average silhouette width is slightly lower, but the clusters correspond more closely to the true biological species. This result is more meaningful, even if slightly less compact.</p>
<p>Thus, the <em>Silhouette Coefficient</em> and the <em>Elbow Method</em> together suggest that: - <span class="math inline">\(k=2\)</span> yields the most compact clustering, - but <span class="math inline">\(k=3\)</span> represents the optimal trade-off between cluster compactness and real-world interpretability</p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-2-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-2-1" role="tab" aria-controls="tabset-2-1" aria-selected="true" href="">Exercise 1</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-2-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-2-2" role="tab" aria-controls="tabset-2-2" aria-selected="false" href="">Exercise 2</a></li></ul>
<div class="tab-content">
<div id="tabset-2-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-2-1-tab">
<p>Use the built-in dataset <code>USArrests</code>, which contains statistics on violent crime rates in the 1970s for 50 U.S. states.</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb13"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(<span class="st">"USArrests"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<p>Standardize all numeric features before applying <span class="math inline">\(k\)</span>-Means using this R code:</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb14"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>us_data <span class="ot">&lt;-</span> <span class="fu">scale</span>(USArrests)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<p><strong>Elbow Method</strong></p>
<ul>
<li><p>Compute the total within-cluster sum of squares (WSS) for <span class="math inline">\(k=1\)</span> to <span class="math inline">\(10\)</span>.</p></li>
<li><p>Plot the results.</p></li>
<li><p>Identify the “elbow” point.</p></li>
</ul>
<p><strong>Silhouette Method</strong></p>
<ul>
<li><p>Compute the average silhouette width for <span class="math inline">\(k=2\)</span> to <span class="math inline">\(10\)</span>.</p></li>
<li><p>Plot the results using the same approach as in the Iris example.</p></li>
<li><p>Identify the <span class="math inline">\(k\)</span> that maximizes the silhouette width.</p></li>
</ul>
</div>
<div id="tabset-2-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-2-2-tab">
<p>This exercise demonstrates how <span class="math inline">\(k\)</span>-Means clustering can be used beyond data analysis — for image compression.</p>
<p>Each color in an image can be treated as a data point in RGB space, and clustering reduces the number of colors while preserving the main structure.</p>
<p><strong>Load and visualize an image.</strong></p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb15"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(jpeg)</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(dplyr)</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Read example image from R base (or provide your own file path)</span></span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a>url <span class="ot">&lt;-</span> <span class="st">"https://upload.wikimedia.org/wikipedia/commons/3/3f/JPEG_example_flower.jpg"</span></span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a>temp <span class="ot">&lt;-</span> <span class="fu">tempfile</span>(<span class="at">fileext =</span> <span class="st">".jpg"</span>)</span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a><span class="fu">download.file</span>(url, temp, <span class="at">mode =</span> <span class="st">"wb"</span>)</span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a>img <span class="ot">&lt;-</span> <span class="fu">readJPEG</span>(temp)</span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert to data frame</span></span>
<span id="cb15-14"><a href="#cb15-14" aria-hidden="true" tabindex="-1"></a>img_df <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb15-15"><a href="#cb15-15" aria-hidden="true" tabindex="-1"></a><span class="at">R =</span> <span class="fu">as.vector</span>(img[,,<span class="dv">1</span>]),</span>
<span id="cb15-16"><a href="#cb15-16" aria-hidden="true" tabindex="-1"></a><span class="at">G =</span> <span class="fu">as.vector</span>(img[,,<span class="dv">2</span>]),</span>
<span id="cb15-17"><a href="#cb15-17" aria-hidden="true" tabindex="-1"></a><span class="at">B =</span> <span class="fu">as.vector</span>(img[,,<span class="dv">3</span>])</span>
<span id="cb15-18"><a href="#cb15-18" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb15-19"><a href="#cb15-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-20"><a href="#cb15-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Sample only a few thousand pixels to avoid memory explosion</span></span>
<span id="cb15-21"><a href="#cb15-21" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb15-22"><a href="#cb15-22" aria-hidden="true" tabindex="-1"></a>img_sample <span class="ot">&lt;-</span> img_df <span class="sc">%&gt;%</span> <span class="fu">sample_n</span>(<span class="dv">5000</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<p><strong>Determine the optimal number of clusters.</strong></p>
<p>Apply <span class="math inline">\(k\)</span>-means clustering to the RGB values of the image (<code>img_sample</code>) for <span class="math inline">\(k = 2\)</span> to <span class="math inline">\(10\)</span>, using <code>nstart = 10</code>. Then, use both the <strong>Elbow Method</strong> and the <strong>Silhouette Coefficient</strong> to decide which <span class="math inline">\(k\)</span> gives the best balance between cluster compactness and separation. Do both methods suggest the same number of clusters?</p>
<p>When you decide about the optimal <span class="math inline">\(k\)</span>, with the following code, you can compare the original and compressed image.</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb16"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>k <span class="ot">&lt;-</span> <span class="st">'put the optimal value you found'</span></span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>km_colors <span class="ot">&lt;-</span> <span class="fu">kmeans</span>(img_sample, <span class="at">centers =</span> k, <span class="at">nstart =</span> <span class="dv">10</span>)</span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Replace each pixel with its cluster centroid color</span></span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a>compressed_img <span class="ot">&lt;-</span> km_colors<span class="sc">$</span>centers[km_colors<span class="sc">$</span>cluster, ]</span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a>compressed_img <span class="ot">&lt;-</span> <span class="fu">array</span>(compressed_img, <span class="at">dim =</span> <span class="fu">dim</span>(img))</span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>))</span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="dv">0</span>, <span class="at">type =</span> <span class="st">"n"</span>, <span class="at">xlim =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">1</span>), <span class="at">ylim =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">1</span>),</span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a><span class="at">xlab =</span> <span class="st">""</span>, <span class="at">ylab =</span> <span class="st">""</span>, <span class="at">axes =</span> <span class="cn">FALSE</span>, <span class="at">main =</span> <span class="st">"Original Image"</span>)</span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a><span class="fu">rasterImage</span>(img, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb16-16"><a href="#cb16-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-17"><a href="#cb16-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-18"><a href="#cb16-18" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="dv">0</span>, <span class="at">type =</span> <span class="st">"n"</span>, <span class="at">xlim =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">1</span>), <span class="at">ylim =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">1</span>),</span>
<span id="cb16-19"><a href="#cb16-19" aria-hidden="true" tabindex="-1"></a><span class="at">xlab =</span> <span class="st">""</span>, <span class="at">ylab =</span> <span class="st">""</span>, <span class="at">axes =</span> <span class="cn">FALSE</span>, <span class="at">main =</span> <span class="fu">paste</span>(<span class="st">"Compressed Image (k ="</span>, k, <span class="st">")"</span>))</span>
<span id="cb16-20"><a href="#cb16-20" aria-hidden="true" tabindex="-1"></a><span class="fu">rasterImage</span>(compressed_img, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">1</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</div>
</div>
</div>
</section>
</section>
<section id="k-medoids-clustering" class="level3" data-number="10.3.2">
<h3 data-number="10.3.2" class="anchored" data-anchor-id="k-medoids-clustering"><span class="header-section-number">10.3.2</span> <span class="math inline">\(K\)</span>-Medoids Clustering</h3>
<p>The <span class="math inline">\(k\)</span>-medoids algorithm is a partitioning clustering method closely related to <span class="math inline">\(k\)</span>-means, but instead of using the <em>mean (centroid)</em> of points to represent a cluster, it uses an <em>actual observation (medoid)</em> — the most centrally located data point within that cluster.</p>
<p>Formally, a medoid is the point whose average dissimilarity to all other points in the cluster is minimal. i.e, <span class="math display">\[
m_k = \arg\min_{\mathbf{x}_i \in C_k} \sum_{\mathbf{x}_j \in C_k} d(\mathbf{x}_i,\mathbf{x}_j)
\]</span> where <span class="math inline">\(C_k\)</span> is the set of points assigned to cluster <span class="math inline">\(k\)</span>, and <span class="math inline">\(d(\mathbf{x}_i,\mathbf{x}_j)\)</span> is a chosen distance or dissimilarity measure (e.g., Euclidean, Manhattan, etc.)</p>
<p><span class="math inline">\(K\)</span>-medoid is a robust alternative to <span class="math inline">\(K\)</span>-means clustering. This means that, the algorithm of clusters to be generated (like in <span class="math inline">\(K\)</span>-means clustering). A useful approach to determine the optimal number of clusters is the <em>silhouette</em> method.</p>
<p>The most common <span class="math inline">\(K\)</span>-medoids clustering methods is the PAM (Partitioning Around Medoids) algorithm <span class="citation" data-cites="kaufman1990">(<a href="#ref-kaufman1990" role="doc-biblioref">Kaufman and Rousseeuw 1990</a>)</span></p>
<section id="pam-algorithm" class="level4" data-number="10.3.2.1">
<h4 data-number="10.3.2.1" class="anchored" data-anchor-id="pam-algorithm"><span class="header-section-number">10.3.2.1</span> PAM Algorithm</h4>
<p>The PAM algorithm is based on the search for <span class="math inline">\(K\)</span> representative objects or medoids among the observations of the data set. After finding a set of <span class="math inline">\(K\)</span> medoids, clusters are constructed by assigning each observation to the nearest medoid. Next, each selected medoid <span class="math inline">\(m\)</span> and each non-medoid data point are swapped and the objective function is computed. The objective function corresponds to the sum of the dissimilarities of all objects to their nearest medoid. The <em>SWAP</em> step attemps to improve the quality of the clustering by exchanging selected objects (medoids) and non-selected objects. If the objective function can be reduced by interchanging a selected object with an unselected object, then the swap is carried out. This is continued until the objective function can no longer be decreased. The goal is to find <span class="math inline">\(k\)</span> representative objects which minimize the sum of the dissimilarities of the observations to their closest representative object.</p>
<p>In summary, PAM algorithm is:</p>
<ol type="1">
<li><strong>Initialize:</strong> Select <span class="math inline">\(k\)</span> representative objects (medoids) randomly from the dataset.</li>
<li>Calculate the distance (dissimilarity) matrix if it was not provided.</li>
<li><strong>Assign:</strong> Assign each remaining point to the nearest medoid based on the chosen distance metric.</li>
<li><strong>Update:</strong> For each cluster, try swapping the medoid with another point from the same cluster and compute the total cost: <span class="math display">\[
\text{Cost} = \sum_{i=1}^n \min_k d(\mathbf{x}_i, m_k)
\]</span> If a swap reduces the cost, keep it.</li>
<li><strong>Iterate:</strong> Repeat assignment and update steps until the medoids no longer change.</li>
</ol>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Important
</div>
</div>
<div class="callout-body-container callout-body">
<p>The <span class="math inline">\(K\)</span>-medoids algorithm minimizes a <strong>sum of dissimilarities</strong>, not squared distances. Thus, the cluster representative is always a real observation, which makes the method robust when data contain noise, outliers, or mixed types.</p>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>The PAM algorithm works with a matrix of dissimilarity, and to compute this matrix the algorithm can use two metrics: 1. The euclidean distance 2. The Manhattan distance</p>
<p>In practice, you should get similar results most of time, using either euclidean or Manhattan distance. If the dataset contains outliers, Manhattan distance should give more robust results, whereas euclidean would be influenced by unusual values.</p>
</div>
</div>
</section>
<section id="example" class="level4" data-number="10.3.2.2">
<h4 data-number="10.3.2.2" class="anchored" data-anchor-id="example"><span class="header-section-number">10.3.2.2</span> Example</h4>
<p>Consider the following example</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th style="text-align: center;"></th>
<th style="text-align: center;">X</th>
<th style="text-align: center;">Y</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">1</td>
<td style="text-align: center;">9</td>
<td style="text-align: center;">3</td>
</tr>
<tr class="even">
<td style="text-align: center;">2</td>
<td style="text-align: center;">8</td>
<td style="text-align: center;">4</td>
</tr>
<tr class="odd">
<td style="text-align: center;">3</td>
<td style="text-align: center;">4</td>
<td style="text-align: center;">6</td>
</tr>
<tr class="even">
<td style="text-align: center;">4</td>
<td style="text-align: center;">8</td>
<td style="text-align: center;">5</td>
</tr>
<tr class="odd">
<td style="text-align: center;">5</td>
<td style="text-align: center;">2</td>
<td style="text-align: center;">5</td>
</tr>
<tr class="even">
<td style="text-align: center;">6</td>
<td style="text-align: center;">3</td>
<td style="text-align: center;">8</td>
</tr>
<tr class="odd">
<td style="text-align: center;">7</td>
<td style="text-align: center;">8</td>
<td style="text-align: center;">8</td>
</tr>
<tr class="even">
<td style="text-align: center;">8</td>
<td style="text-align: center;">4</td>
<td style="text-align: center;">4</td>
</tr>
<tr class="odd">
<td style="text-align: center;">9</td>
<td style="text-align: center;">10</td>
<td style="text-align: center;">4</td>
</tr>
<tr class="even">
<td style="text-align: center;">10</td>
<td style="text-align: center;">9</td>
<td style="text-align: center;">6</td>
</tr>
</tbody>
</table>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb17"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tibble)</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Dataset (same as your table)</span></span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>points <span class="ot">&lt;-</span> tibble<span class="sc">::</span><span class="fu">tibble</span>(</span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a><span class="at">ID =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">10</span>,</span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a><span class="at">X =</span> <span class="fu">c</span>(<span class="dv">9</span>, <span class="dv">8</span>, <span class="dv">4</span>, <span class="dv">8</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">5</span>, <span class="dv">4</span>, <span class="dv">10</span>, <span class="dv">9</span>),</span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a><span class="at">Y =</span> <span class="fu">c</span>(<span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">6</span>, <span class="dv">5</span>, <span class="dv">5</span>, <span class="dv">8</span>, <span class="dv">8</span>, <span class="dv">4</span>, <span class="dv">4</span>, <span class="dv">6</span>)</span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a>points</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 10 × 3
      ID     X     Y
   &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;
 1     1     9     3
 2     2     8     4
 3     3     4     6
 4     4     8     5
 5     5     2     5
 6     6     3     8
 7     7     5     8
 8     8     4     4
 9     9    10     4
10    10     9     6</code></pre>
</div>
</div>
<p>Assume <span class="math inline">\(k = 2\)</span> and use the specified points (<span class="math inline">\(m_1 = (4,6)\)</span>) and <span class="math inline">\(m_2 = (9,3)\)</span></p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb19"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Define medoid points</span></span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>medoids <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a><span class="at">X =</span> <span class="fu">c</span>(<span class="dv">4</span>, <span class="dv">6</span>),</span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a><span class="at">Y =</span> <span class="fu">c</span>(<span class="dv">9</span>, <span class="dv">3</span>),</span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a><span class="at">label =</span> <span class="fu">c</span>(<span class="st">"Medoid 1"</span>, <span class="st">"Medoid 2"</span>)</span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Scatter plot</span></span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-12"><a href="#cb19-12" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(points, <span class="fu">aes</span>(<span class="at">x =</span> X, <span class="at">y =</span> Y)) <span class="sc">+</span></span>
<span id="cb19-13"><a href="#cb19-13" aria-hidden="true" tabindex="-1"></a><span class="fu">geom_point</span>(<span class="at">size =</span> <span class="dv">3</span>, <span class="at">color =</span> <span class="st">"black"</span>) <span class="sc">+</span></span>
<span id="cb19-14"><a href="#cb19-14" aria-hidden="true" tabindex="-1"></a><span class="fu">geom_point</span>(<span class="at">data =</span> medoids, <span class="fu">aes</span>(<span class="at">x =</span> X, <span class="at">y =</span> Y, <span class="at">color =</span> label), <span class="at">size =</span> <span class="dv">5</span>) <span class="sc">+</span></span>
<span id="cb19-15"><a href="#cb19-15" aria-hidden="true" tabindex="-1"></a><span class="fu">geom_text</span>(<span class="fu">aes</span>(<span class="at">label =</span> ID), <span class="at">vjust =</span> <span class="sc">-</span><span class="dv">1</span>, <span class="at">size =</span> <span class="dv">3</span>) <span class="sc">+</span></span>
<span id="cb19-16"><a href="#cb19-16" aria-hidden="true" tabindex="-1"></a><span class="fu">scale_color_manual</span>(<span class="at">values =</span> <span class="fu">c</span>(<span class="st">"Medoid 1"</span> <span class="ot">=</span> <span class="st">"red"</span>, <span class="st">"Medoid 2"</span> <span class="ot">=</span> <span class="st">"blue"</span>)) <span class="sc">+</span></span>
<span id="cb19-17"><a href="#cb19-17" aria-hidden="true" tabindex="-1"></a><span class="fu">labs</span>(</span>
<span id="cb19-18"><a href="#cb19-18" aria-hidden="true" tabindex="-1"></a><span class="at">title =</span> <span class="st">"K-Medoids Example Dataset"</span>,</span>
<span id="cb19-19"><a href="#cb19-19" aria-hidden="true" tabindex="-1"></a><span class="at">subtitle =</span> <span class="st">"Initial medoids highlighted in red and blue"</span>,</span>
<span id="cb19-20"><a href="#cb19-20" aria-hidden="true" tabindex="-1"></a><span class="at">x =</span> <span class="st">"X coordinate"</span>,</span>
<span id="cb19-21"><a href="#cb19-21" aria-hidden="true" tabindex="-1"></a><span class="at">y =</span> <span class="st">"Y coordinate"</span>,</span>
<span id="cb19-22"><a href="#cb19-22" aria-hidden="true" tabindex="-1"></a><span class="at">color =</span> <span class="st">"Medoids"</span></span>
<span id="cb19-23"><a href="#cb19-23" aria-hidden="true" tabindex="-1"></a>) <span class="sc">+</span></span>
<span id="cb19-24"><a href="#cb19-24" aria-hidden="true" tabindex="-1"></a><span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb19-25"><a href="#cb19-25" aria-hidden="true" tabindex="-1"></a><span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">"bottom"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="clustring_files/figure-html/example_PAM_plot-1.png" class="img-fluid figure-img" style="width:80.0%"></p>
<figcaption>Scatter plot of the k-medoids example dataset with initial medoids highlighted.</figcaption>
</figure>
</div>
</div>
</div>
<p>Let consider we use <em>Manhattan distance</em> because it is easy to compute and commonly used with <span class="math inline">\(K\)</span>-medoids.</p>
<p><strong>Step 1</strong> – <strong>Assign each point to the nearest medoid</strong></p>
<table class="caption-top table">
<thead>
<tr class="header">
<th style="text-align: right;">ID</th>
<th style="text-align: right;">X</th>
<th style="text-align: right;">Y</th>
<th style="text-align: right;">d to (4,6)</th>
<th style="text-align: right;">d to (9,3)</th>
<th style="text-align: center;">Assign</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">1</td>
<td style="text-align: right;">9</td>
<td style="text-align: right;">3</td>
<td style="text-align: right;">8</td>
<td style="text-align: right;">0</td>
<td style="text-align: center;">C2</td>
</tr>
<tr class="even">
<td style="text-align: right;">2</td>
<td style="text-align: right;">8</td>
<td style="text-align: right;">4</td>
<td style="text-align: right;">6</td>
<td style="text-align: right;">2</td>
<td style="text-align: center;">C2</td>
</tr>
<tr class="odd">
<td style="text-align: right;">3</td>
<td style="text-align: right;">4</td>
<td style="text-align: right;">6</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">8</td>
<td style="text-align: center;">C1</td>
</tr>
<tr class="even">
<td style="text-align: right;">4</td>
<td style="text-align: right;">8</td>
<td style="text-align: right;">5</td>
<td style="text-align: right;">5</td>
<td style="text-align: right;">3</td>
<td style="text-align: center;">C2</td>
</tr>
<tr class="odd">
<td style="text-align: right;">5</td>
<td style="text-align: right;">2</td>
<td style="text-align: right;">5</td>
<td style="text-align: right;">3</td>
<td style="text-align: right;">9</td>
<td style="text-align: center;">C1</td>
</tr>
<tr class="even">
<td style="text-align: right;">6</td>
<td style="text-align: right;">3</td>
<td style="text-align: right;">8</td>
<td style="text-align: right;">3</td>
<td style="text-align: right;">11</td>
<td style="text-align: center;">C1</td>
</tr>
<tr class="odd">
<td style="text-align: right;">7</td>
<td style="text-align: right;">5</td>
<td style="text-align: right;">8</td>
<td style="text-align: right;">3</td>
<td style="text-align: right;">9</td>
<td style="text-align: center;">C1</td>
</tr>
<tr class="even">
<td style="text-align: right;">8</td>
<td style="text-align: right;">4</td>
<td style="text-align: right;">4</td>
<td style="text-align: right;">2</td>
<td style="text-align: right;">6</td>
<td style="text-align: center;">C1</td>
</tr>
<tr class="odd">
<td style="text-align: right;">9</td>
<td style="text-align: right;">10</td>
<td style="text-align: right;">4</td>
<td style="text-align: right;">8</td>
<td style="text-align: right;">2</td>
<td style="text-align: center;">C2</td>
</tr>
<tr class="even">
<td style="text-align: right;">10</td>
<td style="text-align: right;">9</td>
<td style="text-align: right;">6</td>
<td style="text-align: right;">5</td>
<td style="text-align: right;">3</td>
<td style="text-align: center;">C2</td>
</tr>
</tbody>
</table>
<p>Clusters after assignment is:</p>
<ul>
<li><span class="math inline">\(C_1(m_1) = \{3,5,6,7,8\}\)</span> (around <span class="math inline">\((4,6)\)</span>)</li>
<li><span class="math inline">\(C_2(m_2) = \{1,2,4,9,10\}\)</span> (around <span class="math inline">\((9,3)\)</span>)</li>
</ul>
<p>The total cost (sum of within-cluster distances) is <span class="math display">\[
C_1 + C_2 = 9 + 11 = 20
\]</span> where: - <span class="math inline">\(C_1 = 0 + 3 + 3 + 3 + 2  = 11\)</span> - <span class="math inline">\(C_2 = 0 + 2 + 2 + 2 + 3 = 9\)</span></p>
<p>** Step2** – Update (try swaps)</p>
<p>We evaluate each point in a cluster as a potential medoid, computing the sum of Manhattan distances to all other points in that cluster.</p>
<p><strong>Cluster C1 = {3,5,6,7,8}</strong></p>
<table class="caption-top table">
<thead>
<tr class="header">
<th style="text-align: center;">Candidate (ID)</th>
<th style="text-align: center;">Sum of distances</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">3 (4,6)</td>
<td style="text-align: center;"><strong>11 ← best</strong></td>
</tr>
<tr class="even">
<td style="text-align: center;">5 (2,5)</td>
<td style="text-align: center;">16</td>
</tr>
<tr class="odd">
<td style="text-align: center;">6 (3,8)</td>
<td style="text-align: center;">14</td>
</tr>
<tr class="even">
<td style="text-align: center;">7 (5,8)</td>
<td style="text-align: center;">16</td>
</tr>
<tr class="odd">
<td style="text-align: center;">8 (4,4)</td>
<td style="text-align: center;">15</td>
</tr>
</tbody>
</table>
<p><strong>Cluster C2 = {1,2,4,9,10}</strong></p>
<table class="caption-top table">
<thead>
<tr class="header">
<th style="text-align: center;">Candidate (ID)</th>
<th style="text-align: center;">Sum of distances</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">1 (9,3)</td>
<td style="text-align: center;">10</td>
</tr>
<tr class="even">
<td style="text-align: center;">2 (8,4)</td>
<td style="text-align: center;"><strong>8 ← best</strong></td>
</tr>
<tr class="odd">
<td style="text-align: center;">4 (8,5)</td>
<td style="text-align: center;">9</td>
</tr>
<tr class="even">
<td style="text-align: center;">9 (10,4)</td>
<td style="text-align: center;">10</td>
</tr>
<tr class="odd">
<td style="text-align: center;">10 (9,6)</td>
<td style="text-align: center;">11</td>
</tr>
</tbody>
</table>
<p>Update result:</p>
<ul>
<li>Medoid for <span class="math inline">\(C_1\)</span> stays ID 3 (<span class="math inline">\((4,6)\)</span>)</li>
<li>Medoid for <span class="math inline">\(C_2\)</span> changes to ID 2 (<span class="math inline">\((8,4)\)</span>) which it improves the total cost.</li>
</ul>
<p>After updating the medoids, the next step is to recompute the total cost (sum of distances from each point to its nearest medoid).</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th style="text-align: right;">ID</th>
<th style="text-align: right;">X</th>
<th style="text-align: right;">Y</th>
<th style="text-align: right;">d to (4,6)</th>
<th style="text-align: right;">d to (8,4)</th>
<th style="text-align: right;">min d</th>
<th style="text-align: center;">Assign</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">1</td>
<td style="text-align: right;">9</td>
<td style="text-align: right;">3</td>
<td style="text-align: right;">8</td>
<td style="text-align: right;">2</td>
<td style="text-align: right;">2</td>
<td style="text-align: center;">C2</td>
</tr>
<tr class="even">
<td style="text-align: right;">2</td>
<td style="text-align: right;">8</td>
<td style="text-align: right;">4</td>
<td style="text-align: right;">6</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">0</td>
<td style="text-align: center;">C2</td>
</tr>
<tr class="odd">
<td style="text-align: right;">3</td>
<td style="text-align: right;">4</td>
<td style="text-align: right;">6</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">6</td>
<td style="text-align: right;">0</td>
<td style="text-align: center;">C1</td>
</tr>
<tr class="even">
<td style="text-align: right;">4</td>
<td style="text-align: right;">8</td>
<td style="text-align: right;">5</td>
<td style="text-align: right;">5</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">1</td>
<td style="text-align: center;">C2</td>
</tr>
<tr class="odd">
<td style="text-align: right;">5</td>
<td style="text-align: right;">2</td>
<td style="text-align: right;">5</td>
<td style="text-align: right;">3</td>
<td style="text-align: right;">7</td>
<td style="text-align: right;">3</td>
<td style="text-align: center;">C1</td>
</tr>
<tr class="even">
<td style="text-align: right;">6</td>
<td style="text-align: right;">3</td>
<td style="text-align: right;">8</td>
<td style="text-align: right;">3</td>
<td style="text-align: right;">9</td>
<td style="text-align: right;">3</td>
<td style="text-align: center;">C1</td>
</tr>
<tr class="odd">
<td style="text-align: right;">7</td>
<td style="text-align: right;">5</td>
<td style="text-align: right;">8</td>
<td style="text-align: right;">3</td>
<td style="text-align: right;">7</td>
<td style="text-align: right;">3</td>
<td style="text-align: center;">C1</td>
</tr>
<tr class="even">
<td style="text-align: right;">8</td>
<td style="text-align: right;">4</td>
<td style="text-align: right;">4</td>
<td style="text-align: right;">2</td>
<td style="text-align: right;">4</td>
<td style="text-align: right;">2</td>
<td style="text-align: center;">C1</td>
</tr>
<tr class="odd">
<td style="text-align: right;">9</td>
<td style="text-align: right;">10</td>
<td style="text-align: right;">4</td>
<td style="text-align: right;">8</td>
<td style="text-align: right;">2</td>
<td style="text-align: right;">2</td>
<td style="text-align: center;">C2</td>
</tr>
<tr class="even">
<td style="text-align: right;">10</td>
<td style="text-align: right;">9</td>
<td style="text-align: right;">6</td>
<td style="text-align: right;">5</td>
<td style="text-align: right;">3</td>
<td style="text-align: right;">3</td>
<td style="text-align: center;">C2</td>
</tr>
</tbody>
</table>
<p>The total cost (sum of within-cluster distances) is <span class="math display">\[
C_1 + C_2 = (0+1+3+3+3+2) + (2+0+1+2+3) = 19
\]</span></p>
<p>the following R code helps to do the computations.</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb20"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(dplyr)</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Data</span></span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a>pts <span class="ot">&lt;-</span> tibble<span class="sc">::</span><span class="fu">tibble</span>(</span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">ID =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">10</span>,</span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">X  =</span> <span class="fu">c</span>(<span class="dv">9</span>,<span class="dv">8</span>,<span class="dv">4</span>,<span class="dv">8</span>,<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">5</span>,<span class="dv">4</span>,<span class="dv">10</span>,<span class="dv">9</span>),</span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">Y  =</span> <span class="fu">c</span>(<span class="dv">3</span>,<span class="dv">4</span>,<span class="dv">6</span>,<span class="dv">5</span>,<span class="dv">5</span>,<span class="dv">8</span>,<span class="dv">8</span>,<span class="dv">4</span>, <span class="dv">4</span>,<span class="dv">6</span>)</span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true" tabindex="-1"></a>manhattan <span class="ot">&lt;-</span> <span class="cf">function</span>(a, b) <span class="fu">sum</span>(<span class="fu">abs</span>(a <span class="sc">-</span> b))</span>
<span id="cb20-11"><a href="#cb20-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-12"><a href="#cb20-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Helper to compute total cost for given medoids</span></span>
<span id="cb20-13"><a href="#cb20-13" aria-hidden="true" tabindex="-1"></a>total_cost <span class="ot">&lt;-</span> <span class="cf">function</span>(m1, m2) {</span>
<span id="cb20-14"><a href="#cb20-14" aria-hidden="true" tabindex="-1"></a>  pts <span class="sc">%&gt;%</span></span>
<span id="cb20-15"><a href="#cb20-15" aria-hidden="true" tabindex="-1"></a>    <span class="fu">rowwise</span>() <span class="sc">%&gt;%</span></span>
<span id="cb20-16"><a href="#cb20-16" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mutate</span>(</span>
<span id="cb20-17"><a href="#cb20-17" aria-hidden="true" tabindex="-1"></a>      <span class="at">d1 =</span> <span class="fu">manhattan</span>(<span class="fu">c</span>(X, Y), m1),</span>
<span id="cb20-18"><a href="#cb20-18" aria-hidden="true" tabindex="-1"></a>      <span class="at">d2 =</span> <span class="fu">manhattan</span>(<span class="fu">c</span>(X, Y), m2),</span>
<span id="cb20-19"><a href="#cb20-19" aria-hidden="true" tabindex="-1"></a>      <span class="at">mind =</span> <span class="fu">min</span>(d1, d2),</span>
<span id="cb20-20"><a href="#cb20-20" aria-hidden="true" tabindex="-1"></a>      <span class="at">Assign =</span> <span class="fu">if_else</span>(d1 <span class="sc">&lt;=</span> d2, <span class="st">"C1"</span>, <span class="st">"C2"</span>)</span>
<span id="cb20-21"><a href="#cb20-21" aria-hidden="true" tabindex="-1"></a>    ) <span class="sc">%&gt;%</span></span>
<span id="cb20-22"><a href="#cb20-22" aria-hidden="true" tabindex="-1"></a>    <span class="fu">ungroup</span>()</span>
<span id="cb20-23"><a href="#cb20-23" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb20-24"><a href="#cb20-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-25"><a href="#cb20-25" aria-hidden="true" tabindex="-1"></a><span class="co"># Initial medoids: (4,6), (9,3)</span></span>
<span id="cb20-26"><a href="#cb20-26" aria-hidden="true" tabindex="-1"></a>init_tbl <span class="ot">&lt;-</span> <span class="fu">total_cost</span>(<span class="fu">c</span>(<span class="dv">4</span>,<span class="dv">6</span>), <span class="fu">c</span>(<span class="dv">9</span>,<span class="dv">3</span>))</span>
<span id="cb20-27"><a href="#cb20-27" aria-hidden="true" tabindex="-1"></a>sum_init <span class="ot">&lt;-</span> <span class="fu">sum</span>(init_tbl<span class="sc">$</span>mind)</span>
<span id="cb20-28"><a href="#cb20-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-29"><a href="#cb20-29" aria-hidden="true" tabindex="-1"></a><span class="co"># Updated medoids: (4,6), (8,4)</span></span>
<span id="cb20-30"><a href="#cb20-30" aria-hidden="true" tabindex="-1"></a>upd_tbl  <span class="ot">&lt;-</span> <span class="fu">total_cost</span>(<span class="fu">c</span>(<span class="dv">4</span>,<span class="dv">6</span>), <span class="fu">c</span>(<span class="dv">8</span>,<span class="dv">4</span>))</span>
<span id="cb20-31"><a href="#cb20-31" aria-hidden="true" tabindex="-1"></a>sum_upd  <span class="ot">&lt;-</span> <span class="fu">sum</span>(upd_tbl<span class="sc">$</span>mind)</span>
<span id="cb20-32"><a href="#cb20-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-33"><a href="#cb20-33" aria-hidden="true" tabindex="-1"></a><span class="fu">list</span>(</span>
<span id="cb20-34"><a href="#cb20-34" aria-hidden="true" tabindex="-1"></a>  <span class="at">initial_total =</span> sum_init,</span>
<span id="cb20-35"><a href="#cb20-35" aria-hidden="true" tabindex="-1"></a>  <span class="at">updated_total =</span> sum_upd,</span>
<span id="cb20-36"><a href="#cb20-36" aria-hidden="true" tabindex="-1"></a>  <span class="at">initial_assignments =</span> init_tbl <span class="sc">%&gt;%</span> <span class="fu">select</span>(ID, X, Y, d1, d2, mind, Assign),</span>
<span id="cb20-37"><a href="#cb20-37" aria-hidden="true" tabindex="-1"></a>  <span class="at">updated_assignments =</span> upd_tbl <span class="sc">%&gt;%</span> <span class="fu">select</span>(ID, X, Y, d1, d2, mind, Assign)</span>
<span id="cb20-38"><a href="#cb20-38" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>$initial_total
[1] 21

$updated_total
[1] 19

$initial_assignments
# A tibble: 10 × 7
      ID     X     Y    d1    d2  mind Assign
   &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; 
 1     1     9     3     8     0     0 C2    
 2     2     8     4     6     2     2 C2    
 3     3     4     6     0     8     0 C1    
 4     4     8     5     5     3     3 C2    
 5     5     2     5     3     9     3 C1    
 6     6     3     8     3    11     3 C1    
 7     7     5     8     3     9     3 C1    
 8     8     4     4     2     6     2 C1    
 9     9    10     4     8     2     2 C2    
10    10     9     6     5     3     3 C2    

$updated_assignments
# A tibble: 10 × 7
      ID     X     Y    d1    d2  mind Assign
   &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; 
 1     1     9     3     8     2     2 C2    
 2     2     8     4     6     0     0 C2    
 3     3     4     6     0     6     0 C1    
 4     4     8     5     5     1     1 C2    
 5     5     2     5     3     7     3 C1    
 6     6     3     8     3     9     3 C1    
 7     7     5     8     3     7     3 C1    
 8     8     4     4     2     4     2 C1    
 9     9    10     4     8     2     2 C2    
10    10     9     6     5     3     3 C2    </code></pre>
</div>
</div>
<p>Since there is an improvement in the total cost, we continue with the new medoids: <span class="math inline">\((4,6)\)</span> and <span class="math inline">\((8,4)\)</span>.</p>
<p><strong>Exercise</strong> Continue this process and find the best medoids.</p>
</section>
<section id="implementation-pam-in-r" class="level4" data-number="10.3.2.3">
<h4 data-number="10.3.2.3" class="anchored" data-anchor-id="implementation-pam-in-r"><span class="header-section-number">10.3.2.3</span> Implementation PAM in R</h4>
<p>The function <code>cluster::pam()</code> and <code>fpc::pamk()</code> can be used compute PAM.</p>
<p>The function <code>pamk()</code> does not require a user to decide the number of clusters <span class="math inline">\(K\)</span>.</p>
<p>The simplified format of <code>pam()</code> is</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb22"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="fu">pam</span>(x, k, <span class="at">metric =</span> <span class="st">'euclidean'</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<p>where:</p>
<ul>
<li><code>x</code>: possible value includes: numeric data matrix or numeric data frame, or dissimilarity matrix – in this case <code>x</code> is typically the output of <code>daisy()</code> or <code>dist()</code>.</li>
<li><code>k</code>: the number of clusters</li>
<li><code>metric</code>: the distance matrix to be used. Available options are <code>"euclidean"</code> and <code>"manhattan"</code>.</li>
<li><code>stand</code>: logical value; if <code>TRUE</code>, the variables (columns) in <code>x</code> are standardized before calculating the dissilarities. Ignored when <code>x</code> is a dissimilarity matrix.</li>
</ul>
<p>Similar to <span class="math inline">\(K\)</span>-means, the following <code>R</code> code computes PAM algorithm ::: {.aside}</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb23"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>pam.res <span class="ot">&lt;-</span> <span class="fu">pam</span>(df, <span class="at">k =</span> <span class="dv">2</span>)</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a><span class="co"># print the results </span></span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(pam.res)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<p>The printed output shows:</p>
<ul>
<li>the cluster medoids: a matrix, which rows are the medoids and columns are varibles</li>
<li>the clustering vector: a vector of integers (from <span class="math inline">\(1\)</span> to <span class="math inline">\(k\)</span>) indicating the cluster to which point is allocated.</li>
</ul>
<p>The function <code>pam()</code> returns an object of class <em>pam</em> which components include:</p>
<ul>
<li><em>medoids</em>: Objects that represent clusters</li>
<li><em>clustering</em>: a vector containing the cluster number of each object</li>
</ul>
<p>These components can be accessed as</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb24"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Cluster medoids</span></span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>pam.res<span class="sc">$</span>medoids</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Cluster numbers</span></span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a>pm.res<span class="sc">$</span>clustering</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<p>To create a beautiful graph of the clusters generated with the <code>pam()</code> function, similar to <span class="math inline">\(K\)</span>-means, the function <code>factoextra::fviz_cluster()</code> can be used as</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb25"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="fu">fviz_cluster</span>(pam.res,</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">palette =</span> <span class="fu">c</span>(<span class="st">"#00AFBB"</span>, <span class="st">"#FC4E07"</span>), <span class="co"># color palette</span></span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">ellipse.type =</span> <span class="st">"t"</span>, <span class="co"># Concentration ellipse</span></span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">repel =</span> <span class="cn">TRUE</span>, <span class="co"># Avoid label overplotting (slow)</span></span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">ggtheme =</span> <span class="fu">theme_classic</span>()</span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</section>
<section id="estimating-the-optimal-number-of-clusters" class="level4" data-number="10.3.2.4">
<h4 data-number="10.3.2.4" class="anchored" data-anchor-id="estimating-the-optimal-number-of-clusters"><span class="header-section-number">10.3.2.4</span> Estimating the optimal number of clusters</h4>
<p>To estimate the optimal number of clusters, we will use the average silhouette method. The idea is to compute PAM algorithm using different values of clusters <span class="math inline">\(k\)</span>. Next, the average clusters silhouette is drawn according to the number of clusters. The average silhouette measures the quality of a clustering. A high average silhouette width indicates a good clustering. The optimal number of clusters <span class="math inline">\(k\)</span> is the one that maximize the average silhouette over a range of possible values for <span class="math inline">\(k\)</span> <span class="citation" data-cites="kaufman1990">(<a href="#ref-kaufman1990" role="doc-biblioref">Kaufman and Rousseeuw 1990</a>)</span>.</p>
<p>The R function <code>factoextra::fviz_nbclust()</code> provides a convenient solution to estimate the optimal number of clusters.</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb26"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(cluster)</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(factoextra)</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a><span class="fu">fviz_nbclust</span>(df, pam, <span class="at">method =</span> <span class="st">"silhouette"</span>)<span class="sc">+</span></span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a><span class="fu">theme_classic</span>()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</section>
<section id="example-of-pam-in-r" class="level4" data-number="10.3.2.5">
<h4 data-number="10.3.2.5" class="anchored" data-anchor-id="example-of-pam-in-r"><span class="header-section-number">10.3.2.5</span> Example of PAM in R</h4>
<p>Here, we apply PAM algoritm to <code>iris</code> dataset and we expect to have similar results to <span class="math inline">\(K\)</span>-means since there is no outlier in this dataset.</p>
<div id="qwebr-insertion-location-30"></div>
<noscript>Please enable JavaScript to experience the dynamic code cell content on this page.</noscript>
<p>Similar to <span class="math inline">\(K\)</span>-means, we can use the funtion <code>fviz_cluster()</code> with the following code:</p>
<div id="qwebr-insertion-location-31"></div>
<noscript>Please enable JavaScript to experience the dynamic code cell content on this page.</noscript>
<p>As you see, the black stars represent the <em>medoids</em> — actual data points from the dataset.</p>
<p>Unlike <span class="math inline">\(k\)</span>-means, the medoid is a real observation, not an artificial centroid.</p>
<p><strong>Visual Comparison: k-Means vs k-Medoids</strong></p>
<div id="qwebr-insertion-location-32"></div>
<noscript>Please enable JavaScript to experience the dynamic code cell content on this page.</noscript>
</section>
<section id="exercise" class="level4" data-number="10.3.2.6">
<h4 data-number="10.3.2.6" class="anchored" data-anchor-id="exercise"><span class="header-section-number">10.3.2.6</span> Exercise</h4>
<p>The dataset has a mix of numerical, ordinal, and categorical features: <code>Age</code>, <code>Sex</code>, <code>ChestPain</code>, <code>Thal</code>, <code>RestBP</code>, <code>Chol</code>, <code>MaxHR</code>, <code>AHD</code> (disease outcome), etc.</p>
<p>Do the PAM algorithm for this dataset</p>
<div id="qwebr-insertion-location-33"></div>
<noscript>Please enable JavaScript to experience the dynamic code cell content on this page.</noscript>
</section>
</section>
</section>
<section id="cluster-validation" class="level2" data-number="10.4">
<h2 data-number="10.4" class="anchored" data-anchor-id="cluster-validation"><span class="header-section-number">10.4</span> Cluster Validation</h2>
<p>The cluster validation consists of measuring the goodness of clustering results.</p>
<p>Before applying any clustering algorithm to a dataset, the first thing to do is to assess the <em>clustering tendency</em>. That is, whether applying clustering is suitable for the data. If <em>yes</em>, then how many clusters are there. Next, you can perform clustering methods. Finally, you can use a number of measures to evaluate the goodness of the clustering results.</p>
<section id="assessing-clustering-tendency" class="level3" data-number="10.4.1">
<h3 data-number="10.4.1" class="anchored" data-anchor-id="assessing-clustering-tendency"><span class="header-section-number">10.4.1</span> Assessing Clustering Tendency</h3>
<p>Before applying any clustering method on your data, it is important to evaluate whether the datasets contains meaningful (i.e.&nbsp;non-random structures) or not. If yes, then how many clusters are there. This process is defined as the assessing of clustering tendency or the feasibility of the clustering analysis.</p>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Important
</div>
</div>
<div class="callout-body-container callout-body">
<p>A big issue, in cluster analysis, is that clustering methods will return clusters even if the data does not contain any clusters. In other words, if you blindly apply a clustering method on a data set, it will divide the data into clusters because that is what it supposed to do.</p>
</div>
</div>
<section id="methods-for-assessing-clustering-tendency" class="level4" data-number="10.4.1.1">
<h4 data-number="10.4.1.1" class="anchored" data-anchor-id="methods-for-assessing-clustering-tendency"><span class="header-section-number">10.4.1.1</span> Methods for assessing clustering tendency</h4>
<p>There are two methods for evaluating the clustering tendency:</p>
<ul>
<li>a statistical method like <em>Hopkins statistic</em></li>
<li>a visual method like <em>Visual Assessment of Cluster Tendency (VAT)</em> algorithm</li>
</ul>
<section id="statistical-methods" class="level5" data-number="10.4.1.1.1">
<h5 data-number="10.4.1.1.1" class="anchored" data-anchor-id="statistical-methods"><span class="header-section-number">10.4.1.1.1</span> Statistical methods</h5>
<p>The <em>Hopkins statistic</em> is used to assess the clustering tendency of a dataset by measuring the probability that a given dataset is generated by a uniform data distribution. In other words, it tests the spatial randomness of the data.</p>
<p>Let <span class="math inline">\(D\)</span> be a real dataset. The <em>Hopkins statistic</em> can be calculated as follows:</p>
<ol type="1">
<li>Sample uniformly <span class="math inline">\(n\)</span> points (<span class="math inline">\(p_1\)</span>, <span class="math inline">\(\ldots\)</span>, <span class="math inline">\(p_n\)</span>) from <span class="math inline">\(D\)</span>.</li>
<li>For each point <span class="math inline">\(p_i \in D\)</span>, find its nearest neighbor <span class="math inline">\(p_j\)</span>; then compute the distance between <span class="math inline">\(p_i\)</span> and <span class="math inline">\(p_j\)</span> and denote it as <span class="math inline">\(x_i = \text{dist}(p_i, p_j)\)</span></li>
<li>Generate a simulated dataset (<span class="math inline">\(\text{random}_{D}\)</span>) drawn from a random uniform distribution with <span class="math inline">\(n\)</span> points (<span class="math inline">\(q_1\)</span>, <span class="math inline">\(\ldots\)</span>, <span class="math inline">\(q_n\)</span>) and the same variation as the original real dataset <span class="math inline">\(D\)</span>.</li>
<li>For each point <span class="math inline">\(q_i \in \text{random}_D\)</span>, find its nearest neighbour <span class="math inline">\(q_j\)</span> in <span class="math inline">\(D\)</span>; then compute the distance between <span class="math inline">\(q_i\)</span> and <span class="math inline">\(q_j\)</span> and denote it as <span class="math inline">\(y_i = \text{dist}(q_i, q_j)\)</span></li>
<li>Calculate the <em>Hopkins statistic</em> (denoted by <span class="math inline">\(H\)</span>) as the mean nearst neighbour distance in the random dataset divided by the sum of the mean nearst neighbour disrances in the real and across the simulated dataset.</li>
</ol>
<p>The formula is defind as follow: <span class="math display">\[
H = \frac{\sum_{i=1}^n y_i}{\sum_{i=1}^n x_i + \sum_{i=1}^n y_i}
\]</span></p>
<p>A value of <span class="math inline">\(H\)</span> about <span class="math inline">\(0.5\)</span> means that <span class="math inline">\(\sum_{i=1}^n y_i\)</span> and <span class="math inline">\(\sum_{i=1}^n x_i\)</span> are close to each other, and thus the data <span class="math inline">\(D\)</span> is uniformaly distributed.</p>
<p>The null and the alternative hypotheses are defined as follow:</p>
<ul>
<li><strong>null hypothesis</strong>: the dataset <span class="math inline">\(D\)</span> is uniformly distributed (i.e.&nbsp;no meaninful clusters)</li>
<li><strong>alternative hypotheis</strong>: the dataset <span class="math inline">\(D\)</span> is not uniformly distributed (i.e.&nbsp;contains meaningful clusters)</li>
</ul>
<blockquote class="blockquote">
<p>If the value of <em>Hopkins statistic</em> is close to zero, then we can reject the null hypothesis and conclude that the dataset <span class="math inline">\(D\)</span> is significantlt a clusterable data.</p>
</blockquote>
<div class="callout callout-style-simple callout-none no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<p>The <code>R</code> function <code>hopkins::hopkins()</code> can be used to statistically evaluate clustering tendency. The simplified format is</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb27"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="fu">hopkins</span>(data, m)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<p>where:</p>
<ul>
<li><code>data</code>: a dataframe of matrix</li>
<li><code>m</code>: the number of points to be selected from the data</li>
</ul>
</div>
</div>
</div>
<p><strong>Example</strong>:</p>
<p>Consider a generated dataset to compare with the <code>iris</code> dataset.</p>
<div id="qwebr-insertion-location-34"></div>
<noscript>Please enable JavaScript to experience the dynamic code cell content on this page.</noscript>
<p>It can be seen that the <code>iris</code> dataset is highly clusterable (the <span class="math inline">\(H\)</span> value = <span class="math inline">\(0.18\)</span> which is far below the threshold <span class="math inline">\(0.5\)</span>). However, the random dataset is not clusterable (<span class="math inline">\(H = 0.5\)</span>).</p>
</section>
<section id="visual-methods" class="level5" data-number="10.4.1.1.2">
<h5 data-number="10.4.1.1.2" class="anchored" data-anchor-id="visual-methods"><span class="header-section-number">10.4.1.1.2</span> Visual methods</h5>
<p>The algorithm of the visual assessment of cluster tendency (VAT) approach <span class="citation" data-cites="Bezdek2002">(<a href="#ref-Bezdek2002" role="doc-biblioref">Bezdek and Hathaway 2002</a>)</span> is as follow:</p>
<ol type="1">
<li>Compute the dissimilarity (DM) matrix between the observations in the dataset using the Euclidean distance meature</li>
<li>Reorder the DM so that similar objects are close to one another. This process create an ordered dissimilarity (ODM)</li>
<li>The ODM is displayed as an ordered dissimilarity image (ODI), which is the visual output of VAT.</li>
</ol>
<div class="callout callout-style-simple callout-none no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<p>For the visual assessment of clustering tendency, first, the dissimilarity matrix between observations should be computed using the function <code>dist()</code>. Next, the function <code>factoextra::fviz_dist()</code> is used to display the dissimilarity matrix.</p>
</div>
</div>
</div>
<p><strong>Example</strong>: Following the example provided in the statistical methods, we use those datasets, here.</p>
<div id="qwebr-insertion-location-35"></div>
<noscript>Please enable JavaScript to experience the dynamic code cell content on this page.</noscript>
<div id="qwebr-insertion-location-36"></div>
<noscript>Please enable JavaScript to experience the dynamic code cell content on this page.</noscript>
<p>In these plots, red color shows high similarity (i.e., low dissimilarity) and blue colors means low similarity.</p>
<p>THe colour level is proportional to the value of the dissilarity between observations: pure red if <span class="math inline">\(\text{dist}(x_i, x_j) = 0\)</span> and pure blue if <span class="math inline">\(\text{dist}(x_i,x_j) = 1\)</span>. Observations belonging to the same cluster are displayed in consecutive order.</p>
<p>The dissimilarity matrix image confirms that there is a cluster structure in the <code>iris</code> dataset but not un the random one.</p>
<p>The <em>VAT</em> algorithm detects the clustering tendency in a visual form by computing the number of square shaped dark blocks along the diagonal in a <em>VAT</em> image.</p>
</section>
</section>
</section>
<section id="determing-the-optimal-number-of-clusters" class="level3" data-number="10.4.2">
<h3 data-number="10.4.2" class="anchored" data-anchor-id="determing-the-optimal-number-of-clusters"><span class="header-section-number">10.4.2</span> Determing the optimal number of clusters</h3>
<p><em>Determing the optimal number of clusters in a dataset</em> is a fundamental issue in partitioning clustering, such as <span class="math inline">\(k\)</span>-means clustering, which requires the user to specify the number of clusters <span class="math inline">\(k\)</span> to be generated.</p>
<p>Unfortunately, there is no definitive answer to this question. The optimal number of clusters is somehow subjective and depends on the method used for measuring similarities and the parameters used for partitioning.</p>
<p>The methods include direct methods and statistical testing methods:</p>
<ul>
<li><em>Direct methods</em>: consists of optimizing a criterion, such as the within cluster sums of squares or the average silhouette. The corresponding methods are named <em>elbow</em> and <em>silhouette</em> methods, respectively.</li>
<li><em>Statistical testing methods</em>: consists of computing evidence against null hypothesis. An example is <em>gap statistic</em></li>
</ul>
<p>In addition to <em>elbow</em>, <em>silhouette</em>, and <em>gap statistic</em> methods, there are more than <span class="math inline">\(30\)</span> other indices and methods that have been published for identifying the optimal number of clusters. There are some R codes for computing all these <span class="math inline">\(30\)</span> indices in order to decide the best number of clusters using the ``<em>majority rule</em>”.</p>
<section id="elbow-method" class="level4" data-number="10.4.2.1">
<h4 data-number="10.4.2.1" class="anchored" data-anchor-id="elbow-method"><span class="header-section-number">10.4.2.1</span> Elbow method</h4>
<p>Recall that, the basic idea behind partitioning methods, such as <span class="math inline">\(K\)</span>-means clustering, is to define clusters such that the total intra-cluster variation [or total within-cluster sum of square (WSS)] is minimized. The total WSS measures the compactness of the clustering and we want it to be as small as possible.</p>
<p>The Elbow method looks at the total WSS as a function of the number of clusters: One should choose a number of clusters so that adding another cluster does not improve much better the total WSS.</p>
<p>The optimal number of clusters can be defined as follow:</p>
<ol type="1">
<li>Compute clustering algorithm (e.g.&nbsp;<span class="math inline">\(K\)</span>-means clustering) for different values of <span class="math inline">\(k\)</span>. For example, by varying <span class="math inline">\(k\)</span> from <span class="math inline">\(1\)</span> to <span class="math inline">\(10\)</span> clusters.</li>
<li>For each <span class="math inline">\(k\)</span>, calculate the total within-cluster sum of square (WSS).</li>
<li>Plot the curve of WSS according to the number of clusters <span class="math inline">\(k\)</span>.</li>
<li>The location of a bend (knee) in the plot is generally considered as an indicator of the appropraite number of clusters.</li>
</ol>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Tip
</div>
</div>
<div class="callout-body-container callout-body">
<p>Note that the <em>elbow method</em> is sometimes ambiguous. An alternative is the average silhoutte method <span class="citation" data-cites="kaufman1990">(<a href="#ref-kaufman1990" role="doc-biblioref">Kaufman and Rousseeuw 1990</a>)</span> which can be also used with any clustering approach.</p>
</div>
</div>
</section>
<section id="average-silhouette-method" class="level4" data-number="10.4.2.2">
<h4 data-number="10.4.2.2" class="anchored" data-anchor-id="average-silhouette-method"><span class="header-section-number">10.4.2.2</span> Average silhouette method</h4>
<p>The average silhoutte approach measures the quality of a clustering. That is, it determines how well each observation lies within its cluster. A high average silhouette width indicates a good clustering.</p>
<p>Average silhouette methods computes the average silhouette of observations for different values of <span class="math inline">\(k\)</span>. The optimal number of clusters <span class="math inline">\(k\)</span> is one that maximize the average silhouette over a range of possible values for <span class="math inline">\(k\)</span> <span class="citation" data-cites="kaufman1990">(<a href="#ref-kaufman1990" role="doc-biblioref">Kaufman and Rousseeuw 1990</a>)</span>.</p>
<p>The average silhouette method is similar to the <em>elbow</em> method and can be computed as follow:</p>
<ol type="1">
<li>Compute clustering algorithm (e.g.&nbsp;<span class="math inline">\(k\)</span>-means clustering) for different values of <span class="math inline">\(k\)</span>. For instance, by varying from <span class="math inline">\(1\)</span> to <span class="math inline">\(10\)</span> clusters.</li>
<li>For each <span class="math inline">\(k\)</span>, calculate the average silhouette of observations (<em>avg.sil</em>)</li>
<li>Plot the curve of <em>avg.sil</em> according to the number of clusters <span class="math inline">\(k\)</span>.</li>
<li>The location of the maximum is considered as the appropraite number of clusters.</li>
</ol>
</section>
<section id="gap-statistic-method" class="level4" data-number="10.4.2.3">
<h4 data-number="10.4.2.3" class="anchored" data-anchor-id="gap-statistic-method"><span class="header-section-number">10.4.2.3</span> Gap statistic method</h4>
<p>The <em>gap statistic</em> <span class="citation" data-cites="tibshirani2001gap">(<a href="#ref-tibshirani2001gap" role="doc-biblioref">Tibshirani, Walther, and Hastie 2001</a>)</span> can be applied to any clustering method.</p>
<p>The <em>gap statistic</em> compares the total within intra-cluster variation for different values of <span class="math inline">\(k\)</span> with their expected values under null reference distribution of the data. The estimate of the optimal clusters will be value that maximize the gap statistic (i.e., that yields the largest gap statistic). This means that the clustering structure is far away from the random uniform distribution of points.</p>
<p>The algorithm works as follows:</p>
<ol type="1">
<li>Cluster the observed data, varying the number of clusters (<span class="math inline">\(k\)</span>) from <span class="math inline">\(1\)</span> to <span class="math inline">\(k_{\max}\)</span>, and compute the corresponding total within intra-cluster variation <span class="math inline">\(W_k\)</span>.</li>
<li>Generate <span class="math inline">\(B\)</span> reference datasets with a random uniform distribution. Cluster each of these reference dataset with varying number of clusters <span class="math inline">\(k = 1, \ldots, k_{\max}\)</span>, and compute the corresponding total within intra-cluster variation <span class="math inline">\(W_{kb}\)</span>.</li>
<li>Compute the estimated gap statistic as the deviation of the observed <span class="math inline">\(W_k\)</span> value from its expected value <span class="math inline">\(W_{kb}\)</span> under the null hypothesis: <span class="math display">\[
\text{Gap}(k) = \frac{1}{B} \sum_{b=1}^{B} \log(W_{kb}^*) - \log(W_k)
\]</span> Compute also the standard deviation of the statistics.</li>
<li>Choose the number of clusters as the smallest value of <span class="math inline">\(k\)</span> such that the gap statistic is within one standard deviation of the gap at <span class="math inline">\(k+1\)</span>: <span class="math inline">\(\text{Gap}(k) \ge \text{Gap}(k+1) - s_{k+1}\)</span>.</li>
</ol>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>Note that using <span class="math inline">\(B = 500\)</span> gives quite precise results so that the gap plot is basically unchanged after an another run.</p>
</div>
</div>
</section>
<section id="computing-the-number-of-clusters-using-r" class="level4" data-number="10.4.2.4">
<h4 data-number="10.4.2.4" class="anchored" data-anchor-id="computing-the-number-of-clusters-using-r"><span class="header-section-number">10.4.2.4</span> Computing the number of clusters using R</h4>
<p>There are two functions for determing the optimal number of clusters:</p>
<ol type="1">
<li><code>factoextra::fviz_nbclust()</code> function: It can be used to compute the three differet methods for any partitioning clustering methods.</li>
<li><code>NbClust::NbClust()</code> function <span class="citation" data-cites="charrad2014nbclust">(<a href="#ref-charrad2014nbclust" role="doc-biblioref">Charrad et al. 2014</a>)</span>: It provides <span class="math inline">\(30\)</span> indices for determining the relevant number of clusters and proposes to users the best clustering sheme from the different results obtained by varying all combinations of number of clusters, distance measures, and clustering methods. It can simultanously computes all the indices and determine the number of clusters in a single function call.</li>
</ol>
<p>The simplified format is as:</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb28"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="fu">fvix_nbclust</span>(x, FUNcluster, <span class="at">method =</span> <span class="fu">c</span>(<span class="st">'silhouette'</span>, <span class="st">'wss'</span>, <span class="st">'gap_stat'</span>))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<p>where:</p>
<ul>
<li><code>x</code>: numeric matrix or dataframe</li>
<li><code>FUNcluster</code>: a partitioning function. Allowed values include <em>kmeans</em>, <em>pam</em>, and others.</li>
<li><code>method</code>: the method to be used for determing the optimal number of clusters.</li>
</ul>
<p>The R code below determine the optimal number of clusters for <span class="math inline">\(k\)</span>-means clustering:</p>
<div id="qwebr-insertion-location-37"></div>
<noscript>Please enable JavaScript to experience the dynamic code cell content on this page.</noscript>
<div id="qwebr-insertion-location-38"></div>
<noscript>Please enable JavaScript to experience the dynamic code cell content on this page.</noscript>
<div id="qwebr-insertion-location-39"></div>
<noscript>Please enable JavaScript to experience the dynamic code cell content on this page.</noscript>
<p>The results show that:</p>
<ul>
<li><em>Elbow method</em> suggested <span class="math inline">\(4\)</span> clusters</li>
<li><em>Silhouette method</em> suggested <span class="math inline">\(2\)</span> clusters</li>
<li><em>Gap statistic method</em> suggested <span class="math inline">\(4\)</span> clusters</li>
</ul>
<p>According to these observatios, it is possible to define <span class="math inline">\(k = 2\)</span> as the optimal number of clusters in the <code>iris</code> dataset although, we know that the dataset has three clusters but based on the plots of the data, choosing <span class="math inline">\(k=2\)</span> makes sense.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>The disadvantage of elbow and average silhouette methods is that, they measure a global clustering characteristic only. A more sophisticated method is to use the gap statistic which provides a statistical procedure to formalize the elbow/silhouette heuristic in order to estimate the optimal number of clusters.</p>
</div>
</div>
<p>The simplified format of the function <code>NBClust()</code> is</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb29"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="fu">NbClust</span>(<span class="at">data =</span> <span class="cn">NULL</span>, <span class="at">diss =</span> <span class="cn">NULL</span>, <span class="at">distance =</span> <span class="st">'euclidean'</span>, <span class="at">min.nc =</span> <span class="dv">2</span>, <span class="at">max.nc =</span> <span class="dv">15</span>, <span class="at">method =</span> <span class="cn">NULL</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<p>where: - <code>data</code>: matrix - <code>diss</code>: dissimilarity matrix to be used. By default, <code>diss=NULL</code>, but if it is replaced by a dissimilarity matrix, distance should be <code>NULL</code> - <code>distance</code>: the distance measure to be used to compute the dissimilarity matrix. Possible values include <code>"euclidean"</code>, <code>"manhattan"</code> or <code>NULL</code>. - <code>min.nc</code> and <code>max.nc</code>: minimal and maximal number of clusters, respectively. - <code>method</code>: The cluster analysis method to be used including <code>"ward.D"</code>, <code>"ward.D2"</code>, <code>"single"</code>, <code>"complete"</code>, <code>"average"</code>, <code>"kmeans"</code>, and more.</p>
<p>To compute <code>NbClust()</code> for <span class="math inline">\(k\)</span>-means, use <code>method = "kmeans"</code>.</p>
<p>Th R code below computes <code>NbClust()</code> for <span class="math inline">\(k\)</span>-means:</p>
<div id="qwebr-insertion-location-40"></div>
<noscript>Please enable JavaScript to experience the dynamic code cell content on this page.</noscript>
<p>Based on this output, the best number of clusters is <span class="math inline">\(2\)</span>.</p>
</section>
</section>
<section id="cluster-validation-statistics" class="level3" data-number="10.4.3">
<h3 data-number="10.4.3" class="anchored" data-anchor-id="cluster-validation-statistics"><span class="header-section-number">10.4.3</span> Cluster Validation Statistics</h3>
<p>The term <em>cluster validation</em> is used to design the procedure of evaluating the goodness of clustering algorithm results. This is important to avoid finding patterns in a random data, as well as, in the situation where you want to compare two clustering algorithms.</p>
<p>Based on <span class="citation" data-cites="theodoridis2008pattern">Theodoridis and Koutroumbas (<a href="#ref-theodoridis2008pattern" role="doc-biblioref">2008</a>)</span>, <span class="citation" data-cites="brock2008clvalid">Brock et al. (<a href="#ref-brock2008clvalid" role="doc-biblioref">2008</a>)</span>, <span class="citation" data-cites="charrad2014nbclust">Charrad et al. (<a href="#ref-charrad2014nbclust" role="doc-biblioref">2014</a>)</span>; clustering validation statistics can be categorized into <span class="math inline">\(3\)</span> classes:</p>
<ol type="1">
<li><strong>Internal cluster validation</strong>. which uses the internal information of the clustering process to evaluate the goodness of a clustering structure without reference to external information. It can be also used for estimating the number of clusters and the appropriate clustering algorithm without any external data.</li>
<li><strong>External cluster validation</strong>, which consists of comparing the results of a clutser analsis to an externally known result, such as externally provided class labels. It measures the extent to which cluster labels match externally supplied class labels. Since we know the “true” cluster number in advance, this approach is mainly used for selecting the right clustering algorithm for a specific data set.</li>
<li><strong>Relative cluster validation</strong>, which evaluates the clustering structure by varying different parameter values for the same algorithm (e.g.,: varying the number of clusters <span class="math inline">\(k\)</span>). It is generally used for determining the optimal number of clusters.</li>
</ol>
<section id="internal-measures-for-cluster-validation" class="level4" data-number="10.4.3.1">
<h4 data-number="10.4.3.1" class="anchored" data-anchor-id="internal-measures-for-cluster-validation"><span class="header-section-number">10.4.3.1</span> Internal measures for cluster validation</h4>
<p>Recall that the goal of partitioning algoritms is to split the dataset into clusters of observations, such that:</p>
<ul>
<li>the observations in the same cluster are similar as much as possible</li>
<li>the observation in the different clusters are highly distict</li>
</ul>
<p>Thus, the average distance within cluster should be <em>as samll as</em> possible, and the average distance between clusters should be <em>as large as</em> possible.</p>
<p>Internal validation measures reflect often the <strong>compactness</strong>, the <strong>connectedness</strong> and the <strong>separation</strong> of the cluster partitions.</p>
<ol type="1">
<li><strong>Compactness</strong> or <strong>cluster cohesion</strong>: Measures how close are the objects within the same cluster. A lower within-cluster variation is an indicator of a good compactness (i.e., a good clustering). The different indices for evaluating the compactness of clusters are base on distance measures such as the cluster-wise within average/median distances between observations.</li>
<li><strong>Separation</strong>: Measures how well-separated a cluster is from other clusters. The indices used as separation measures include:</li>
</ol>
<ul>
<li>distances between cluster centers</li>
<li>the pairwise minimum distances between objects in different clusters</li>
</ul>
<ol start="3" type="1">
<li><strong>Connectivity</strong>: corresponds to what extent items are placed in the same cluster as their nearest neighbors in the data space. The connectivity has a value between <span class="math inline">\(0\)</span> and <span class="math inline">\(\infty\)</span> and should be minimized.</li>
</ol>
<p>Generally most of the indices used for internal clustering validation combine compactness and speration measures as follow: <span class="math display">\[
\text{Index} = \frac{\alpha \times \text{Separation}}{\beta \times \text{Compactness}}
\]</span> where <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span> are weights.</p>
<p>There are two commonly used indices for assessing the goodness of clustering:</p>
<ul>
<li>the *silhouette width**</li>
<li>the <em>Dunn index</em></li>
</ul>
<p>These internal measure can be used also to determine the <em>optimal number of clusters</em> in the data.</p>
<section id="silhouette-coefficient-1" class="level5" data-number="10.4.3.1.1">
<h5 data-number="10.4.3.1.1" class="anchored" data-anchor-id="silhouette-coefficient-1"><span class="header-section-number">10.4.3.1.1</span> Silhouette coefficient</h5>
<p>The silhouette analysis measures how well an observation is clustered and it estimates the <em>average distance between clusters</em>. The silhouette plot displays a measure of how close each point in one cluster is to points in the neighboring clusters.</p>
<p>For each observation <span class="math inline">\(\mathbf{x}_i\)</span>, the silhouette width <span class="math inline">\(s_i\)</span> is calculated as follows:</p>
<ol type="1">
<li>For each observation <span class="math inline">\(\mathbf{x}_i\)</span>, calculate the average dissimilarity <span class="math inline">\(a_i\)</span> between <span class="math inline">\(\mathbf{x}_i\)</span> and all other points of the cluster to which <span class="math inline">\(\mathbf{x}_i\)</span> belongs.</li>
<li>For all other clusters <span class="math inline">\(C\)</span>, to which <span class="math inline">\(\mathbf{x}_i\)</span> does not belong, calculate the average dissimilarity <span class="math inline">\(d(\mathbf{x}_i,C)\)</span> of <span class="math inline">\(\mathbf{x}_i\)</span> to all observations of <span class="math inline">\(C\)</span>. The smallest of these <span class="math inline">\(d(\mathbf{x}_i,C)\)</span> is defined as <span class="math inline">\(b_i = \min_C d(\mathbf{x}_i,C)\)</span> The value of <span class="math inline">\(b_i\)</span> can be seen as the dissimilarity between <span class="math inline">\(\mathbf{x}_i\)</span> and its “<em>neighbor</em>” cluster, i.e., the nearest one to which it does not belong.</li>
<li>Finally the silhouette width of the observation <span class="math inline">\(\mathbf{x}_i\)</span> is defined by the formula: <span class="math display">\[
S_i = \frac{b_i - a_i}{\max(a_i, b_i)}
\]</span></li>
</ol>
<p>Silhouette width can be interpreted as follow:</p>
<ul>
<li>Observations with a large <span class="math inline">\(S_i\)</span> (almost <span class="math inline">\(1\)</span>) are very well clustered.</li>
<li>A small <span class="math inline">\(S_i\)</span> (around <span class="math inline">\(0\)</span>) means that the observation lies between two clusters.</li>
<li>Observations with a negative <span class="math inline">\(S_i\)</span> are probably placed in the wrong cluster.</li>
</ul>


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-Bezdek2002" class="csl-entry" role="listitem">
Bezdek, J. C., and R. J. Hathaway. 2002. <span>“VAT: A Tool for Visual Assessment of (Cluster) Tendency.”</span> In <em>Proceedings of the 2002 International Joint Conference on Neural Networks. IJCNN’02 (Cat. No.02CH37290)</em>, 3:2225–30.
</div>
<div id="ref-brock2008clvalid" class="csl-entry" role="listitem">
Brock, Guy, Vasyl Pihur, Susmita Datta, and Somnath Datta. 2008. <span>“clValid: An r Package for Cluster Validation.”</span> <em>Journal of Statistical Software</em> 25 (4): 1–22. <a href="https://doi.org/10.18637/jss.v025.i04">https://doi.org/10.18637/jss.v025.i04</a>.
</div>
<div id="ref-charrad2014nbclust" class="csl-entry" role="listitem">
Charrad, Malika, Nadia Ghazzali, Véronique Boiteau, and Azam Niknafs. 2014. <span>“NbClust: An r Package for Determining the Relevant Number of Clusters in a Data Set.”</span> <em>Journal of Statistical Software</em> 61 (6): 1–36. <a href="https://doi.org/10.18637/jss.v061.i06">https://doi.org/10.18637/jss.v061.i06</a>.
</div>
<div id="ref-Gower1971" class="csl-entry" role="listitem">
Gower, J. C. 1971. <span>“A General Coefficient of Similarity and Some of Its Properties.”</span> <em>Biometrics</em> 27 (4): 857–71.
</div>
<div id="ref-hartigan1979" class="csl-entry" role="listitem">
Hartigan, John A., and Manchek A. Wong. 1979. <span>“A <span>K</span>-Means Clustering Algorithm.”</span> <em>Applied Statistics</em> 28: 100–108.
</div>
<div id="ref-kaufman1990" class="csl-entry" role="listitem">
Kaufman, Leonard, and Peter J. Rousseeuw. 1990. <em>Finding Groups in Data: An Introduction to Cluster Analysis</em>. New York: Wiley.
</div>
<div id="ref-macqueen1967" class="csl-entry" role="listitem">
MacQueen, J. 1967. <span>“Some Methods for Classification and Analysis of Multivariate Observations.”</span> In <em>Proceedings of the Fifth Berkeley Symposium on Mathematical Statistics and Probability</em>, edited by L. M. Le Cam and J. Neyman, 1:281–97. Berkeley, CA: University of California Press.
</div>
<div id="ref-theodoridis2008pattern" class="csl-entry" role="listitem">
Theodoridis, Sergios, and Konstantinos Koutroumbas. 2008. <em>Pattern Recognition</em>. 4th ed. Amsterdam, Netherlands: Academic Press.
</div>
<div id="ref-tibshirani2001gap" class="csl-entry" role="listitem">
Tibshirani, Robert, Guenther Walther, and Trevor Hastie. 2001. <span>“Estimating the Number of Data Clusters via the Gap Statistic.”</span> <em>Journal of the Royal Statistical Society: Series B (Statistical Methodology)</em> 63 (2): 411–23.
</div>
</div>
</section>
</section>
</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../chapters/Decision_trees.html" class="pagination-link" aria-label="Decision Trees">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Decision Trees</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../chapters/chapter5_logistic_regression.html" class="pagination-link" aria-label="Logistic Regression">
        <span class="nav-page-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Logistic Regression</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<script type="module">
// Handle cell initialization initialization
qwebrCellDetails.map(
  (entry) => {
    // Handle the creation of the element
    qwebrCreateHTMLElement(entry);
    // In the event of interactive, initialize the monaco editor
    if (entry.options.context == EvalTypes.Interactive) {
      qwebrCreateMonacoEditorInstance(entry);
    }
  }
);

// Identify non-interactive cells (in order)
const filteredEntries = qwebrCellDetails.filter(entry => {
  const contextOption = entry.options && entry.options.context;
  return ['output', 'setup'].includes(contextOption) || (contextOption == "interactive" && entry.options && entry.options.autorun === 'true');
});

// Condition non-interactive cells to only be run after webR finishes its initialization.
qwebrInstance.then(
  async () => {
    const nHiddenCells = filteredEntries.length;
    var currentHiddenCell = 0;


    // Modify button state
    qwebrSetInteractiveButtonState(`🟡 Running hidden code cells ...`, false);

    // Begin processing non-interactive sections
    // Due to the iteration policy, we must use a for() loop.
    // Otherwise, we would need to switch to using reduce with an empty
    // starting promise
    for (const entry of filteredEntries) {

      // Determine cell being examined
      currentHiddenCell = currentHiddenCell + 1;
      const formattedMessage = `Evaluating hidden cell ${currentHiddenCell} out of ${nHiddenCells}`;

      // Update the document status header
      if (qwebrShowStartupMessage) {
        qwebrUpdateStatusHeader(formattedMessage);
      }

      // Display the update in non-active areas
      qwebrUpdateStatusMessage(formattedMessage);

      // Extract details on the active cell
      const evalType = entry.options.context;
      const cellCode = entry.code;
      const qwebrCounter = entry.id;

      if (['output', 'setup'].includes(evalType)) {
        // Disable further global status updates
        const activeContainer = document.getElementById(`qwebr-non-interactive-loading-container-${qwebrCounter}`);
        activeContainer.classList.remove('qwebr-cell-needs-evaluation');
        activeContainer.classList.add('qwebr-cell-evaluated');

        // Update status on the code cell
        const activeStatus = document.getElementById(`qwebr-status-text-${qwebrCounter}`);
        activeStatus.innerText = " Evaluating hidden code cell...";
        activeStatus.classList.remove('qwebr-cell-needs-evaluation');
        activeStatus.classList.add('qwebr-cell-evaluated');
      }

      switch (evalType) {
        case 'interactive':
          // TODO: Make this more standardized.
          // At the moment, we're overriding the interactive status update by pretending its
          // output-like. 
          const tempOptions = entry.options;
          tempOptions["context"] = "output"
          // Run the code in a non-interactive state that is geared to displaying output
          await qwebrExecuteCode(`${cellCode}`, qwebrCounter, tempOptions);
          break;
        case 'output':
          // Run the code in a non-interactive state that is geared to displaying output
          await qwebrExecuteCode(`${cellCode}`, qwebrCounter, entry.options);
          break;
        case 'setup':
          const activeDiv = document.getElementById(`qwebr-noninteractive-setup-area-${qwebrCounter}`);

          // Store code in history
          qwebrLogCodeToHistory(cellCode, entry.options);

          // Run the code in a non-interactive state with all output thrown away
          await mainWebR.evalRVoid(`${cellCode}`);
          break;
        default: 
          break; 
      }

      if (['output', 'setup'].includes(evalType)) {
        // Disable further global status updates
        const activeContainer = document.getElementById(`qwebr-non-interactive-loading-container-${qwebrCounter}`);
        // Disable visibility
        activeContainer.style.visibility = 'hidden';
        activeContainer.style.display = 'none';
      }
    }
  }
).then(
  () => {
    // Release document status as ready

    if (qwebrShowStartupMessage) {
      qwebrStartupMessage.innerText = "🟢 Ready!"
    }
  
    qwebrSetInteractiveButtonState(
      `<i class="fa-solid fa-play qwebr-icon-run-code"></i> <span>Run Code</span>`, 
      true
    );  
  }
);
</script>




</body></html>