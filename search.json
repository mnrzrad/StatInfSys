[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Statistics and Information Systems",
    "section": "",
    "text": "Prerequisites\nThis is a Quarto book.\nTo learn more about Quarto books visit https://quarto.org/docs/books.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.",
    "crumbs": [
      "Prerequisites"
    ]
  },
  {
    "objectID": "chapters/chapter1_data_ethics.html",
    "href": "chapters/chapter1_data_ethics.html",
    "title": "1  Data Ethics",
    "section": "",
    "text": "1.1 What is the Ethics of Data Science?\nThe ethics of data science are very important, and all data analyst, data scientists, and everyone who works with data should know the principles of ethics.\nAll individuals handling data are obligated to report any occurrences such as data theft, improper storage, unethical data collection, or data misuse.\nFor example, a business might track and store information about a customer’s path, starting from the moment they enter their email address on the website until they purchase products. In such cases, it is essential that the individual’s report remains confidential and is safeguarded it from unauthorized access.\nThe study and evaluation of ethical issues related to data have led to the emergence of a new domain in ethics, known as “data science ethics.” Data can be collected, recorded, generated, processed, shared, and used. This field also covers various data and technologies, including programming, professional code, and algorithms.\nIn the past, ethical principles in computer and information science primarily focused on the content and information present within computer systems. However, with the advancement of technology and the increasing volume of data, the scope of data science ethics has expanded to include concepts and principles related to data collection, use, processing, and sharing.\nWhen companies collect data from individuals, ethical issues related to privacy, personal information, and data misuse arise. However, when companies begin to use these data for purposes not initially specified, even more ethical concerns emerge. In other words, companies try to monetize the collected data, using it in ways that were not previously disclosed. This practice further challenges privacy, trust, and ethics in data collection and use.\nAlthough “ethics” seems complicated, it is really about understanding what is right or wrong. There are different ways people think about ethics, especially when it comes to data world.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Data Ethics</span>"
    ]
  },
  {
    "objectID": "chapters/chapter1_data_ethics.html#what-is-the-ethics-of-data-science",
    "href": "chapters/chapter1_data_ethics.html#what-is-the-ethics-of-data-science",
    "title": "1  Data Ethics",
    "section": "",
    "text": "Important\n\n\n\nData Ethics covers the moral and ethical obligations related to the collection, sharing, and use of data, focusing on ensuring its fair and beneficial applications. It is mainly focused on any negative impacts that data might have on individuals, groups or wider society.\n\n\n\n1.1.1 Principles of Data Ethics for Business Professionals\nIn an era where data is considered the new oil, understanding the ethical issues related to its collection, analysis, and use is of most important. Below, we will introduce the five key ethical principles that every data professional should be aware of.\n\nOwnership: The first principle of data ethics is that every individual has the right to ownership over their personal information. Just as it is considered theft to take an object without its owner’s permission, collecting someone’s personal information without their consent is both illegal and unethical. Some common methods for obtaining consent include signed written agreements, digital privacy policies that require users to agree to a company’s terms and conditions, and pop-up windows with check-boxes that allow websites to track users’ online behavior with cookies. *Never assume customers agree to their information being collected; always seek their permission to avoid ethical and legal problems.\nTransparency: In addition to ownership, individuals whose data you collect have the right to know how you plan to gather, store, and use their personal information. When collecting data, prioritize transparency and provide them with all necessary information.\nFor example, imagine your company decides to implement an algorithm to personalize the website experience based on user shopping habits and behavior. You should develop a policy explaining that cookies will track user behavior, the collected data will be stored in a secure database, and an algorithm will be trained to personalize the website experience.\nUsers have the right to access this information so they can decide whether to accept or reject your website’s cookies. Hiding or lying about your company’s methods and goals is deceptive, illegal, and unfair to the individuals whose data you handle.\nPrivacy: One of the ethical responsibilities associated with handling data is preserving the privacy of individuals whose data is involved. Even if a customer has given your company permission to collect, store, and analyze their Personally Identifiable Information (PII), it does not mean they want this information to be publicly accessible.\nPII is any data that relates to an individual’s identity. This typically includes items such as full name, address, phone number, date of birth, credit card number, bank account number, social security number, passport number, and other information that can be used to identify a person.\nTo protect individuals’ privacy, ensure you store data in a secure database to prevent it from falling into the wrong hands. Data security methods that help maintain privacy include file encryption (transforming information into a readable format only with an encryption key) and dual-authentication (password protection with two-factor authentication).\nOne way to prevent errors is to de-identify the dataset. When all PII is removed, only anonymous data remains, and the dataset can no longer be traced back to individuals. This allows analysis to identify relationships between variables of interest without linking data points to personal identities.\nIntention : Before you even begin collecting data, it is crucial to consider why you need this data and what purpose you aim to achieve with it. If your intention is to engage in unethical activities, such as harassing others or improperly exploiting individuals’ vulnerabilities, then collecting their data is not ethical. Ethical data collection requires a legitimate purpose and operating in accordance with regulations and ethical principles.\nEven when your intention is good - for instance, collecting data to understand health experience in order to create an app that addresses urgent needs – you still need to evaluate your purpose for collecting every piece of data.\nOutcomes : Even if your intention and purpose in collecting and analyzing data are good, the outcome of this process might unintentionally cause harm to individuals or groups. This type of harm is known as disparate impact and is considered invalid under civil rights laws, meaning it is illegal.\nUnfortunately, you cannot definitively predict the exact impact of data analysis until it is complete. However, by considering this question and its importance before conducting the analysis, you can identify any potential disparate impacts that might occur. By being aware if the possibility of disparate impact, you can then take the necessary steps to prevent and mitigate it.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Data Ethics</span>"
    ]
  },
  {
    "objectID": "chapters/chapter1_data_ethics.html#why-is-ethics-important-in-the-age-of-data-abundance",
    "href": "chapters/chapter1_data_ethics.html#why-is-ethics-important-in-the-age-of-data-abundance",
    "title": "1  Data Ethics",
    "section": "1.2 Why is Ethics Important in the Age of Data Abundance?",
    "text": "1.2 Why is Ethics Important in the Age of Data Abundance?\nUsing information ethically within decision-making has always been important. However, two factors have made data ethics business-critical:\n\nData Volumes : There has been an explosion in the amount of data available to organizations, both collected themselves, ans sourced from third-parties. It is not always clear where this information has come from, particularly in the case of personal information, and what permissions have been provided for its reuse.\nArtificial Intelligence : Organizations are increasing using machine learning and artificial intelligence algorithms to make sense of data and take automated decisions based on data analysis without involving human oversights. This can lead to issues around fairness and discrimination, even if these are unintended consequences of how data is used.\n\nThe importance of ethics in data science stems from the necessity of having a clear set of rules and guidelines that determine what businesses can and cannot do with the personal information they collect from their customers. This is crucial for safeguarding customer privacy and rights, and appropriate laws and standards must be established to protect personal information.\nAll experts agree that certain fundamental principles must be implemented, even if this field still contains gray areas and nothing is simple or uniform. These are just a few important topics and strategic ideas that have currently garnered the most attention. However, there is still much ground to cover in data ethics, and further progress and development are needed in this area.\n\n\n\n\n\n\n Exercise 1\n\n\n\nIdentify the data ethics principle related to each question:\n\nIs it clear what data is being used for, how and where it is being stored, and is this information freely available to all?\nAre you collecting only data that is necessary and relevant to your clearly defined goals?\nHave you anticipated any potential harmful, negative, or biased impacts that could result from your use of the data?\nIs any personal or identifiable data being securely stored and anonymized to prevent unauthorized access?\nHave you obtained informed consent from individuals for how their data will be used in your project?\n\n\n\n\n\n\n\n Answers\n\n\n\n\n\n\nTransparency\nIntention\nOutcomes\nPrivacy\nOwnership\n\n\n\n\n\n\n\n\n\n\n\n\n Exercise 2\n\n\n\nIdentify the data ethics principle related to each question:\n\nA company collects location data from users’ mobile phones but does not disclose that this information will be shared with advertisers.\nAn analyst stores survey responses on an unsecured shared drive, and the file includes names and phone numbers of participants.\nA data science team begins using a health dataset for a study unrelated to the one participants originally agreed to take part in.\nBefore collecting any data, a team carefully evaluates whether the data they plan to gather is essential to their project goals and excludes anything not directly needed.\nBefore launching a new app feature based on user behavior data, a team conducts a risk assessment to explore how it might negatively affect vulnerable users.\n\n\n\n\n\n\n\n Answers\n\n\n\n\n\n\nTransparency\nPrivacy\nOwnership\nIntention\nOutcomes",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Data Ethics</span>"
    ]
  },
  {
    "objectID": "chapters/chapter3_dplyr.html",
    "href": "chapters/chapter3_dplyr.html",
    "title": "2  Getting Started with dplyr",
    "section": "",
    "text": "2.1 Filter observations - filter()\nThe dplyr package is a part of the R tidyverse : an ecosystem of several libraries designed to work together by representing data in common formats.\nThe data frame is a key data structure in statistics and in R. The basic structure of a data frame is that there is one observation per ro and each column represents a variable, a measure, feature, or characteristic of that observation. Given the importance of managing data frames, it is important that we have good tools for dealing with them.\nThe dplyr package is a relatively new R package that allows you to do all kinds of analyses quickly and easily.\nOne important contribution of the dplyr package is that it provides a “grammar” (in particular, verbs) for data manipulating and for operating on data frames. With this grammar, you can sensibly communicate what it is that you are doing to a data frame that other people can understand (assuming they also know the grammar). This is useful because it provides an abstraction for data manipulation that previously did not exist.\nSome of the key “verbs” provided by the dplyr package are\nTo install the dplyr package from CRAN, just run\nAfter installing the package, it is important to load it into the R session.\nTo better understanding, let us continue within analyzing a dataset, penguins, available within the palmerpenguins package. we need to load the dataset and if it is necessary, we need to install the package.\n‌The data frame contain data for \\(344\\) penguins and \\(8\\) variables describing the species (species), the island (island), some measurements of the size of the bill (bill_length_mm and bill_depth_mm), flipper (flipper_length_mm) and body mass (body_mass_g), the sex (sex) and the study year (year). More information about the data frame can be found by running ?penguins .\nYou can see some basic characteristics of the dataset with the dim() and str() functions.\nThe first and last 6 rows can be displayed by head() and tail(), respectively.\nThe summary information of data frame can be found by summary() .\nThis function works on both quantitative and qualitative variables.\nYou can combine multiple conditions using & if all conditions must be true (cumulative), or | if at least one condition must be true (alternative). For example,\nAs you can see, the filter() functions require the name of the data frames as the first argument, then the condition (with the usual logical operators &gt;, &lt;, &gt;=, &lt;=, ==, !=, %in%, etc.) as second argument.\nSo with the pipe operator, the code above becomes:\nInstead of listing the data frame’s name as the initial argument within functions like filter() (or other {dplyr} functions), you simply specify the data frame once, then use the pipe operator to connect it to the desired function.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Getting Started with `dplyr`</span>"
    ]
  },
  {
    "objectID": "chapters/chapter3_dplyr.html#filter-observations---filter",
    "href": "chapters/chapter3_dplyr.html#filter-observations---filter",
    "title": "2  Getting Started with dplyr",
    "section": "",
    "text": "Please enable JavaScript to experience the dynamic code cell content on this page.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\n\nNote\n\n\n\nVariable names should be used directly, without enclosing them in single or double quotation marks (' or \").\n\n\n\n\n\n\n\n\n\nCaution\n\n\n\nTo use any functions in the dplyr package, you must specify the data frame’s name as the first argument. Alternatively, you can use the pipe operator (|&gt; or %&gt;% ) to avoid explicitly naming the data frame within each function.\n\n\n\n\n\n\n\n\nTip\n\n\n\nThe keyboard shortcut for the pipe operator is ctrl+shift+M on Windows or cmd + shift + M on Mac. By default, this will produce %&gt;%, but if you have configured RStudio to use the native pipe operator, it will print |&gt; .\n\n\n\n\n\n\nNote\n\n\n\nthe %&gt;% pipe, originating from the magrittr package (included in the tidyverse), was superseded in R 4.1.0 (released in 2021) by the native |&gt; pipe. We recommend |&gt; because it’s a simpler, built-in feature of base R, always available without needing additional package loads.\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nThe pipe operator lets you chain multiple operations together, which is especially handy for performing several calculations on a data frame without saving the result of each intermediate step.\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\n\nNote\n\n\n\nThe pipe operator streamlines your code by feeding the output of one operation directly into the next, making your code much easier to write and read.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Getting Started with `dplyr`</span>"
    ]
  },
  {
    "objectID": "chapters/chapter3_dplyr.html#extract-observations",
    "href": "chapters/chapter3_dplyr.html#extract-observations",
    "title": "2  Getting Started with dplyr",
    "section": "2.2 Extract observations",
    "text": "2.2 Extract observations\nYou can extract observations from a dataset based on either their positions or their values.\n\n2.2.1 Based on Their Positions\nTo extract observations based on their positions, you can use the slice() function.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nFurthermore, for extracting specific rows like the first or last, you can use specialized functions:\n\nslice_head(): Extracts rows from the beginning of the dataset.\nslice_tail(): Extracts rows from the end of the dataset.\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n2.2.2 Based on their values\nWhen you need to extract observations based on the values of a variable, you can use:\n\nslice_min(): Selects rows with the lowest values, allowing you to define a specific proportion.\nslice_max(): Selects rows with the highest values, also with the option to define a proportion.\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Getting Started with `dplyr`</span>"
    ]
  },
  {
    "objectID": "chapters/chapter3_dplyr.html#sample-observations",
    "href": "chapters/chapter3_dplyr.html#sample-observations",
    "title": "2  Getting Started with dplyr",
    "section": "2.3 Sample Observations",
    "text": "2.3 Sample Observations\nSampling observations can be achieved in two ways:\n\nsample_n(): Takes a random sample of a specified number of rows.\nsample_frac(): Takes a random sample of a specified fraction of rows.\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\n\nNote\n\n\n\nIt is important to note that, similar to the base R sample() function, the size argument can exceed the total number of rows in your data frame. If this happens, some rows will be duplicated, and you will need to explicitly set the argument replace = TRUE.\n\n\nAlternatively, you can obtain a random sample (either a specific number or a fraction of rows) using slice_sample(). For this, you use:\n\nThe argument n to select a specific number of rows.\nThe argument prop to select a fraction of rows.\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Getting Started with `dplyr`</span>"
    ]
  },
  {
    "objectID": "chapters/chapter3_dplyr.html#sort-observations",
    "href": "chapters/chapter3_dplyr.html#sort-observations",
    "title": "2  Getting Started with dplyr",
    "section": "2.4 Sort observations",
    "text": "2.4 Sort observations\nObservations can be sorted using the arrange() function.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nBy default, arrange() sorts in ascending order. To sort in descending order, simply use desc() within the arrange() function, like arrange(desc(variable_name)).\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nSimilar to filter(), arrange() can sort by multiple variables and works with both quantitative (numerical) and qualitative (categorical) variables. For example, arrange(sex, body_mass) would first sort by sex (alphabetical order) and then by body_mass (ascending, from lowest to highest).\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\n\nImportant\n\n\n\nIt is important to note that if a qualitative variable is defined as an ordered factor, the sorting will follow its defined level order, not alphabetical order.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Getting Started with `dplyr`</span>"
    ]
  },
  {
    "objectID": "chapters/chapter3_dplyr.html#select-variables",
    "href": "chapters/chapter3_dplyr.html#select-variables",
    "title": "2  Getting Started with dplyr",
    "section": "2.5 Select variables",
    "text": "2.5 Select variables\nYou can select variables using the select() function based on their position or name.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nTo remove variables, use a - sign before their position or name.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nYou can also select a sequence of variables by name (e.g., select(df, var1:var5)).\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nFurthermore, select() provides a straightforward way to rearrange column order in your data frame.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Getting Started with `dplyr`</span>"
    ]
  },
  {
    "objectID": "chapters/chapter3_dplyr.html#renaming-variables",
    "href": "chapters/chapter3_dplyr.html#renaming-variables",
    "title": "2  Getting Started with dplyr",
    "section": "2.6 Renaming Variables",
    "text": "2.6 Renaming Variables\nTo rename variables, use the rename() function.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nRemember the syntax: new_name = old_name. This means you always write the desired new name first, followed by an equals sign, and then the current old name of the variable.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Getting Started with `dplyr`</span>"
    ]
  },
  {
    "objectID": "chapters/chapter3_dplyr.html#create-or-modify-variables",
    "href": "chapters/chapter3_dplyr.html#create-or-modify-variables",
    "title": "2  Getting Started with dplyr",
    "section": "2.7 Create or Modify Variables",
    "text": "2.7 Create or Modify Variables\nThe mutate() function allows you to create new variables or modify existing ones. You can base these operations on another existing variable or a vector of your choice.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\n\nNote\n\n\n\nIf you create a variable with a name that already exists, the old variable will be overwritten.\n\n\nSimilar to rename(), mutate() requires the argument to be in the format name = expression, where name is the column being created or modified, and expression is the formula for its values.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Getting Started with `dplyr`</span>"
    ]
  },
  {
    "objectID": "chapters/chapter3_dplyr.html#summarize-observations",
    "href": "chapters/chapter3_dplyr.html#summarize-observations",
    "title": "2  Getting Started with dplyr",
    "section": "2.8 Summarize Observations",
    "text": "2.8 Summarize Observations\nTo get descriptive statistics of your data, use the summarize() (or summarise()) function in conjunction with statistical functions like mean(), median(), min(), max(), sd(), var(), etc.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nRemember to use na.rm = TRUE to exclude missing values from calculations.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Getting Started with `dplyr`</span>"
    ]
  },
  {
    "objectID": "chapters/chapter3_dplyr.html#identify-distinct-values",
    "href": "chapters/chapter3_dplyr.html#identify-distinct-values",
    "title": "2  Getting Started with dplyr",
    "section": "2.9 Identify Distinct Values",
    "text": "2.9 Identify Distinct Values\nThe distinct() function helps you find unique values within a variable.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nWhile typically used for qualitative or quantitative discrete variables, it works for any variable type and can identify unique combinations of values when multiple variables are specified. For instance, distinct(species, study_year) would return all unique combinations of species and study year.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Getting Started with `dplyr`</span>"
    ]
  },
  {
    "objectID": "chapters/chapter3_dplyr.html#group-by",
    "href": "chapters/chapter3_dplyr.html#group-by",
    "title": "2  Getting Started with dplyr",
    "section": "2.10 Group By",
    "text": "2.10 Group By\nThe group_by() function changes how subsequent operations are performed. Instead of applying functions to the entire data frame, operations will be applied to each defined group of rows. This is particularly useful with summarize(), as it will produce statistics for each group rather than for all observations.\nFor example, to calculate the mean and standard deviation of body_mass separately for each species, you would first group_by(species) and then summarize() the body_mass. The pipe operator smoothly passes the grouped data from group_by() to summarize().\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nYou can also group by multiple variables (e.g., group_by(var1, var2)), and the data frame’s name only needs to be specified in the very first operation of a chained sequence.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Getting Started with `dplyr`</span>"
    ]
  },
  {
    "objectID": "chapters/chapter3_dplyr.html#number-of-observations",
    "href": "chapters/chapter3_dplyr.html#number-of-observations",
    "title": "2  Getting Started with dplyr",
    "section": "2.11 Number of Observations",
    "text": "2.11 Number of Observations\nThe function n() returns the number of observations. It can only be used inside summarize().\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nWhen combined with group_by(), you can easily get the number of observations per group. n() takes no parameters, so it’s always written as n().\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nNotably, the count() function is a convenient shortcut, equivalent to summarize(n = n()).\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Getting Started with `dplyr`</span>"
    ]
  },
  {
    "objectID": "chapters/chapter3_dplyr.html#number-of-distinct-values",
    "href": "chapters/chapter3_dplyr.html#number-of-distinct-values",
    "title": "2  Getting Started with dplyr",
    "section": "2.12 Number of Distinct Values",
    "text": "2.12 Number of Distinct Values\nTo count the number of unique values or levels in a variable (or combination of variables), use n_distinct(). Like n(), it’s exclusively used within summarize().\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nYou do not have to explicitly name the output; the operation’s name will be used by default (e.g., summarize(n_distinct(variable))).\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Getting Started with `dplyr`</span>"
    ]
  },
  {
    "objectID": "chapters/chapter3_dplyr.html#first-last-or-nth-value",
    "href": "chapters/chapter3_dplyr.html#first-last-or-nth-value",
    "title": "2  Getting Started with dplyr",
    "section": "2.13 First, Last, or \\(n\\)th Value",
    "text": "2.13 First, Last, or \\(n\\)th Value\nAlso available only within summarize(), you can retrieve the first, last, or nth value of a variable. Functions like first(), last(), and nth() enable this.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nThese functions offer arguments to handle missing values; for more details, consult their documentation (e.g., ?nth()).",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Getting Started with `dplyr`</span>"
    ]
  },
  {
    "objectID": "chapters/chapter3_dplyr.html#conditional-transformations",
    "href": "chapters/chapter3_dplyr.html#conditional-transformations",
    "title": "2  Getting Started with dplyr",
    "section": "2.14 Conditional Transformations",
    "text": "2.14 Conditional Transformations\n\n2.14.1 If Else\nThe if_else() function (used with mutate()) is ideal for creating a new variable with two levels based on a condition. It takes three arguments:\n\nThe condition (e.g., body_mass_g &gt;= 4000).\nThe output value if the condition is TRUE (e.g., “High”).\nThe output value if the condition is FALSE (e.g., “Low”).\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\n\nTip\n\n\n\nA key advantage is that if_else() propagates missing values (NA) if the condition’s input is missing, preventing misclassification.\n\n\n\n\n2.14.2 Case When\nFor categorizing a variable into more than two levels, case_when() is far more appropriate and readable than nested if_else() statements.\nWhile nested if_else() functions can technically work, they are prone to errors and result in difficult-to-read code. For instance, to classify body mass into “Low” (&lt;3500), “High” (&gt;4750), and “Medium” (otherwise), nested if_else() would look like this:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nThis code first checks if body_mass_g is less than 3500. If true, it assigns “Low”. If false, it then checks if body_mass_g is greater than 4750. If that’s true, it assigns “High”; otherwise, it assigns “Medium”. While functional, this structure can become complex and error-prone with more conditions.\ncase_when() evaluates conditions sequentially. To improve this workflow, we now use the case when technique:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nThis workflow is much simpler to code and read!\nIf there are no missing values in the variable(s) used for the condition(s), it can even be simplified to:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nWhile a .default argument can be used to specify an output for observations not matching any condition, exercise caution with missing values. If NA values in the conditioning variable are not explicitly handled, they might be incorrectly assigned to the default category. A safer approach is to explicitly define all categories or ensure NAs remain NA.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\n\nNote\n\n\n\nRegardless of whether you use if_else() or case_when(), it’s always good practice to verify the newly created variable to ensure it aligns with your intended results.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Getting Started with `dplyr`</span>"
    ]
  },
  {
    "objectID": "chapters/chapter3_dplyr.html#exploring-further-dplyr-functions",
    "href": "chapters/chapter3_dplyr.html#exploring-further-dplyr-functions",
    "title": "2  Getting Started with dplyr",
    "section": "2.15 Exploring Further dplyr Functions",
    "text": "2.15 Exploring Further dplyr Functions\nUntil now, we have focused on analyzing the penguins dataset. To effectively explain some of dplyr’s other powerful functions, we’ll now shift to creating custom datasets tailored to demonstrate their specific functionalities.\n\n2.15.1 Separate and Unite\nYou can separate a character column into two or more new columns using separate().\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nConversely, to combine two or more columns into a single character column, use unite().\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n2.15.2 Reshaping Data: gather() and spread()\ngather() transforms “wide” format data into “long” or “tall” format by collapsing columns into key-value pairs.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nConversely, spread() converts “long” or “tall” format data into “wide” format by separating key-value pairs across multiple columns.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Getting Started with `dplyr`</span>"
    ]
  },
  {
    "objectID": "chapters/chapter3_dplyr.html#managing-groups-ungroup",
    "href": "chapters/chapter3_dplyr.html#managing-groups-ungroup",
    "title": "2  Getting Started with dplyr",
    "section": "2.16 Managing Groups: ungroup()",
    "text": "2.16 Managing Groups: ungroup()\nAfter performing operations on grouped data, the ungroup() function allows you to revert to a normal data frame, enabling operations on entire columns again or switching to new grouping criteria. Remember, you can also group_by() multiple columns simultaneously.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Getting Started with `dplyr`</span>"
    ]
  },
  {
    "objectID": "chapters/chapter3_dplyr.html#combining-datasets-joins",
    "href": "chapters/chapter3_dplyr.html#combining-datasets-joins",
    "title": "2  Getting Started with dplyr",
    "section": "2.17 Combining Datasets: Joins",
    "text": "2.17 Combining Datasets: Joins\nWhen working with data spread across multiple tables, you’ll often need to combine them based on a shared column (a “key column”)—a process known as joining or merging. dplyr provides several functions for common data joins.\nIf your datasets have identical columns but different records that you wish to concatenate (add rows), use rbind() (base R) or bind_rows() (dplyr). Similarly, to append new columns (add columns), use cbind() (base R) or bind_cols() (dplyr).\n\nExerciseHintsSolution\n\n\nUsing the starwars dataset and dplyr functions, perform the following data manipulations.\n\n2.17.1 Part 1: Initial Exploration and Filtering\n\nFilter for Human Characters: Create a new data frame called human_characters that only includes characters of the “Human” species.\nSelect Key Attributes: From human_characters, select only the name, height, mass, and homeworld columns.\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n2.17.2 Part 2: Calculating BMI and Identifying Extremes\n\nCalculate BMI: Add a new variable called bmi (Body Mass Index) to your human_characters data frame. The formula for BMI is \\(\\text{mass}/(\\text{height}/100)^2\\). Ensure that mass is in kilograms and height in centimeters as provided in the dataset.\nSort by BMI: Arrange the human_characters data frame in descending order based on their bmi.\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n2.17.3 Part 3: Grouped Summaries\n\nSpecies Statistics: Calculate the number of characters (n) and the average height for each species in the original starwars dataset.\nFilter Significant Species: From the previous summary, filter out species that have fewer than 5 characters and an average height greater than 100.\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n2.17.4 Part 4: Conditional Categorization\n\nCategorize Height: Add a new variable called height_category to the starwars dataset using mutate() and case_when().\n\nIf height is less than or equal to 100, categorize as “Short”.\nIf height is greater than 100 but less than or equal to 180, categorize as “Medium”.\nIf height is greater than 180, categorize as “Tall”.\nHandle NA values for height appropriately so they remain NA in height_category.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\nPart 1: Initial Exploration and Filtering\n\nFilter for Human Characters: which dplyr function helps you select rows based on a condition? Remember the syntax for checking equality.\nThere is a dplyr function specifially for choosing columns.\n\nPart 2: Calculating BMI and Identifying Extremes\n\nCalculate BMI: Which dplyr function is used to create or modify columns? Pay attention to the order of operations in the formula.\nSort by BMI: The arrange() function is key here. How do you specify descending order?\n\n\n2.17.5 Part 3: Grouped Summaries\n\nSpecies Statistics: You will need two main functions here: one to define groups and another to calculate summary statistics within those groups. Do not forget to handle NA values for the mean.\nFilter Significant Species: You will apply another filter() operation, but this time on the summarized data. Remember how to combine two conditions.\n\n\n\n2.17.6 Part 4: Conditional Categorization\n\nCategorize Height: case_when() is perfect for multiple conditions. How do you specify the conditions and their corresponding outputs? Remember to check for NAs first to ensure they do not get misclassified by other conditions.\n\n\n\n\n\n\nSolution. \nlibrary(dplyr)\n\n# Part 1: Initial Exploration and Filtering\nhuman_characters &lt;- starwars |&gt; \n  filter(species == \"Human\") |&gt; \n  select(name, height, mass, homeworld)\n\n# Part 2: Calculating BMI and Identifying Extremes\nhuman_characters_bmi &lt;- human_characters  |&gt; \n  mutate(bmi = mass / ((height / 100)^2))  |&gt; \n  arrange(desc(bmi))\n\n# Part 3: Grouped Summaries\nspecies_stats &lt;- starwars  |&gt; \n  group_by(species) %&gt;%\n  summarise(\n    n = n(),\n    avg_height = mean(height, na.rm = TRUE)\n  ) %&gt;%\n  filter(\n    n &gt;= 5, \n    avg_height &gt; 100\n  )\n\n# Part 4: Conditional Categorization\nstarwars_with_height_category &lt;- starwars %&gt;%\n  mutate(\n    height_category = case_when(\n      is.na(height) ~ NA_character_, # Handle NA values first\n      height &lt;= 100 ~ \"Short\",\n      height &gt; 100 & height &lt;= 180 ~ \"Medium\",\n      height &gt; 180 ~ \"Tall\"\n    )\n  )\n\n\n\n\nTo learn more about the dplyr package, here are some recommended resources:\n\ndplyr.tidyverse.org\nChapter “Data transformation” in the book “R for Data Science”\nCheatsheet\nBlog Stats and R\nKaggele",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Getting Started with `dplyr`</span>"
    ]
  },
  {
    "objectID": "chapters/chapter2_data_visualization.html",
    "href": "chapters/chapter2_data_visualization.html",
    "title": "3  Data Visualization",
    "section": "",
    "text": "3.1 Data\nThe most famous package in R that is used for visualizing of data is ggplot2 that is based on the grammar of graphics. It allows you to `speak’ a graph from composable elements, instead of being limited to a predefined set of charts.\nBefore using ggplot2, a user must first install the package and then load it into their R session. Installation is done only using the command install.packages('ggplot2'). Alternatively, the following code can be used to install if only if the package is not already installed on the computer.\nwhich downloads the package from CRAN (the Comprehensive R Archive Network). After installation, the package needs to be loaded each time R is restarted. This is done with the following command:\nA brief overview about using this package is available at this website and more complete information about how to use ggplot2 can be found in Wickham, Navarro, and Pederson (2019).\nThe structure of the package includes 7 composable parts that come together as a set of instructions on how to draw a chart.\nThe package ggplot2 requires a minimum of three main components to create a chart: data, mapping, and a layer. Other components – like scales, facets, coordinates, and themes – are optional because ggplot2 gives them automatic settings that usually work well, so you do not need to adjust them too much.\nIn the following, we briefly describe these components:\nEvery plot made with ggplot2 starts with data. This data should be in a tidy format that means the data is in a table (called a rectangular data frame) where:\nThe first step to create a plot with ggplot2 is to pass this data to the ggplot() function, which stores the data to be used later by other parts of the plot.\nFor example, if we want to make a plot using the mpg dataset, we begin like this:",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data Visualization</span>"
    ]
  },
  {
    "objectID": "chapters/chapter2_data_visualization.html#data",
    "href": "chapters/chapter2_data_visualization.html#data",
    "title": "3  Data Visualization",
    "section": "",
    "text": "Each row is one observation.\nEach column is one variable.\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\n\nYou should see an empty plot. It is correct. Can you explain why the plot is empty?",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data Visualization</span>"
    ]
  },
  {
    "objectID": "chapters/chapter2_data_visualization.html#mapping",
    "href": "chapters/chapter2_data_visualization.html#mapping",
    "title": "3  Data Visualization",
    "section": "3.2 Mapping",
    "text": "3.2 Mapping\nIn ggplot2 package, mapping means telling the system how to connect parts of the data to aesthetic properties of the plot.\nAesthetic (say: es-THE-ik) is a word that describes how something looks – its style, color, shape, and beauty. In ggplot2, an aesthetic is a visual feature of a plot like:\n\n Position (x and y) – controls where data appears on the plot\n\n Color – changes color based on data values\n\n Size – adjusts the size of points\n\n Shape – uses different shapes for different categories\n\nThese help us turn numbers into pictures. It is how we ’’dress up” the data so it speaks to our eyes.\n\n\n\n\n\n\nMemory tip\n\n\n\nJust like fashion has aesthetic styles (like modern, classic, or colorful), plots also have aesthetics – they decide how the data looks!\n\n\nA mapping can be made by using aes() function to make pairs of graphical attributes and parts of the data. Inside aes(), we match parts of the data (like column names) with visual elements (like \\(x\\) and \\(y\\) position).\nFor the dataset mpg, if we want to show cty (city miles per gallon) on the \\(x\\)-axis and hwy (highway miles per gallon) on the \\(y\\)-axis, we write\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data Visualization</span>"
    ]
  },
  {
    "objectID": "chapters/chapter2_data_visualization.html#layers",
    "href": "chapters/chapter2_data_visualization.html#layers",
    "title": "3  Data Visualization",
    "section": "3.3 Layers",
    "text": "3.3 Layers\nThe layer is the heart of any plot in ggplot2. A layer takes the mapped data and turns it into something that a human can see and understand – like points, lines, or bars.\nEach layer has three main parts: 1. Geometry – decides how the data is shown (for example: points, lines, bars) 2. Statistical transformation – can create new values from the data (like averages or smooth curves). 3. Position adjustment – controls where each part of the plot appears, especially when things overlap.\nA layer can be constructed using functions that start with geom_ (for geometry) and stat_ (for statistics). These function help us choose how the data looks and what to display.\n::: callout-note The geom_*() and stat_*() functions usually control one part of the layer – like the geometry or the statistics – but you can still manullay choose the other two parts if you want. :::\nThe code below shows how to make a scatter plot with a trend line using two layers:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data Visualization</span>"
    ]
  },
  {
    "objectID": "chapters/chapter2_data_visualization.html#scales",
    "href": "chapters/chapter2_data_visualization.html#scales",
    "title": "3  Data Visualization",
    "section": "3.4 Scales",
    "text": "3.4 Scales\nA scale translates what we see on the plot into something we can understand from the data – like showing how far, how big, or what category a point represents.\nEach scale is connected to an aesthetic – for example, the \\(x\\)-axis, \\(y\\)-axis, color, or size – and it controls things like - The limits of the plot (minimum and maximum values) - The breaks (where ticks or labels appear) - The format of the labels (like numbers or percentages) - Any transformation (like logarithmic scale)\nScales also create guides for the reader – like axes or legend – so we can better understand the meaning of the plot.\nScale functions in ggplot2 usually follow the format scale_[aesthetic]_[type](), where {aesthetic} is one of the pairing made in the mapping part of a plot. For example, scale_x_continuous() – for a numeric \\(x\\)-axis; scale_colour_viridis_d() – for discrete color with the Viridis palette.\nHere is how to use a custom color scale for the class variable in the mpg dataset:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nThis tells ggplot2 to use Viridis colors for the different car classes – making the plot easier to read and more accessible.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data Visualization</span>"
    ]
  },
  {
    "objectID": "chapters/chapter2_data_visualization.html#facets",
    "href": "chapters/chapter2_data_visualization.html#facets",
    "title": "3  Data Visualization",
    "section": "3.5 Facets",
    "text": "3.5 Facets\nFacets are used to split a plot into smaller subplots, each showing a subet of the data. This is helpful when you want to compare groups – for example, different years, categories, or types – in separate panels.\nFacets are a powerful way to quickly see patterns, trends, or even no patterns in different parts of the data.\nFacets have their own mapping, written as a formula.\nThe following code creates one scatter plot of two variables cty and hwy of the dataset mpg for each combination of year and drv (driver type) in different panels; so, you can compare them side by side.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nIn facet_grid(year ~ drv), the rows are based on year and the columns are based on drv. As you see, this creates a grid of plots that makes it easy to explore how variables interact.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data Visualization</span>"
    ]
  },
  {
    "objectID": "chapters/chapter2_data_visualization.html#coordinates",
    "href": "chapters/chapter2_data_visualization.html#coordinates",
    "title": "3  Data Visualization",
    "section": "3.6 Coordinates",
    "text": "3.6 Coordinates\nThe coordinates is the part if the plot that controls how position aesthetics (like \\(x\\) and \\(y\\)) are shown. You can think of it as the interpreter that tells the plot where to place things.\nMost ggplot2 plots use Cartesian coordinates, where data is shown on regular \\(x\\)-\\(y\\) grid. But you can also use other systems, like: Polar cooridinate (for circular plots) and Map projections (for geographic data).\nYou can also use coordinates to make sure that one unit on the \\(x\\)-axis is the same size as one unit on the \\(y\\)-axis. This is called a fixed aspect ratio. The function coord_fixed() does this ratio automatically.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data Visualization</span>"
    ]
  },
  {
    "objectID": "chapters/chapter2_data_visualization.html#theme",
    "href": "chapters/chapter2_data_visualization.html#theme",
    "title": "3  Data Visualization",
    "section": "3.7 Theme",
    "text": "3.7 Theme\nThe theme controls parts of the plot that are not related to the data, such as background, text, grid, and legend position. It helps define the overall look and feel of the plot.\nFor instance, you can use the theme to: - Move or hide the legend - Change font size or colors - Set a new background style - Adjust the axes or grid lines\nSome them settings are hierarchical, meaning that if you change the general axis style, it also changes both the \\(x\\)-axis and \\(y\\)-axis unless you set them separately.\nTo change the appearance of a plot, you can use the built-in theme_*() functions (like theme_minimal(), theme_classic(), or theme_light()), or you can customize specific details using the theme() function. With element_*() functions (e.g. element_line(), element_text()) let you adjust the visual style of theme parts, such as lines, texts, or backgrounds.\nThe following code creates a scatter plot and applies a minimal theme. It also moves the legend to the top, makes axis lines thicker, and colors the bottom \\(x\\)-axis blue.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data Visualization</span>"
    ]
  },
  {
    "objectID": "chapters/chapter2_data_visualization.html#mastering-plot-layers-guided-examples-and-student-activities",
    "href": "chapters/chapter2_data_visualization.html#mastering-plot-layers-guided-examples-and-student-activities",
    "title": "3  Data Visualization",
    "section": "3.8 Mastering Plot Layers: Guided Examples and Student Activities",
    "text": "3.8 Mastering Plot Layers: Guided Examples and Student Activities\nAs we mentioned before, a ggplot2 is made by layering different parts. You can combine data, mapping, geoms, scales, facets, coordinates, and themes to build a fully customized plot.\nBelow is an example that brings everything together:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\n\nNote\n\n\n\nThere is no need to type argumants.\n\n\n\n3.8.1 Scatter Plot – geom_point()\nA scatter plot shows the relationship between two numeric variables. each point on the plot represents one observation.\n\n\n\n\n\n\nTip\n\n\n\nScatter plots are useful for seeing patterns, trends, or outliers in data.\n\n\nAn example for seeing the basic scatter plot is showing how height (in inches) changes with age (in years) for each person in the dataset heightweight.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nwe can customize the size of points by adding size = 1.5 to the function geom_point().\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nNow, we can add two aesthetics: shape and color, based on the sex variable.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nNow, we are mapping colour or size to a numeric variable (e.g. weightLb)\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nThese plots show how weight varies with age and height using color or size.\nNow, we are mapping colour to the variable sex and size to a numeric variable weightLb\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nExerciseHintsSolution\n\n\nUsing the heightweight dataset, make a scatter plot to explore the relationship between heightIn and weightLb variables. Your tasks are:\n\nUse points to represent the data.\nShow the variable sex using color so that we can see the difference between males and females.\nMake the points larger than usual, with a size of \\(2.5\\).\nFinally, give your plot a title that describes what it shows, The title should be: “Height vs, Weight by Sex”\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nYou will need\n\naes(x = ______, y = ______, colour = ______) -\ngeom_point(size = ______)\nggtitle(______)\n\n\n\n\n\nSolution. \nggplot(heightweight, aes(x = weightLb, y = heightIn, colour = sex)) + \n  geom_point(size = 2.5) +\n  ggtitle(\"Height vs. Weight by Sex\")\n\n\n\n\n\n\n3.8.2 Line Plot – geom_line()\nUse when: You want to show how a variable changes over time or another ordered variable (like day, year, index)\nWhat is shows: Trends, increases or decreases, cycles over time\nExample\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nThis plot shows how unemployment has changed over time.\n\n\n3.8.3 Barplot – geom_bar() and geom_col()\nUse when: You want to compare counts or values between categories.\n\ngeom_bar() counts how many times each category appears.\ngeom_col() shows values you provided directly.\n\nWhat it shows: Frequencies or values across different categories.\nExample\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n3.8.4 Histogram – geom_histogram()\nUse when : You want to see the distribution of a numeric variable.\nWhat is shows : How values are spread across intervals (called “bins”).\nExample\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nThis plot shows many cars fall into different highway mpg ranges.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n3.8.5 Boxplot – geom_boxplot()\nUse when: You want to compare summary statistics (like median, quartiles, ouliers) across different groups.\nWhat it shows : Median, spread, and outliers for each group.\nExample\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nThis plot compare highway mpg for different type of vehicles.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n3.8.6 Violin Plot – geom_violin()\nUse when: You want to see the distribution shape plus summary info for groups.\nWhat it shows: Like a boxplot, but with a mirrored density curve – great for showing the full distribution and comparison across groups.\nExample\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nYou can also add add points or boxplots inside the violins:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n3.8.7 Dot plot – geom_dotplot()\nUse when: You want to show individual values, especially for small datasets.\nExample\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n3.8.8 Density Plot – geom_density()\nUse when: You want a smoothed version of a histogram.\nWhat is shows: Estimate of the data’s distribution, good for seeing shapes or peaks.\nExample\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nWe can combine the histogram and density plot to show exact counts (histogram) and smooth distribution (density) in one plot.\nExample\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\n\nWhat is after_stat(density)?\n\n\n\nIn ggplot2, when you use geom_histogram(), the default \\(y\\)-axis is count (how many observations fall in each bin). But if you write aes(y = after_stat(density)), you are asking ggplot2 to scale the height of the bars so they represent probability density instead of raw counts. This allows you to compare this histogram with a density curve (like the one from geom_density()), which also shows density.\n\n\nThis shows both frequency and smoothed distribution of highway mpg.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n3.8.9 Pie Chart (using Polar Coordinates)\nUse when: You want to show parts of a whole, but use with caution – bar plots are often easier to read.\nExample\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n3.8.10 2D Density Plot\nA 2D density plot is used to show the distribution of two numeric variables. Instead of plotting each point (like in a scatter plot), it shows where points are concentrated using contour lines (geom_density_2d()) and filled contour areas (geom_density_2d_filled()).\nUse when: you have many overlapping points (overlapping) in a scatter plot and you want to highlight patterns or clusters in two numeric variables and see a smoother version of the joint distribution.\nExample\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nAdding points makes it easier to see what the contours represent.\n\nggplot(faithful, aes(x = waiting, y = eruptions)) +\n  # Add Data Points for Context\n  geom_point(alpha = 0.3) +\n  geom_density_2d()\n\n\n\n\n\n\n\n\nThe following code results in a plot that shows filled bands of density that it is great for visual impact.\n\nggplot(faithful, aes(x = eruptions, y = waiting)) + \n  geom_density_2d_filled(alpha = 0.6) \n\n\n\n\n\n\n\n\nCombining points and filled contours gives both precision and overview.\n\nggplot(faithful, aes(x = eruptions, y = waiting)) +\n  geom_point(alpha = 0.3) +\n  geom_density_2d_filled(alpha = 0.5) +\n  theme_minimal()\n\n\n\n\n\n\n\n\nYou can map density levels to color using after_stat(level)\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nYou can also different code to produce the plot.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n3.8.11 2D Binned Plot for Big Data – stat_bin2d()\nUse when: You have a lot of points and scatter plots are too dense.\nExample\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n3.8.12 Frequency Polygon – geom_freqpoly()\nA frequency plot is similar to a histogram, but it uses lines instead of bars to show how a variable is distributed. It is especially useful when you want to compare distributions across groups.\nUse when: You want to show the shape of a distribution and also compare multiple groups using lines (which may be easier to read than overlapping histograms).\nExamples\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n3.8.13 Correlation Plot (Cor plot)\nA correlation plot (or cor plot) is a visual way to show how strongly variables are related to each other. Correlation values range from \\(-1\\) to \\(1\\), and the plot helps you quickly see positive, negative, or no relationships.\nThis is not built into ggplot2, but we can use it together with\n\nThe cor() function to compute correlation\nThe corrplot or ggcorrplot package to visualize it.\n\nExample using ggcorrplot\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nExample using corrplot\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\nWickham, Hadley, Danielle Navarro, and Thomas Lin Pederson. 2019. Ggplot2: Elegant Graphics for Data Analysis. 3rd ed. https://ggplot2-book.org/.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data Visualization</span>"
    ]
  }
]